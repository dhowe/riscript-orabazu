{"version":3,"sources":["../src/riscript.js","../node_modules/chevrotain/src/parse/parser/parser.ts","../node_modules/chevrotain/src/parse/grammar/rest.ts","../node_modules/chevrotain/src/parse/grammar/first.ts","../node_modules/chevrotain/src/parse/grammar/follow.ts","../node_modules/chevrotain/src/parse/constants.ts","../node_modules/chevrotain/src/scan/tokens_public.ts","../node_modules/chevrotain/src/scan/lexer.ts","../node_modules/chevrotain/src/scan/reg_exp.ts","../node_modules/chevrotain/src/scan/reg_exp_parser.ts","../node_modules/chevrotain/src/scan/lexer_public.ts","../node_modules/chevrotain/src/scan/tokens.ts","../node_modules/chevrotain/src/scan/lexer_errors_public.ts","../node_modules/chevrotain/src/parse/errors_public.ts","../node_modules/chevrotain/src/parse/grammar/gast/gast_resolver_public.ts","../node_modules/chevrotain/src/parse/grammar/resolver.ts","../node_modules/chevrotain/src/parse/grammar/checks.ts","../node_modules/chevrotain/src/parse/grammar/lookahead.ts","../node_modules/chevrotain/src/parse/grammar/interpreter.ts","../node_modules/chevrotain/src/parse/parser/traits/recoverable.ts","../node_modules/chevrotain/src/parse/exceptions_public.ts","../node_modules/chevrotain/src/parse/parser/traits/looksahead.ts","../node_modules/chevrotain/src/parse/grammar/keys.ts","../node_modules/chevrotain/src/parse/grammar/llk_lookahead.ts","../node_modules/chevrotain/src/parse/cst/cst.ts","../node_modules/chevrotain/src/parse/parser/traits/tree_builder.ts","../node_modules/chevrotain/src/parse/cst/cst_visitor.ts","../node_modules/chevrotain/src/lang/lang_extensions.ts","../node_modules/chevrotain/src/parse/parser/traits/lexer_adapter.ts","../node_modules/chevrotain/src/parse/parser/traits/recognizer_api.ts","../node_modules/chevrotain/src/parse/parser/traits/recognizer_engine.ts","../node_modules/chevrotain/src/parse/parser/traits/error_handler.ts","../node_modules/chevrotain/src/parse/parser/traits/context_assist.ts","../node_modules/chevrotain/src/parse/parser/traits/gast_recorder.ts","../node_modules/chevrotain/src/parse/parser/traits/perf_tracer.ts","../node_modules/chevrotain/src/parse/parser/utils/apply_mixins.ts","../node_modules/chevrotain/src/api.ts","../src/tokens.js","../src/parser.js","../src/visitor.js","../src/grammar.js","../src/index.js"],"sourcesContent":["import he from 'he';\nimport { Query } from 'mingo';\nimport { Lexer } from 'chevrotain';\n\nimport { getTokens } from './tokens.js';\nimport { RiScriptParser } from './parser.js';\nimport { RiScriptVisitor } from './visitor.js';\n\n/*\n  Specification:\n    script: expr+\n    expr: (atom)+\n    wexpr: (atom)+ weight\n    symbol: SYM transform*\n    assign: SYM EQ expr transform*\n    gate: @mingo@\n    silent: { gate? expr }\n    atom: (choice | symbol | text | silent) weight?\n    choice: [ gate? ( expr | wexpr ) (OR  (expr | wexpr ) )* else? ] transform*\n    else: ELSE expr\n    raw: Raw\n*/\n\n// TODO: integrate with rita, test node-packages, linting, coverage?\n\nconst { decode } = he;\nconst VowelRE = /[aeiou]/;\nconst RegexEscape = '_RE_';\nconst HtmlEntities = /&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-fA-F]{1,6});/gi;\n\nclass RiQuery extends Query {\n  constructor(scripting, condition, options) {\n    if (typeof condition === 'string') {\n      let raw = condition; // eslint-disable-line\n      condition = scripting.parseJSOL(condition);\n      // console.log('RAW: ', raw, 'parsed', condition);\n    }\n    super(condition, options);\n  }\n\n  test(obj) {\n    for (let i = 0, len = this.compiled.length; i < len; i++) {\n      if (!this.compiled[i](obj)) return false;\n    }\n    return true;\n  }\n\n  operands() {\n    const stack = [this.condition];\n    const keys = new Set();\n    while (stack?.length > 0) {\n      const currentObj = stack.pop();\n      Object.keys(currentObj).forEach((key) => {\n        const value = currentObj[key];\n        // console.log(`key: ${ key }, value: ${ value } `);\n        if (!key.startsWith('$')) keys.add(key);\n        if (typeof value === 'object' && value !== null) {\n          const eles = Array.isArray(value) ? value : [value];\n          eles.forEach((ele) => stack.push(ele));\n        }\n      });\n    }\n    return Array.from(keys);\n  }\n}\n\nclass RiScript {\n  static Query = RiQuery;\n\n  static VERSION = '[VI]{version}[/VI]';\n\n  static RiTaWarnings = { plurals: false, phones: false };\n\n  static evaluate(script, context, opts = {}) {\n    return new RiScript().evaluate(script, context, opts);\n  }\n\n  constructor(opts = {}) { // private ?\n    this.visitor = 0; // created in evaluate() or passed in here\n    this.v2Compatible = opts.compatibility === 2;\n    const { Constants, tokens } = getTokens(this.v2Compatible);\n    this.Escaped = Constants.Escaped;\n    this.Symbols = Constants.Symbols;\n\n    const anysym = Constants.Escaped.STATIC + Constants.Escaped.DYNAMIC;\n    const open = Constants.Escaped.OPEN_CHOICE;\n    const close = Constants.Escaped.CLOSE_CHOICE;\n\n    this.JSOLIdentRE = new RegExp(`([${anysym}]?[A-Za-z_0-9][A-Za-z_0-9]*)\\\\s*:`, 'g');\n    this.RawAssignRE = new RegExp(`^[${anysym}][A-Za-z_0-9][A-Za-z_0-9]*\\\\s*=`);\n    this.ChoiceWrapRE = new RegExp('^' + open + '[^' + open + close + ']*' + close + '$');\n\n    this.SpecialRE = new RegExp(`[${this.Escaped.SPECIAL.replace('&', '')}]`);\n    this.ContinueRE = new RegExp(this.Escaped.CONTINUATION + '\\\\r?\\\\n', 'g');\n    this.WhitespaceRE = /[\\u00a0\\u2000-\\u200b\\u2028-\\u2029\\u3000]+/g;\n    this.AnySymbolRE = new RegExp(`[${anysym}]`); // added\n\n    this.silent = false;\n    this.lexer = new Lexer(tokens);\n    this.parser = new RiScriptParser(tokens);\n    this.RiTa = opts.RiTa || {\n      VERSION: 0,\n      randi: (k) => Math.floor(Math.random() * k),\n    }\n  }\n\n  lex(opts) {\n    if (!opts.input) throw Error('no input');\n    const lexResult = this.lexer.tokenize(opts.input);\n    if (lexResult.errors.length) {\n      console.error('Input: ' + opts.input + '\\n', lexResult.errors[0].message);\n      throw Error('[LEXING] ' + lexResult.errors[0].message);\n    }\n    if (opts.trace) this.printTokens(lexResult.tokens);\n    opts.tokens = lexResult.tokens;\n    // return lexResult;\n  }\n\n  parse(opts) {\n    opts.cst = this.parser.parse(opts);\n  }\n\n  visit(opts) {\n    return this.visitor.start(opts);\n  }\n\n  lexParseVisit(opts = {}) {\n    this.lex(opts);\n    this.parse(opts);\n    return this.visit(opts);\n  }\n\n  evaluate(script, context, opts = {}) {\n    if (typeof script !== 'string') {\n      throw Error('RiScript.evaluate() expects a string, got ' + typeof script);\n    }\n    opts.input = script;\n    opts.visitor = new RiScriptVisitor(this, context);\n    return this._evaluate(opts);\n  }\n\n  _evaluate(opts) {\n    const { input } = opts;\n\n    // opts.onepass = true; // TMP\n\n    let last, endingBreak = /\\r?\\n$/.test(input); // keep\n\n    let expr = this.preParse(input, opts);\n    if (!expr) return '';\n\n    if (opts.trace) console.log(`\\nInput:  '${RiScript._escapeText(input)}'`);\n    if (opts.trace && input !== expr) {\n      console.log(`Parsed: '${RiScript._escapeText(expr)}'`);\n    }\n\n    if (!opts.visitor) throw Error('no visitor');\n    this.visitor = opts.visitor;\n    delete opts.visitor; // remind me why\n\n    for (let i = 1; expr !== last && i <= 10; i++) {\n      last = expr;\n\n      if (opts.trace) console.log('-'.repeat(20) + ' Pass#' + i + ' ' + '-'.repeat(20));\n\n      opts.input = expr;\n      expr = this.lexParseVisit(opts); // do it\n\n      if (opts.trace) {\n        console.log(`Result(${i}) -> \"` + `${RiScript._escapeText(expr)}\"`\n          + ` ctx=${this.visitor.lookupsToString()}`);\n      }\n\n      // end if no more riscript\n      if (opts.onepass || !this.isParseable(expr)) break;\n    }\n\n    // check for unresolved symbols ([$#]) after removing HTML entities\n    if (!this.silent && !this.RiTa.SILENT) {\n      if (this.AnySymbolRE.test(expr.replace(HtmlEntities, ''))) {\n        console.warn('[WARN] Unresolved symbol(s) in \"' + expr.replace(/\\n/g, '\\\\n') + '\" ');\n      }\n    }\n\n    return this.postParse(expr, opts) + (endingBreak ? '\\n' : '');\n  }\n\n  _query(rawQuery, opts) {\n    return new RiQuery(this, rawQuery, opts);\n  }\n\n  printTokens(tokens) {\n    let s = tokens.reduce((str, t) => {\n      let { name } = t.tokenType;\n      let tag = name;\n      if (tag === 'TEXT') tag = RiScript._escapeText(t.image, 1);\n      if (tag === 'SYM') tag = 'sym(' + t.image + ')';\n      if (tag === 'TX') tag = 'tx(' + t.image + ')';\n      return str + tag + ', ';\n    }, '')\n      .slice(0, -2);\n    console.log('\\nTokens: [ ' + s + ' ]  Context:',\n      this.visitor.lookupsToString());\n  }\n\n  postParse(input, opts) {\n    if (typeof input !== 'string') return '';\n\n    // replace html entities\n    let decoded = decode(input);\n\n    // clean up whitespace, linebreaks\n    let result = decoded.replace(this.WhitespaceRE, ' ').replace(/\\r?\\n$/, '');\n\n    // handle unresolved gates\n    let gates = [...result.matchAll(this.Symbols.PENDING_GATE_RE)];\n    gates.forEach((g) => {\n      if (!g || !g[0] || !g[1]) throw Error('bad gate: ' + g);\n      let deferredGate = this.visitor.pendingGates[g[1]];\n      let { deferredContext, operands } = deferredGate;\n      if (!operands.length) throw Error('no operands');\n      let reject = this.visitor.choice(deferredContext, { forceReject: true });\n\n      result = result.replace(g[0], reject);\n      if (opts.trace) console.log('  ' + g[0] + '-> ' + reject);\n    });\n\n    if (opts.trace) console.log(`\\nFinal: '${result}'`);\n\n    if (!opts.preserveLookups) {\n      // reset lookups unless preserveLookups=true (for testing only)\n      this.visitor.statics = undefined;\n      this.visitor.dynamics = undefined;\n    }\n\n    return result;\n  }\n\n  preParse(script, opts) {\n    if (typeof script !== 'string') return '';\n\n    const $ = this.Symbols;\n\n    let input = script;\n    if (!this.v2Compatible) {\n      // handle parenthesized weights ??\n      input = input.replace(/\\((\\s*\\d+\\s*)\\)/g, '^$1^');\n    }\n\n    input = input.replace(/\\/\\*[^]*?(\\r?\\n)?\\//g, ''); // multi-line comments\n    input = input.replace(/\\/\\/[^\\n]+(\\r?\\n|$)/g, ''); // single-line comments\n    input = input.replace(this.ContinueRE, ''); // line continuations\n    input = slashEscapesToEntities(input); // double-backslashed escapes\n\n    let result = '';\n    let lines = input.split(/\\r?\\n/);\n    for (let i = 0; i < lines.length; i++) {\n      // special-case: handle assignments alone on a line\n      if (/*!opts.noAddedSilence && */ this.RawAssignRE.test(lines[i])) {\n        // a very convoluted way of preserving line-breaks inside groups\n        let eqIdx = lines[i].indexOf('=');\n        if (eqIdx < 0) throw Error('invalid state: no assigment: ' + lines[i]);\n        let lhs = lines[i].substring(0, eqIdx),\n          rhs = lines[i].substring(eqIdx + 1);\n        let opens = charCount(rhs, $.OPEN_CHOICE);\n        let closes = charCount(rhs, $.CLOSE_CHOICE);\n        while (opens > closes) {\n          let line = lines[++i];\n          rhs += '\\n' + line;\n          opens += charCount(line, $.OPEN_CHOICE);\n          closes += charCount(line, $.CLOSE_CHOICE);\n        }\n        result += $.OPEN_SILENT + (lhs + '=' + rhs) + $.CLOSE_SILENT;\n      } else {\n        result += lines[i];\n        if (i < lines.length - 1) result += '\\n';\n      }\n    }\n\n    return result;\n  }\n\n  /**\n   * Parses a mingo query into JSON format\n   */\n  parseJSOL(text) {\n    const unescapeRegexProperty = (text) => {\n      // TODO: why do we need this?\n      let res = text;\n      if (\n        typeof text === 'string' &&\n        text.startsWith(RegexEscape) &&\n        text.endsWith(RegexEscape)\n      ) {\n        let parts = text.split(RegexEscape);\n        if (parts.length !== 4) throw Error('invalid regex in unescape');\n        res = new RegExp(parts[1], parts[2]);\n      }\n      return res;\n    };\n    let escaped = RiScript._escapeJSONRegex(text)\n      .replace(this.JSOLIdentRE, '\"$1\":')\n      .replace(/'/g, '\"');\n\n    // console.log(\"escaped: '\"+escaped+\"'\");\n\n    let result = JSON.parse(escaped),\n      urp = unescapeRegexProperty;\n    Object.keys(result).forEach((k) => (result[k] = urp(result[k])));\n    return result;\n  }\n\n  isParseable(s) {\n    // conservatively assume non-string/numbers are always parseable\n    let result = true;\n    let isStrOrNum = /(string|number)/.test(typeof s);\n    // if a string or num, test for special chars\n    if (isStrOrNum) result = this.SpecialRE.test(s.toString());\n    return result;\n  }\n\n  // ========================= statics ===============================\n\n\n  // Default transform that adds an article\n  static articlize(s) {\n    if (!s || !s.length) return '';\n\n    let first = s.split(/\\s+/)[0];\n\n    if (!RiScript.RiTa?.phones) {\n      if (!RiScript.RiTaWarnings.phones) {\n        console.warn('[WARN] Install RiTa for proper phonemes');\n        RiScript.RiTaWarnings.phones = true;\n      }\n      // first.startsWith('a') ? 'an ' : 'a ') + s;\n      return (/^[aeiou].*/i.test(first) ? 'an ' : 'a ') + s;\n    }\n\n    let phones = RiScript.RiTa.phones(first, { silent: true });\n\n    // could still be original word if no phones found\n    return (\n      (phones && phones.length && VowelRE.test(phones[0]) ? 'an ' : 'a ') + s\n    );\n  }\n\n  // Default transform that capitalizes the first character\n  static capitalize(s) {\n    return s ? s[0].toUpperCase() + s.substring(1) : '';\n  }\n\n  // Default transform that capitalizes the string\n  static uppercase(s) {\n    return s ? s.toUpperCase() : '';\n  }\n\n  // Default transform that wraps the string in (smart) quotes.\n  static quotify(s) {\n    return '&#8220;' + (s || '') + '&#8221;';\n  }\n\n  // Default transform that pluralizes a string (requires RiTa)\n  static pluralize(s) {\n    if (!RiScript.RiTa?.pluralize) {\n      if (!RiScript.RiTaWarnings.plurals) {\n        RiScript.RiTaWarnings.plurals = true;\n        console.warn('[WARN] Install RiTa for proper pluralization');\n      }\n      return s.endsWith('s') ? s : s + 's';\n    }\n    return RiScript.RiTa.pluralize(s);\n  }\n\n  // Default no-op transform\n  static identity(s) {\n    return s;\n  }\n\n  // static helpers\n\n  static _transformNames(txs) {\n    return txs && txs.length\n      ? txs.map((tx) => tx.image.replace(/(^\\.|\\(\\)$)/g, ''), [])\n      : [];\n  }\n\n  static _escapeText(s, quotify) {\n    if (typeof s !== 'string') return s;\n    let t = s.replace(/\\r?\\n/g, '\\\\n');\n    return quotify || !t.length ? \"'\" + t + \"'\" : t;\n  }\n\n  static _escapeJSONRegex(text) {\n    return text.replace(\n      /\\/([^/]+?)\\/([igmsuy]*)/g,\n      `\"${RegexEscape}$1${RegexEscape}$2${RegexEscape}\"`\n    );\n  }\n\n  static _stringHash(s) {\n    let chr,\n      hash = 0;\n    for (let i = 0; i < s.length; i++) {\n      chr = s.charCodeAt(i);\n      hash = (hash << 5) - hash + chr;\n      hash |= 0; // Convert to 32bit integer\n    }\n    let strHash = hash.toString();\n    return hash < 0 ? strHash.replace('-', '0') : strHash;\n  }\n}\n\n////////////////////// STATIC PROPS ///////////////////////\n\nRiScript.transforms = {\n  quotify: RiScript.quotify,\n  pluralize: RiScript.pluralize,\n  capitalize: RiScript.capitalize,\n  articlize: RiScript.articlize,\n  uppercase: RiScript.uppercase,\n\n  // sequences\n  norepeat: RiScript.identity,\n\n  // aliases\n  art: RiScript.articlize,\n  nr: RiScript.identity,\n  cap: RiScript.capitalize,\n  ucf: RiScript.capitalize, // deprecated?\n  uc: RiScript.uppercase,\n  qq: RiScript.quotify,\n  s: RiScript.pluralize,\n};\n\n///////////////////////// FUNCTIONS /////////////////////////\n\nfunction slashEscapesToEntities(s) {\n  s = replaceAll(s, '\\\\(', '&lpar;');\n  s = replaceAll(s, '\\\\)', '&rpar;');\n  s = replaceAll(s, '\\\\[', '&lsqb;');\n  s = replaceAll(s, '\\\\]', '&rsqb;');\n  s = replaceAll(s, '\\\\{', '&lcqb;');\n  s = replaceAll(s, '\\\\}', '&rcqb;');\n  s = replaceAll(s, '\\\\@', '&commat;');\n  s = replaceAll(s, '\\\\#', '&num;');\n  s = replaceAll(s, '\\\\|', ' &vert');\n  s = replaceAll(s, '\\\\=', ' &equals');\n  return s;\n}\nfunction escapeRegExp(string) {\n  return string.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\n}\nfunction replaceAll(str, match, replacement) {\n  return str.replace(new RegExp(escapeRegExp(match), 'g'), () => replacement);\n}\nfunction charCount(str, c) {\n  let count = 0;\n  for (let i = 0; i < str.length; i++) {\n    if (str[i] === c) count++;\n  }\n  return count;\n}\n\nexport { RiScript };","import { clone, forEach, has, isEmpty, map, values } from \"lodash-es\";\nimport { toFastProperties } from \"@chevrotain/utils\";\nimport { computeAllProdsFollows } from \"../grammar/follow.js\";\nimport { createTokenInstance, EOF } from \"../../scan/tokens_public.js\";\nimport {\n  defaultGrammarValidatorErrorProvider,\n  defaultParserErrorProvider,\n} from \"../errors_public.js\";\nimport {\n  resolveGrammar,\n  validateGrammar,\n} from \"../grammar/gast/gast_resolver_public.js\";\nimport {\n  CstNode,\n  IParserConfig,\n  IRecognitionException,\n  IRuleConfig,\n  IToken,\n  TokenType,\n  TokenVocabulary,\n} from \"@chevrotain/types\";\nimport { Recoverable } from \"./traits/recoverable.js\";\nimport { LooksAhead } from \"./traits/looksahead.js\";\nimport { TreeBuilder } from \"./traits/tree_builder.js\";\nimport { LexerAdapter } from \"./traits/lexer_adapter.js\";\nimport { RecognizerApi } from \"./traits/recognizer_api.js\";\nimport { RecognizerEngine } from \"./traits/recognizer_engine.js\";\n\nimport { ErrorHandler } from \"./traits/error_handler.js\";\nimport { MixedInParser } from \"./traits/parser_traits.js\";\nimport { ContentAssist } from \"./traits/context_assist.js\";\nimport { GastRecorder } from \"./traits/gast_recorder.js\";\nimport { PerformanceTracer } from \"./traits/perf_tracer.js\";\nimport { applyMixins } from \"./utils/apply_mixins.js\";\nimport { IParserDefinitionError } from \"../grammar/types.js\";\nimport { Rule } from \"@chevrotain/gast\";\nimport { IParserConfigInternal, ParserMethodInternal } from \"./types.js\";\nimport { validateLookahead } from \"../grammar/checks.js\";\n\nexport const END_OF_FILE = createTokenInstance(\n  EOF,\n  \"\",\n  NaN,\n  NaN,\n  NaN,\n  NaN,\n  NaN,\n  NaN,\n);\nObject.freeze(END_OF_FILE);\n\nexport type TokenMatcher = (token: IToken, tokType: TokenType) => boolean;\n\nexport const DEFAULT_PARSER_CONFIG: Required<\n  Omit<IParserConfigInternal, \"lookaheadStrategy\">\n> = Object.freeze({\n  recoveryEnabled: false,\n  maxLookahead: 3,\n  dynamicTokensEnabled: false,\n  outputCst: true,\n  errorMessageProvider: defaultParserErrorProvider,\n  nodeLocationTracking: \"none\",\n  traceInitPerf: false,\n  skipValidations: false,\n});\n\nexport const DEFAULT_RULE_CONFIG: Required<IRuleConfig<any>> = Object.freeze({\n  recoveryValueFunc: () => undefined,\n  resyncEnabled: true,\n});\n\nexport enum ParserDefinitionErrorType {\n  INVALID_RULE_NAME = 0,\n  DUPLICATE_RULE_NAME = 1,\n  INVALID_RULE_OVERRIDE = 2,\n  DUPLICATE_PRODUCTIONS = 3,\n  UNRESOLVED_SUBRULE_REF = 4,\n  LEFT_RECURSION = 5,\n  NONE_LAST_EMPTY_ALT = 6,\n  AMBIGUOUS_ALTS = 7,\n  CONFLICT_TOKENS_RULES_NAMESPACE = 8,\n  INVALID_TOKEN_NAME = 9,\n  NO_NON_EMPTY_LOOKAHEAD = 10,\n  AMBIGUOUS_PREFIX_ALTS = 11,\n  TOO_MANY_ALTS = 12,\n  CUSTOM_LOOKAHEAD_VALIDATION = 13,\n}\n\nexport interface IParserDuplicatesDefinitionError\n  extends IParserDefinitionError {\n  dslName: string;\n  occurrence: number;\n  parameter?: string;\n}\n\nexport interface IParserEmptyAlternativeDefinitionError\n  extends IParserDefinitionError {\n  occurrence: number;\n  alternative: number;\n}\n\nexport interface IParserAmbiguousAlternativesDefinitionError\n  extends IParserDefinitionError {\n  occurrence: number | string;\n  alternatives: number[];\n}\n\nexport interface IParserUnresolvedRefDefinitionError\n  extends IParserDefinitionError {\n  unresolvedRefName: string;\n}\n\nexport interface IParserState {\n  errors: IRecognitionException[];\n  lexerState: any;\n  RULE_STACK: number[];\n  CST_STACK: CstNode[];\n}\n\nexport type Predicate = () => boolean;\n\nexport function EMPTY_ALT(): () => undefined;\nexport function EMPTY_ALT<T>(value: T): () => T;\nexport function EMPTY_ALT(value: any = undefined) {\n  return function () {\n    return value;\n  };\n}\n\nexport class Parser {\n  // Set this flag to true if you don't want the Parser to throw error when problems in it's definition are detected.\n  // (normally during the parser's constructor).\n  // This is a design time flag, it will not affect the runtime error handling of the parser, just design time errors,\n  // for example: duplicate rule names, referencing an unresolved subrule, ect...\n  // This flag should not be enabled during normal usage, it is used in special situations, for example when\n  // needing to display the parser definition errors in some GUI(online playground).\n  static DEFER_DEFINITION_ERRORS_HANDLING: boolean = false;\n\n  /**\n   *  @deprecated use the **instance** method with the same name instead\n   */\n  static performSelfAnalysis(parserInstance: Parser): void {\n    throw Error(\n      \"The **static** `performSelfAnalysis` method has been deprecated.\" +\n        \"\\t\\nUse the **instance** method with the same name instead.\",\n    );\n  }\n\n  public performSelfAnalysis(this: MixedInParser): void {\n    this.TRACE_INIT(\"performSelfAnalysis\", () => {\n      let defErrorsMsgs;\n\n      this.selfAnalysisDone = true;\n      const className = this.className;\n\n      this.TRACE_INIT(\"toFastProps\", () => {\n        // Without this voodoo magic the parser would be x3-x4 slower\n        // It seems it is better to invoke `toFastProperties` **before**\n        // Any manipulations of the `this` object done during the recording phase.\n        toFastProperties(this);\n      });\n\n      this.TRACE_INIT(\"Grammar Recording\", () => {\n        try {\n          this.enableRecording();\n          // Building the GAST\n          forEach(this.definedRulesNames, (currRuleName) => {\n            const wrappedRule = (this as any)[\n              currRuleName\n            ] as ParserMethodInternal<unknown[], unknown>;\n            const originalGrammarAction = wrappedRule[\"originalGrammarAction\"];\n            let recordedRuleGast!: Rule;\n            this.TRACE_INIT(`${currRuleName} Rule`, () => {\n              recordedRuleGast = this.topLevelRuleRecord(\n                currRuleName,\n                originalGrammarAction,\n              );\n            });\n            this.gastProductionsCache[currRuleName] = recordedRuleGast;\n          });\n        } finally {\n          this.disableRecording();\n        }\n      });\n\n      let resolverErrors: IParserDefinitionError[] = [];\n      this.TRACE_INIT(\"Grammar Resolving\", () => {\n        resolverErrors = resolveGrammar({\n          rules: values(this.gastProductionsCache),\n        });\n        this.definitionErrors = this.definitionErrors.concat(resolverErrors);\n      });\n\n      this.TRACE_INIT(\"Grammar Validations\", () => {\n        // only perform additional grammar validations IFF no resolving errors have occurred.\n        // as unresolved grammar may lead to unhandled runtime exceptions in the follow up validations.\n        if (isEmpty(resolverErrors) && this.skipValidations === false) {\n          const validationErrors = validateGrammar({\n            rules: values(this.gastProductionsCache),\n            tokenTypes: values(this.tokensMap),\n            errMsgProvider: defaultGrammarValidatorErrorProvider,\n            grammarName: className,\n          });\n          const lookaheadValidationErrors = validateLookahead({\n            lookaheadStrategy: this.lookaheadStrategy,\n            rules: values(this.gastProductionsCache),\n            tokenTypes: values(this.tokensMap),\n            grammarName: className,\n          });\n          this.definitionErrors = this.definitionErrors.concat(\n            validationErrors,\n            lookaheadValidationErrors,\n          );\n        }\n      });\n\n      // this analysis may fail if the grammar is not perfectly valid\n      if (isEmpty(this.definitionErrors)) {\n        // The results of these computations are not needed unless error recovery is enabled.\n        if (this.recoveryEnabled) {\n          this.TRACE_INIT(\"computeAllProdsFollows\", () => {\n            const allFollows = computeAllProdsFollows(\n              values(this.gastProductionsCache),\n            );\n            this.resyncFollows = allFollows;\n          });\n        }\n\n        this.TRACE_INIT(\"ComputeLookaheadFunctions\", () => {\n          this.lookaheadStrategy.initialize?.({\n            rules: values(this.gastProductionsCache),\n          });\n          this.preComputeLookaheadFunctions(values(this.gastProductionsCache));\n        });\n      }\n\n      if (\n        !Parser.DEFER_DEFINITION_ERRORS_HANDLING &&\n        !isEmpty(this.definitionErrors)\n      ) {\n        defErrorsMsgs = map(\n          this.definitionErrors,\n          (defError) => defError.message,\n        );\n        throw new Error(\n          `Parser Definition Errors detected:\\n ${defErrorsMsgs.join(\n            \"\\n-------------------------------\\n\",\n          )}`,\n        );\n      }\n    });\n  }\n\n  definitionErrors: IParserDefinitionError[] = [];\n  selfAnalysisDone = false;\n  protected skipValidations: boolean;\n\n  constructor(tokenVocabulary: TokenVocabulary, config: IParserConfig) {\n    const that: MixedInParser = this as any;\n    that.initErrorHandler(config);\n    that.initLexerAdapter();\n    that.initLooksAhead(config);\n    that.initRecognizerEngine(tokenVocabulary, config);\n    that.initRecoverable(config);\n    that.initTreeBuilder(config);\n    that.initContentAssist();\n    that.initGastRecorder(config);\n    that.initPerformanceTracer(config);\n\n    if (has(config, \"ignoredIssues\")) {\n      throw new Error(\n        \"The <ignoredIssues> IParserConfig property has been deprecated.\\n\\t\" +\n          \"Please use the <IGNORE_AMBIGUITIES> flag on the relevant DSL method instead.\\n\\t\" +\n          \"See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#IGNORING_AMBIGUITIES\\n\\t\" +\n          \"For further details.\",\n      );\n    }\n\n    this.skipValidations = has(config, \"skipValidations\")\n      ? (config.skipValidations as boolean) // casting assumes the end user passing the correct type\n      : DEFAULT_PARSER_CONFIG.skipValidations;\n  }\n}\n\napplyMixins(Parser, [\n  Recoverable,\n  LooksAhead,\n  TreeBuilder,\n  LexerAdapter,\n  RecognizerEngine,\n  RecognizerApi,\n  ErrorHandler,\n  ContentAssist,\n  GastRecorder,\n  PerformanceTracer,\n]);\n\nexport class CstParser extends Parser {\n  constructor(\n    tokenVocabulary: TokenVocabulary,\n    config: IParserConfigInternal = DEFAULT_PARSER_CONFIG,\n  ) {\n    const configClone = clone(config);\n    configClone.outputCst = true;\n    super(tokenVocabulary, configClone);\n  }\n}\n\nexport class EmbeddedActionsParser extends Parser {\n  constructor(\n    tokenVocabulary: TokenVocabulary,\n    config: IParserConfigInternal = DEFAULT_PARSER_CONFIG,\n  ) {\n    const configClone = clone(config);\n    configClone.outputCst = false;\n    super(tokenVocabulary, configClone);\n  }\n}\n","import { drop, forEach } from \"lodash-es\";\nimport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport { IProduction } from \"@chevrotain/types\";\n\n/**\n *  A Grammar Walker that computes the \"remaining\" grammar \"after\" a productions in the grammar.\n */\nexport abstract class RestWalker {\n  walk(prod: { definition: IProduction[] }, prevRest: any[] = []): void {\n    forEach(prod.definition, (subProd: IProduction, index) => {\n      const currRest = drop(prod.definition, index + 1);\n      /* istanbul ignore else */\n      if (subProd instanceof NonTerminal) {\n        this.walkProdRef(subProd, currRest, prevRest);\n      } else if (subProd instanceof Terminal) {\n        this.walkTerminal(subProd, currRest, prevRest);\n      } else if (subProd instanceof Alternative) {\n        this.walkFlat(subProd, currRest, prevRest);\n      } else if (subProd instanceof Option) {\n        this.walkOption(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionMandatory) {\n        this.walkAtLeastOne(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionMandatoryWithSeparator) {\n        this.walkAtLeastOneSep(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionWithSeparator) {\n        this.walkManySep(subProd, currRest, prevRest);\n      } else if (subProd instanceof Repetition) {\n        this.walkMany(subProd, currRest, prevRest);\n      } else if (subProd instanceof Alternation) {\n        this.walkOr(subProd, currRest, prevRest);\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n  }\n\n  walkTerminal(\n    terminal: Terminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {}\n\n  walkProdRef(\n    refProd: NonTerminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {}\n\n  walkFlat(\n    flatProd: Alternative,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABCDEF => after the D the rest is EF\n    const fullOrRest = currRest.concat(prevRest);\n    this.walk(flatProd, <any>fullOrRest);\n  }\n\n  walkOption(\n    optionProd: Option,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(DE)?F => after the (DE)? the rest is F\n    const fullOrRest = currRest.concat(prevRest);\n    this.walk(optionProd, <any>fullOrRest);\n  }\n\n  walkAtLeastOne(\n    atLeastOneProd: RepetitionMandatory,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(DE)+F => after the (DE)+ the rest is (DE)?F\n    const fullAtLeastOneRest: IProduction[] = [\n      new Option({ definition: atLeastOneProd.definition }),\n    ].concat(<any>currRest, <any>prevRest);\n    this.walk(atLeastOneProd, fullAtLeastOneRest);\n  }\n\n  walkAtLeastOneSep(\n    atLeastOneSepProd: RepetitionMandatoryWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC DE(,DE)* F => after the (,DE)+ the rest is (,DE)?F\n    const fullAtLeastOneSepRest = restForRepetitionWithSeparator(\n      atLeastOneSepProd,\n      currRest,\n      prevRest,\n    );\n    this.walk(atLeastOneSepProd, fullAtLeastOneSepRest);\n  }\n\n  walkMany(\n    manyProd: Repetition,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(DE)*F => after the (DE)* the rest is (DE)?F\n    const fullManyRest: IProduction[] = [\n      new Option({ definition: manyProd.definition }),\n    ].concat(<any>currRest, <any>prevRest);\n    this.walk(manyProd, fullManyRest);\n  }\n\n  walkManySep(\n    manySepProd: RepetitionWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC (DE(,DE)*)? F => after the (,DE)* the rest is (,DE)?F\n    const fullManySepRest = restForRepetitionWithSeparator(\n      manySepProd,\n      currRest,\n      prevRest,\n    );\n    this.walk(manySepProd, fullManySepRest);\n  }\n\n  walkOr(\n    orProd: Alternation,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(D|E|F)G => when finding the (D|E|F) the rest is G\n    const fullOrRest = currRest.concat(prevRest);\n    // walk all different alternatives\n    forEach(orProd.definition, (alt) => {\n      // wrapping each alternative in a single definition wrapper\n      // to avoid errors in computing the rest of that alternative in the invocation to computeInProdFollows\n      // (otherwise for OR([alt1,alt2]) alt2 will be considered in 'rest' of alt1\n      const prodWrapper = new Alternative({ definition: [alt] });\n      this.walk(prodWrapper, <any>fullOrRest);\n    });\n  }\n}\n\nfunction restForRepetitionWithSeparator(\n  repSepProd: RepetitionWithSeparator,\n  currRest: IProduction[],\n  prevRest: IProduction[],\n) {\n  const repSepRest = [\n    new Option({\n      definition: [\n        new Terminal({ terminalType: repSepProd.separator }) as IProduction,\n      ].concat(repSepProd.definition),\n    }) as IProduction,\n  ];\n  const fullRepSepRest: IProduction[] = repSepRest.concat(currRest, prevRest);\n  return fullRepSepRest;\n}\n","import { flatten, map, uniq } from \"lodash-es\";\nimport {\n  isBranchingProd,\n  isOptionalProd,\n  isSequenceProd,\n  NonTerminal,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport { IProduction, TokenType } from \"@chevrotain/types\";\n\nexport function first(prod: IProduction): TokenType[] {\n  /* istanbul ignore else */\n  if (prod instanceof NonTerminal) {\n    // this could in theory cause infinite loops if\n    // (1) prod A refs prod B.\n    // (2) prod B refs prod A\n    // (3) AB can match the empty set\n    // in other words a cycle where everything is optional so the first will keep\n    // looking ahead for the next optional part and will never exit\n    // currently there is no safeguard for this unique edge case because\n    // (1) not sure a grammar in which this can happen is useful for anything (productive)\n    return first((<NonTerminal>prod).referencedRule);\n  } else if (prod instanceof Terminal) {\n    return firstForTerminal(<Terminal>prod);\n  } else if (isSequenceProd(prod)) {\n    return firstForSequence(prod);\n  } else if (isBranchingProd(prod)) {\n    return firstForBranching(prod);\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexport function firstForSequence(prod: {\n  definition: IProduction[];\n}): TokenType[] {\n  let firstSet: TokenType[] = [];\n  const seq = prod.definition;\n  let nextSubProdIdx = 0;\n  let hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n  let currSubProd;\n  // so we enter the loop at least once (if the definition is not empty\n  let isLastInnerProdOptional = true;\n  // scan a sequence until it's end or until we have found a NONE optional production in it\n  while (hasInnerProdsRemaining && isLastInnerProdOptional) {\n    currSubProd = seq[nextSubProdIdx];\n    isLastInnerProdOptional = isOptionalProd(currSubProd);\n    firstSet = firstSet.concat(first(currSubProd));\n    nextSubProdIdx = nextSubProdIdx + 1;\n    hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n  }\n\n  return uniq(firstSet);\n}\n\nexport function firstForBranching(prod: {\n  definition: IProduction[];\n}): TokenType[] {\n  const allAlternativesFirsts: TokenType[][] = map(\n    prod.definition,\n    (innerProd) => {\n      return first(innerProd);\n    },\n  );\n  return uniq(flatten<TokenType>(allAlternativesFirsts));\n}\n\nexport function firstForTerminal(terminal: Terminal): TokenType[] {\n  return [terminal.terminalType];\n}\n","import { RestWalker } from \"./rest.js\";\nimport { first } from \"./first.js\";\nimport { assign, forEach } from \"lodash-es\";\nimport { IN } from \"../constants.js\";\nimport { Alternative, NonTerminal, Rule, Terminal } from \"@chevrotain/gast\";\nimport { IProduction, TokenType } from \"@chevrotain/types\";\n\n// This ResyncFollowsWalker computes all of the follows required for RESYNC\n// (skipping reference production).\nexport class ResyncFollowsWalker extends RestWalker {\n  public follows: Record<string, TokenType[]> = {};\n\n  constructor(private topProd: Rule) {\n    super();\n  }\n\n  startWalking(): Record<string, TokenType[]> {\n    this.walk(this.topProd);\n    return this.follows;\n  }\n\n  walkTerminal(\n    terminal: Terminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // do nothing! just like in the public sector after 13:00\n  }\n\n  walkProdRef(\n    refProd: NonTerminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    const followName =\n      buildBetweenProdsFollowPrefix(refProd.referencedRule, refProd.idx) +\n      this.topProd.name;\n    const fullRest: IProduction[] = currRest.concat(prevRest);\n    const restProd = new Alternative({ definition: fullRest });\n    const t_in_topProd_follows = first(restProd);\n    this.follows[followName] = t_in_topProd_follows;\n  }\n}\n\nexport function computeAllProdsFollows(\n  topProductions: Rule[],\n): Record<string, TokenType[]> {\n  const reSyncFollows = {};\n\n  forEach(topProductions, (topProd) => {\n    const currRefsFollow = new ResyncFollowsWalker(topProd).startWalking();\n    assign(reSyncFollows, currRefsFollow);\n  });\n  return reSyncFollows;\n}\n\nexport function buildBetweenProdsFollowPrefix(\n  inner: Rule,\n  occurenceInParent: number,\n): string {\n  return inner.name + occurenceInParent + IN;\n}\n\nexport function buildInProdFollowPrefix(terminal: Terminal): string {\n  const terminalName = terminal.terminalType.name;\n  return terminalName + terminal.idx + IN;\n}\n","// TODO: can this be removed? where is it used?\nexport const IN = \"_~IN~_\";\n","import { has, isString, isUndefined } from \"lodash-es\";\nimport { Lexer } from \"./lexer_public.js\";\nimport { augmentTokenTypes, tokenStructuredMatcher } from \"./tokens.js\";\nimport { IToken, ITokenConfig, TokenType } from \"@chevrotain/types\";\n\nexport function tokenLabel(tokType: TokenType): string {\n  if (hasTokenLabel(tokType)) {\n    return tokType.LABEL;\n  } else {\n    return tokType.name;\n  }\n}\n\nexport function tokenName(tokType: TokenType): string {\n  return tokType.name;\n}\n\nexport function hasTokenLabel(\n  obj: TokenType,\n): obj is TokenType & Pick<Required<TokenType>, \"LABEL\"> {\n  return isString(obj.LABEL) && obj.LABEL !== \"\";\n}\n\nconst PARENT = \"parent\";\nconst CATEGORIES = \"categories\";\nconst LABEL = \"label\";\nconst GROUP = \"group\";\nconst PUSH_MODE = \"push_mode\";\nconst POP_MODE = \"pop_mode\";\nconst LONGER_ALT = \"longer_alt\";\nconst LINE_BREAKS = \"line_breaks\";\nconst START_CHARS_HINT = \"start_chars_hint\";\n\nexport function createToken(config: ITokenConfig): TokenType {\n  return createTokenInternal(config);\n}\n\nfunction createTokenInternal(config: ITokenConfig): TokenType {\n  const pattern = config.pattern;\n\n  const tokenType: TokenType = <any>{};\n  tokenType.name = config.name;\n\n  if (!isUndefined(pattern)) {\n    tokenType.PATTERN = pattern;\n  }\n\n  if (has(config, PARENT)) {\n    throw (\n      \"The parent property is no longer supported.\\n\" +\n      \"See: https://github.com/chevrotain/chevrotain/issues/564#issuecomment-349062346 for details.\"\n    );\n  }\n\n  if (has(config, CATEGORIES)) {\n    // casting to ANY as this will be fixed inside `augmentTokenTypes``\n    tokenType.CATEGORIES = <any>config[CATEGORIES];\n  }\n\n  augmentTokenTypes([tokenType]);\n\n  if (has(config, LABEL)) {\n    tokenType.LABEL = config[LABEL];\n  }\n\n  if (has(config, GROUP)) {\n    tokenType.GROUP = config[GROUP];\n  }\n\n  if (has(config, POP_MODE)) {\n    tokenType.POP_MODE = config[POP_MODE];\n  }\n\n  if (has(config, PUSH_MODE)) {\n    tokenType.PUSH_MODE = config[PUSH_MODE];\n  }\n\n  if (has(config, LONGER_ALT)) {\n    tokenType.LONGER_ALT = config[LONGER_ALT];\n  }\n\n  if (has(config, LINE_BREAKS)) {\n    tokenType.LINE_BREAKS = config[LINE_BREAKS];\n  }\n\n  if (has(config, START_CHARS_HINT)) {\n    tokenType.START_CHARS_HINT = config[START_CHARS_HINT];\n  }\n\n  return tokenType;\n}\n\nexport const EOF = createToken({ name: \"EOF\", pattern: Lexer.NA });\naugmentTokenTypes([EOF]);\n\nexport function createTokenInstance(\n  tokType: TokenType,\n  image: string,\n  startOffset: number,\n  endOffset: number,\n  startLine: number,\n  endLine: number,\n  startColumn: number,\n  endColumn: number,\n): IToken {\n  return {\n    image,\n    startOffset,\n    endOffset,\n    startLine,\n    endLine,\n    startColumn,\n    endColumn,\n    tokenTypeIdx: (<any>tokType).tokenTypeIdx,\n    tokenType: tokType,\n  };\n}\n\nexport function tokenMatcher(token: IToken, tokType: TokenType): boolean {\n  return tokenStructuredMatcher(token, tokType);\n}\n","import { BaseRegExpVisitor } from \"@chevrotain/regexp-to-ast\";\nimport {\n  IRegExpExec,\n  Lexer,\n  LexerDefinitionErrorType,\n} from \"./lexer_public.js\";\nimport {\n  compact,\n  defaults,\n  difference,\n  filter,\n  find,\n  first,\n  flatten,\n  forEach,\n  has,\n  includes,\n  indexOf,\n  isArray,\n  isEmpty,\n  isFunction,\n  isRegExp,\n  isString,\n  isUndefined,\n  keys,\n  map,\n  reduce,\n  reject,\n  values,\n} from \"lodash-es\";\nimport { PRINT_ERROR } from \"@chevrotain/utils\";\nimport {\n  canMatchCharCode,\n  failedOptimizationPrefixMsg,\n  getOptimizedStartCodesIndices,\n} from \"./reg_exp.js\";\nimport {\n  ILexerDefinitionError,\n  ILineTerminatorsTester,\n  IMultiModeLexerDefinition,\n  IToken,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { getRegExpAst } from \"./reg_exp_parser.js\";\n\nconst PATTERN = \"PATTERN\";\nexport const DEFAULT_MODE = \"defaultMode\";\nexport const MODES = \"modes\";\n\nexport interface IPatternConfig {\n  pattern: IRegExpExec | string;\n  longerAlt: number[] | undefined;\n  canLineTerminator: boolean;\n  isCustom: boolean;\n  short: number | false;\n  group: string | undefined | false;\n  push: string | undefined;\n  pop: boolean;\n  tokenType: TokenType;\n  tokenTypeIdx: number;\n}\n\nexport interface IAnalyzeResult {\n  patternIdxToConfig: IPatternConfig[];\n  charCodeToPatternIdxToConfig: { [charCode: number]: IPatternConfig[] };\n  emptyGroups: { [groupName: string]: IToken[] };\n  hasCustom: boolean;\n  canBeOptimized: boolean;\n}\n\nexport let SUPPORT_STICKY =\n  typeof (<any>new RegExp(\"(?:)\")).sticky === \"boolean\";\n\nexport function disableSticky() {\n  SUPPORT_STICKY = false;\n}\n\nexport function enableSticky() {\n  SUPPORT_STICKY = true;\n}\n\nexport function analyzeTokenTypes(\n  tokenTypes: TokenType[],\n  options: {\n    positionTracking?: \"full\" | \"onlyStart\" | \"onlyOffset\";\n    ensureOptimizations?: boolean;\n    lineTerminatorCharacters?: (number | string)[];\n    // TODO: should `useSticky` be an argument here?\n    useSticky?: boolean;\n    safeMode?: boolean;\n    tracer?: (msg: string, action: () => void) => void;\n  },\n): IAnalyzeResult {\n  options = defaults(options, {\n    useSticky: SUPPORT_STICKY,\n    debug: false as boolean,\n    safeMode: false as boolean,\n    positionTracking: \"full\",\n    lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n    tracer: (msg: string, action: Function) => action(),\n  });\n\n  const tracer = options.tracer!;\n\n  tracer(\"initCharCodeToOptimizedIndexMap\", () => {\n    initCharCodeToOptimizedIndexMap();\n  });\n\n  let onlyRelevantTypes: TokenType[];\n  tracer(\"Reject Lexer.NA\", () => {\n    onlyRelevantTypes = reject(tokenTypes, (currType) => {\n      return currType[PATTERN] === Lexer.NA;\n    });\n  });\n\n  let hasCustom = false;\n  let allTransformedPatterns: (IRegExpExec | string)[];\n  tracer(\"Transform Patterns\", () => {\n    hasCustom = false;\n    allTransformedPatterns = map(\n      onlyRelevantTypes,\n      (currType): IRegExpExec | string => {\n        const currPattern = currType[PATTERN];\n\n        /* istanbul ignore else */\n        if (isRegExp(currPattern)) {\n          const regExpSource = currPattern.source;\n          if (\n            regExpSource.length === 1 &&\n            // only these regExp meta characters which can appear in a length one regExp\n            regExpSource !== \"^\" &&\n            regExpSource !== \"$\" &&\n            regExpSource !== \".\" &&\n            !currPattern.ignoreCase\n          ) {\n            return regExpSource;\n          } else if (\n            regExpSource.length === 2 &&\n            regExpSource[0] === \"\\\\\" &&\n            // not a meta character\n            !includes(\n              [\n                \"d\",\n                \"D\",\n                \"s\",\n                \"S\",\n                \"t\",\n                \"r\",\n                \"n\",\n                \"t\",\n                \"0\",\n                \"c\",\n                \"b\",\n                \"B\",\n                \"f\",\n                \"v\",\n                \"w\",\n                \"W\",\n              ],\n              regExpSource[1],\n            )\n          ) {\n            // escaped meta Characters: /\\+/ /\\[/\n            // or redundant escaping: /\\a/\n            // without the escaping \"\\\"\n            return regExpSource[1];\n          } else {\n            return options.useSticky\n              ? addStickyFlag(currPattern)\n              : addStartOfInput(currPattern);\n          }\n        } else if (isFunction(currPattern)) {\n          hasCustom = true;\n          // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n          return { exec: currPattern };\n        } else if (typeof currPattern === \"object\") {\n          hasCustom = true;\n          // ICustomPattern\n          return currPattern;\n        } else if (typeof currPattern === \"string\") {\n          if (currPattern.length === 1) {\n            return currPattern;\n          } else {\n            const escapedRegExpString = currPattern.replace(\n              /[\\\\^$.*+?()[\\]{}|]/g,\n              \"\\\\$&\",\n            );\n            const wrappedRegExp = new RegExp(escapedRegExpString);\n            return options.useSticky\n              ? addStickyFlag(wrappedRegExp)\n              : addStartOfInput(wrappedRegExp);\n          }\n        } else {\n          throw Error(\"non exhaustive match\");\n        }\n      },\n    );\n  });\n\n  let patternIdxToType: number[];\n  let patternIdxToGroup: (string | undefined | false)[];\n  let patternIdxToLongerAltIdxArr: (number[] | undefined)[];\n  let patternIdxToPushMode: (string | undefined)[];\n  let patternIdxToPopMode: boolean[];\n  tracer(\"misc mapping\", () => {\n    patternIdxToType = map(\n      onlyRelevantTypes,\n      (currType) => currType.tokenTypeIdx!,\n    );\n\n    patternIdxToGroup = map(onlyRelevantTypes, (clazz: any) => {\n      const groupName = clazz.GROUP;\n      /* istanbul ignore next */\n      if (groupName === Lexer.SKIPPED) {\n        return undefined;\n      } else if (isString(groupName)) {\n        return groupName;\n      } else if (isUndefined(groupName)) {\n        return false;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n\n    patternIdxToLongerAltIdxArr = map(onlyRelevantTypes, (clazz: any) => {\n      const longerAltType = clazz.LONGER_ALT;\n\n      if (longerAltType) {\n        const longerAltIdxArr = isArray(longerAltType)\n          ? map(longerAltType, (type: any) => indexOf(onlyRelevantTypes, type))\n          : [indexOf(onlyRelevantTypes, longerAltType)];\n        return longerAltIdxArr;\n      }\n    });\n\n    patternIdxToPushMode = map(\n      onlyRelevantTypes,\n      (clazz: any) => clazz.PUSH_MODE,\n    );\n\n    patternIdxToPopMode = map(onlyRelevantTypes, (clazz: any) =>\n      has(clazz, \"POP_MODE\"),\n    );\n  });\n\n  let patternIdxToCanLineTerminator: boolean[];\n  tracer(\"Line Terminator Handling\", () => {\n    const lineTerminatorCharCodes = getCharCodes(\n      options.lineTerminatorCharacters!,\n    );\n    patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => false);\n    if (options.positionTracking !== \"onlyOffset\") {\n      patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => {\n        if (has(tokType, \"LINE_BREAKS\")) {\n          return !!tokType.LINE_BREAKS;\n        } else {\n          return (\n            checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false &&\n            canMatchCharCode(\n              lineTerminatorCharCodes,\n              tokType.PATTERN as RegExp | string,\n            )\n          );\n        }\n      });\n    }\n  });\n\n  let patternIdxToIsCustom: boolean[];\n  let patternIdxToShort: (number | false)[];\n  let emptyGroups!: { [groupName: string]: IToken[] };\n  let patternIdxToConfig!: IPatternConfig[];\n  tracer(\"Misc Mapping #2\", () => {\n    patternIdxToIsCustom = map(onlyRelevantTypes, isCustomPattern);\n    patternIdxToShort = map(allTransformedPatterns, isShortPattern);\n\n    emptyGroups = reduce(\n      onlyRelevantTypes,\n      (acc, clazz: any) => {\n        const groupName = clazz.GROUP;\n        if (isString(groupName) && !(groupName === Lexer.SKIPPED)) {\n          acc[groupName] = [];\n        }\n        return acc;\n      },\n      {} as { [groupName: string]: IToken[] },\n    );\n\n    patternIdxToConfig = map(\n      allTransformedPatterns,\n      (x, idx): IPatternConfig => {\n        return {\n          pattern: allTransformedPatterns[idx],\n          longerAlt: patternIdxToLongerAltIdxArr[idx],\n          canLineTerminator: patternIdxToCanLineTerminator[idx],\n          isCustom: patternIdxToIsCustom[idx],\n          short: patternIdxToShort[idx],\n          group: patternIdxToGroup[idx],\n          push: patternIdxToPushMode[idx],\n          pop: patternIdxToPopMode[idx],\n          tokenTypeIdx: patternIdxToType[idx],\n          tokenType: onlyRelevantTypes[idx],\n        };\n      },\n    );\n  });\n\n  let canBeOptimized = true;\n  let charCodeToPatternIdxToConfig: { [charCode: number]: IPatternConfig[] } =\n    [];\n\n  if (!options.safeMode) {\n    tracer(\"First Char Optimization\", () => {\n      charCodeToPatternIdxToConfig = reduce(\n        onlyRelevantTypes,\n        (result, currTokType, idx) => {\n          if (typeof currTokType.PATTERN === \"string\") {\n            const charCode = currTokType.PATTERN.charCodeAt(0);\n            const optimizedIdx = charCodeToOptimizedIndex(charCode);\n            addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n          } else if (isArray(currTokType.START_CHARS_HINT)) {\n            let lastOptimizedIdx: number;\n            forEach(currTokType.START_CHARS_HINT, (charOrInt) => {\n              const charCode =\n                typeof charOrInt === \"string\"\n                  ? charOrInt.charCodeAt(0)\n                  : charOrInt;\n              const currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n              // Avoid adding the config multiple times\n              /* istanbul ignore else */\n              // - Difficult to check this scenario effects as it is only a performance\n              //   optimization that does not change correctness\n              if (lastOptimizedIdx !== currOptimizedIdx) {\n                lastOptimizedIdx = currOptimizedIdx;\n                addToMapOfArrays(\n                  result,\n                  currOptimizedIdx,\n                  patternIdxToConfig[idx],\n                );\n              }\n            });\n          } else if (isRegExp(currTokType.PATTERN)) {\n            if (currTokType.PATTERN.unicode) {\n              canBeOptimized = false;\n              if (options.ensureOptimizations) {\n                PRINT_ERROR(\n                  `${failedOptimizationPrefixMsg}` +\n                    `\\tUnable to analyze < ${currTokType.PATTERN.toString()} > pattern.\\n` +\n                    \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" +\n                    \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                    \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\",\n                );\n              }\n            } else {\n              const optimizedCodes = getOptimizedStartCodesIndices(\n                currTokType.PATTERN,\n                options.ensureOptimizations,\n              );\n              /* istanbul ignore if */\n              // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n              // the first should be a different validation and the second cannot be tested.\n              if (isEmpty(optimizedCodes)) {\n                // we cannot understand what codes may start possible matches\n                // The optimization correctness requires knowing start codes for ALL patterns.\n                // Not actually sure this is an error, no debug message\n                canBeOptimized = false;\n              }\n              forEach(optimizedCodes, (code) => {\n                addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n              });\n            }\n          } else {\n            if (options.ensureOptimizations) {\n              PRINT_ERROR(\n                `${failedOptimizationPrefixMsg}` +\n                  `\\tTokenType: <${currTokType.name}> is using a custom token pattern without providing <start_chars_hint> parameter.\\n` +\n                  \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                  \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\",\n              );\n            }\n            canBeOptimized = false;\n          }\n\n          return result;\n        },\n        [] as { [charCode: number]: IPatternConfig[] },\n      );\n    });\n  }\n\n  return {\n    emptyGroups: emptyGroups,\n    patternIdxToConfig: patternIdxToConfig,\n    charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n    hasCustom: hasCustom,\n    canBeOptimized: canBeOptimized,\n  };\n}\n\nexport function validatePatterns(\n  tokenTypes: TokenType[],\n  validModesNames: string[],\n): ILexerDefinitionError[] {\n  let errors: ILexerDefinitionError[] = [];\n\n  const missingResult = findMissingPatterns(tokenTypes);\n  errors = errors.concat(missingResult.errors);\n\n  const invalidResult = findInvalidPatterns(missingResult.valid);\n  const validTokenTypes = invalidResult.valid;\n  errors = errors.concat(invalidResult.errors);\n\n  errors = errors.concat(validateRegExpPattern(validTokenTypes));\n\n  errors = errors.concat(findInvalidGroupType(validTokenTypes));\n\n  errors = errors.concat(\n    findModesThatDoNotExist(validTokenTypes, validModesNames),\n  );\n\n  errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n\n  return errors;\n}\n\nfunction validateRegExpPattern(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  let errors: ILexerDefinitionError[] = [];\n  const withRegExpPatterns = filter(tokenTypes, (currTokType) =>\n    isRegExp(currTokType[PATTERN]),\n  );\n\n  errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n\n  errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n\n  errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n\n  errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n\n  errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n\n  return errors;\n}\n\nexport interface ILexerFilterResult {\n  errors: ILexerDefinitionError[];\n  valid: TokenType[];\n}\n\nexport function findMissingPatterns(\n  tokenTypes: TokenType[],\n): ILexerFilterResult {\n  const tokenTypesWithMissingPattern = filter(tokenTypes, (currType) => {\n    return !has(currType, PATTERN);\n  });\n\n  const errors = map(tokenTypesWithMissingPattern, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- missing static 'PATTERN' property\",\n      type: LexerDefinitionErrorType.MISSING_PATTERN,\n      tokenTypes: [currType],\n    };\n  });\n\n  const valid = difference(tokenTypes, tokenTypesWithMissingPattern);\n  return { errors, valid };\n}\n\nexport function findInvalidPatterns(\n  tokenTypes: TokenType[],\n): ILexerFilterResult {\n  const tokenTypesWithInvalidPattern = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN];\n    return (\n      !isRegExp(pattern) &&\n      !isFunction(pattern) &&\n      !has(pattern, \"exec\") &&\n      !isString(pattern)\n    );\n  });\n\n  const errors = map(tokenTypesWithInvalidPattern, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' can only be a RegExp, a\" +\n        \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n      type: LexerDefinitionErrorType.INVALID_PATTERN,\n      tokenTypes: [currType],\n    };\n  });\n\n  const valid = difference(tokenTypes, tokenTypesWithInvalidPattern);\n  return { errors, valid };\n}\n\nconst end_of_input = /[^\\\\][$]/;\n\nexport function findEndOfInputAnchor(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  class EndAnchorFinder extends BaseRegExpVisitor {\n    found = false;\n\n    visitEndAnchor(node: unknown) {\n      this.found = true;\n    }\n  }\n\n  const invalidRegex = filter(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN;\n\n    try {\n      const regexpAst = getRegExpAst(pattern as RegExp);\n      const endAnchorVisitor = new EndAnchorFinder();\n      endAnchorVisitor.visit(regexpAst);\n\n      return endAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return end_of_input.test((pattern as RegExp).source);\n    }\n  });\n\n  const errors = map(invalidRegex, (currType) => {\n    return {\n      message:\n        \"Unexpected RegExp Anchor Error:\\n\" +\n        \"\\tToken Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" +\n        \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findEmptyMatchRegExps(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const matchesEmptyString = filter(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN as RegExp;\n    return pattern.test(\"\");\n  });\n\n  const errors = map(matchesEmptyString, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' must not match an empty string\",\n      type: LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nconst start_of_input = /[^\\\\[][\\^]|^\\^/;\n\nexport function findStartOfInputAnchor(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  class StartAnchorFinder extends BaseRegExpVisitor {\n    found = false;\n\n    visitStartAnchor(node: unknown) {\n      this.found = true;\n    }\n  }\n\n  const invalidRegex = filter(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN as RegExp;\n    try {\n      const regexpAst = getRegExpAst(pattern);\n      const startAnchorVisitor = new StartAnchorFinder();\n      startAnchorVisitor.visit(regexpAst);\n\n      return startAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return start_of_input.test(pattern.source);\n    }\n  });\n\n  const errors = map(invalidRegex, (currType) => {\n    return {\n      message:\n        \"Unexpected RegExp Anchor Error:\\n\" +\n        \"\\tToken Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" +\n        \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findUnsupportedFlags(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const invalidFlags = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN];\n    return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n  });\n\n  const errors = map(invalidFlags, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n      type: LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nexport function findDuplicatePatterns(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const found: TokenType[] = [];\n  let identicalPatterns = map(tokenTypes, (outerType: any) => {\n    return reduce(\n      tokenTypes,\n      (result, innerType) => {\n        if (\n          outerType.PATTERN.source === (innerType.PATTERN as RegExp).source &&\n          !includes(found, innerType) &&\n          innerType.PATTERN !== Lexer.NA\n        ) {\n          // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n          // in essence we are creating Equivalence classes on equality relation.\n          found.push(innerType);\n          result.push(innerType);\n          return result;\n        }\n        return result;\n      },\n      [] as TokenType[],\n    );\n  });\n\n  identicalPatterns = compact(identicalPatterns);\n\n  const duplicatePatterns = filter(identicalPatterns, (currIdenticalSet) => {\n    return currIdenticalSet.length > 1;\n  });\n\n  const errors = map(duplicatePatterns, (setOfIdentical: any) => {\n    const tokenTypeNames = map(setOfIdentical, (currType: any) => {\n      return currType.name;\n    });\n\n    const dupPatternSrc = (<any>first(setOfIdentical)).PATTERN;\n    return {\n      message:\n        `The same RegExp pattern ->${dupPatternSrc}<-` +\n        `has been used in all of the following Token Types: ${tokenTypeNames.join(\n          \", \",\n        )} <-`,\n      type: LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n      tokenTypes: setOfIdentical,\n    };\n  });\n\n  return errors;\n}\n\nexport function findInvalidGroupType(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const invalidTypes = filter(tokenTypes, (clazz: any) => {\n    if (!has(clazz, \"GROUP\")) {\n      return false;\n    }\n    const group = clazz.GROUP;\n\n    return group !== Lexer.SKIPPED && group !== Lexer.NA && !isString(group);\n  });\n\n  const errors = map(invalidTypes, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n      type: LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findModesThatDoNotExist(\n  tokenTypes: TokenType[],\n  validModes: string[],\n): ILexerDefinitionError[] {\n  const invalidModes = filter(tokenTypes, (clazz: any) => {\n    return (\n      clazz.PUSH_MODE !== undefined && !includes(validModes, clazz.PUSH_MODE)\n    );\n  });\n\n  const errors = map(invalidModes, (tokType) => {\n    const msg =\n      `Token Type: ->${tokType.name}<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->${tokType.PUSH_MODE}<-` +\n      `which does not exist`;\n    return {\n      message: msg,\n      type: LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n      tokenTypes: [tokType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findUnreachablePatterns(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const errors: ILexerDefinitionError[] = [];\n\n  const canBeTested = reduce(\n    tokenTypes,\n    (result, tokType, idx) => {\n      const pattern = tokType.PATTERN;\n\n      if (pattern === Lexer.NA) {\n        return result;\n      }\n\n      // a more comprehensive validation for all forms of regExps would require\n      // deeper regExp analysis capabilities\n      if (isString(pattern)) {\n        result.push({ str: pattern, idx, tokenType: tokType });\n      } else if (isRegExp(pattern) && noMetaChar(pattern)) {\n        result.push({ str: pattern.source, idx, tokenType: tokType });\n      }\n      return result;\n    },\n    [] as { str: string; idx: number; tokenType: TokenType }[],\n  );\n\n  forEach(tokenTypes, (tokType, testIdx) => {\n    forEach(canBeTested, ({ str, idx, tokenType }) => {\n      if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n        const msg =\n          `Token: ->${tokenType.name}<- can never be matched.\\n` +\n          `Because it appears AFTER the Token Type ->${tokType.name}<-` +\n          `in the lexer's definition.\\n` +\n          `See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE`;\n        errors.push({\n          message: msg,\n          type: LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n          tokenTypes: [tokType, tokenType],\n        });\n      }\n    });\n  });\n\n  return errors;\n}\n\nfunction testTokenType(str: string, pattern: any): boolean {\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    const regExpArray = pattern.exec(str);\n    return regExpArray !== null && regExpArray.index === 0;\n  } else if (isFunction(pattern)) {\n    // maintain the API of custom patterns\n    return pattern(str, 0, [], {});\n  } else if (has(pattern, \"exec\")) {\n    // maintain the API of custom patterns\n    return pattern.exec(str, 0, [], {});\n  } else if (typeof pattern === \"string\") {\n    return pattern === str;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nfunction noMetaChar(regExp: RegExp): boolean {\n  //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n  const metaChars = [\n    \".\",\n    \"\\\\\",\n    \"[\",\n    \"]\",\n    \"|\",\n    \"^\",\n    \"$\",\n    \"(\",\n    \")\",\n    \"?\",\n    \"*\",\n    \"+\",\n    \"{\",\n  ];\n  return (\n    find(metaChars, (char) => regExp.source.indexOf(char) !== -1) === undefined\n  );\n}\n\nexport function addStartOfInput(pattern: RegExp): RegExp {\n  const flags = pattern.ignoreCase ? \"i\" : \"\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(`^(?:${pattern.source})`, flags);\n}\n\nexport function addStickyFlag(pattern: RegExp): RegExp {\n  const flags = pattern.ignoreCase ? \"iy\" : \"y\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(`${pattern.source}`, flags);\n}\n\nexport function performRuntimeChecks(\n  lexerDefinition: IMultiModeLexerDefinition,\n  trackLines: boolean,\n  lineTerminatorCharacters: (number | string)[],\n): ILexerDefinitionError[] {\n  const errors: ILexerDefinitionError[] = [];\n\n  // some run time checks to help the end users.\n  if (!has(lexerDefinition, DEFAULT_MODE)) {\n    errors.push({\n      message:\n        \"A MultiMode Lexer cannot be initialized without a <\" +\n        DEFAULT_MODE +\n        \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE,\n    });\n  }\n  if (!has(lexerDefinition, MODES)) {\n    errors.push({\n      message:\n        \"A MultiMode Lexer cannot be initialized without a <\" +\n        MODES +\n        \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY,\n    });\n  }\n\n  if (\n    has(lexerDefinition, MODES) &&\n    has(lexerDefinition, DEFAULT_MODE) &&\n    !has(lexerDefinition.modes, lexerDefinition.defaultMode)\n  ) {\n    errors.push({\n      message:\n        `A MultiMode Lexer cannot be initialized with a ${DEFAULT_MODE}: <${lexerDefinition.defaultMode}>` +\n        `which does not exist\\n`,\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST,\n    });\n  }\n\n  if (has(lexerDefinition, MODES)) {\n    forEach(lexerDefinition.modes, (currModeValue, currModeName) => {\n      forEach(currModeValue, (currTokType, currIdx) => {\n        if (isUndefined(currTokType)) {\n          errors.push({\n            message:\n              `A Lexer cannot be initialized using an undefined Token Type. Mode:` +\n              `<${currModeName}> at index: <${currIdx}>\\n`,\n            type: LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED,\n          });\n        } else if (has(currTokType, \"LONGER_ALT\")) {\n          const longerAlt = isArray(currTokType.LONGER_ALT)\n            ? currTokType.LONGER_ALT\n            : [currTokType.LONGER_ALT];\n          forEach(longerAlt, (currLongerAlt) => {\n            if (\n              !isUndefined(currLongerAlt) &&\n              !includes(currModeValue, currLongerAlt)\n            ) {\n              errors.push({\n                message: `A MultiMode Lexer cannot be initialized with a longer_alt <${currLongerAlt.name}> on token <${currTokType.name}> outside of mode <${currModeName}>\\n`,\n                type: LexerDefinitionErrorType.MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE,\n              });\n            }\n          });\n        }\n      });\n    });\n  }\n\n  return errors;\n}\n\nexport function performWarningRuntimeChecks(\n  lexerDefinition: IMultiModeLexerDefinition,\n  trackLines: boolean,\n  lineTerminatorCharacters: (number | string)[],\n): ILexerDefinitionError[] {\n  const warnings = [];\n  let hasAnyLineBreak = false;\n  const allTokenTypes = compact(flatten(values(lexerDefinition.modes)));\n\n  const concreteTokenTypes = reject(\n    allTokenTypes,\n    (currType) => currType[PATTERN] === Lexer.NA,\n  );\n  const terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n  if (trackLines) {\n    forEach(concreteTokenTypes, (tokType) => {\n      const currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n      if (currIssue !== false) {\n        const message = buildLineBreakIssueMessage(tokType, currIssue);\n        const warningDescriptor = {\n          message,\n          type: currIssue.issue,\n          tokenType: tokType,\n        };\n        warnings.push(warningDescriptor);\n      } else {\n        // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n        if (has(tokType, \"LINE_BREAKS\")) {\n          if (tokType.LINE_BREAKS === true) {\n            hasAnyLineBreak = true;\n          }\n        } else {\n          if (\n            canMatchCharCode(terminatorCharCodes, tokType.PATTERN as RegExp)\n          ) {\n            hasAnyLineBreak = true;\n          }\n        }\n      }\n    });\n  }\n\n  if (trackLines && !hasAnyLineBreak) {\n    warnings.push({\n      message:\n        \"Warning: No LINE_BREAKS Found.\\n\" +\n        \"\\tThis Lexer has been defined to track line and column information,\\n\" +\n        \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" +\n        \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS,\n    });\n  }\n  return warnings;\n}\n\nexport function cloneEmptyGroups(emptyGroups: {\n  [groupName: string]: IToken;\n}): { [groupName: string]: IToken } {\n  const clonedResult: any = {};\n  const groupKeys = keys(emptyGroups);\n\n  forEach(groupKeys, (currKey) => {\n    const currGroupValue = emptyGroups[currKey];\n\n    /* istanbul ignore else */\n    if (isArray(currGroupValue)) {\n      clonedResult[currKey] = [];\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  });\n\n  return clonedResult;\n}\n\n// TODO: refactor to avoid duplication\nexport function isCustomPattern(tokenType: TokenType): boolean {\n  const pattern = tokenType.PATTERN;\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    return false;\n  } else if (isFunction(pattern)) {\n    // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n    return true;\n  } else if (has(pattern, \"exec\")) {\n    // ICustomPattern\n    return true;\n  } else if (isString(pattern)) {\n    return false;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexport function isShortPattern(pattern: any): number | false {\n  if (isString(pattern) && pattern.length === 1) {\n    return pattern.charCodeAt(0);\n  } else {\n    return false;\n  }\n}\n\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexport const LineTerminatorOptimizedTester: ILineTerminatorsTester = {\n  // implements /\\n|\\r\\n?/g.test\n  test: function (text) {\n    const len = text.length;\n    for (let i = this.lastIndex; i < len; i++) {\n      const c = text.charCodeAt(i);\n      if (c === 10) {\n        this.lastIndex = i + 1;\n        return true;\n      } else if (c === 13) {\n        if (text.charCodeAt(i + 1) === 10) {\n          this.lastIndex = i + 2;\n        } else {\n          this.lastIndex = i + 1;\n        }\n        return true;\n      }\n    }\n    return false;\n  },\n\n  lastIndex: 0,\n};\n\nfunction checkLineBreaksIssues(\n  tokType: TokenType,\n  lineTerminatorCharCodes: number[],\n):\n  | {\n      issue:\n        | LexerDefinitionErrorType.IDENTIFY_TERMINATOR\n        | LexerDefinitionErrorType.CUSTOM_LINE_BREAK;\n      errMsg?: string;\n    }\n  | false {\n  if (has(tokType, \"LINE_BREAKS\")) {\n    // if the user explicitly declared the line_breaks option we will respect their choice\n    // and assume it is correct.\n    return false;\n  } else {\n    /* istanbul ignore else */\n    if (isRegExp(tokType.PATTERN)) {\n      try {\n        // TODO: why is the casting suddenly needed?\n        canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN as RegExp);\n      } catch (e) {\n        /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n        return {\n          issue: LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n          errMsg: (e as Error).message,\n        };\n      }\n      return false;\n    } else if (isString(tokType.PATTERN)) {\n      // string literal patterns can always be analyzed to detect line terminator usage\n      return false;\n    } else if (isCustomPattern(tokType)) {\n      // custom token types\n      return { issue: LexerDefinitionErrorType.CUSTOM_LINE_BREAK };\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n}\n\nexport function buildLineBreakIssueMessage(\n  tokType: TokenType,\n  details: {\n    issue:\n      | LexerDefinitionErrorType.IDENTIFY_TERMINATOR\n      | LexerDefinitionErrorType.CUSTOM_LINE_BREAK;\n    errMsg?: string;\n  },\n): string {\n  /* istanbul ignore else */\n  if (details.issue === LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n    return (\n      \"Warning: unable to identify line terminator usage in pattern.\\n\" +\n      `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n      `\\t Root cause: ${details.errMsg}.\\n` +\n      \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\"\n    );\n  } else if (details.issue === LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n    return (\n      \"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" +\n      `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n      \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\"\n    );\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nfunction getCharCodes(charsOrCodes: (number | string)[]): number[] {\n  const charCodes = map(charsOrCodes, (numOrString) => {\n    if (isString(numOrString)) {\n      return numOrString.charCodeAt(0);\n    } else {\n      return numOrString;\n    }\n  });\n\n  return charCodes;\n}\n\nfunction addToMapOfArrays<T>(\n  map: Record<number, T[]>,\n  key: number,\n  value: T,\n): void {\n  if (map[key] === undefined) {\n    map[key] = [value];\n  } else {\n    map[key].push(value);\n  }\n}\n\nexport const minOptimizationVal = 256;\n\n/**\n * We are mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nlet charCodeToOptimizedIdxMap: number[] = [];\nexport function charCodeToOptimizedIndex(charCode: number): number {\n  return charCode < minOptimizationVal\n    ? charCode\n    : charCodeToOptimizedIdxMap[charCode];\n}\n\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nfunction initCharCodeToOptimizedIndexMap() {\n  if (isEmpty(charCodeToOptimizedIdxMap)) {\n    charCodeToOptimizedIdxMap = new Array(65536);\n    for (let i = 0; i < 65536; i++) {\n      charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n    }\n  }\n}\n","import {\n  Alternative,\n  Atom,\n  BaseRegExpVisitor,\n  Character,\n  Disjunction,\n  Group,\n  Set,\n} from \"@chevrotain/regexp-to-ast\";\nimport { every, find, forEach, includes, isArray, values } from \"lodash-es\";\nimport { PRINT_ERROR, PRINT_WARNING } from \"@chevrotain/utils\";\nimport { ASTNode, getRegExpAst } from \"./reg_exp_parser.js\";\nimport { charCodeToOptimizedIndex, minOptimizationVal } from \"./lexer.js\";\n\nconst complementErrorMessage =\n  \"Complement Sets are not supported for first char optimization\";\nexport const failedOptimizationPrefixMsg =\n  'Unable to use \"first char\" lexer optimizations:\\n';\n\nexport function getOptimizedStartCodesIndices(\n  regExp: RegExp,\n  ensureOptimizations = false,\n): number[] {\n  try {\n    const ast = getRegExpAst(regExp);\n    const firstChars = firstCharOptimizedIndices(\n      ast.value,\n      {},\n      ast.flags.ignoreCase,\n    );\n    return firstChars;\n  } catch (e) {\n    /* istanbul ignore next */\n    // Testing this relies on the regexp-to-ast library having a bug... */\n    // TODO: only the else branch needs to be ignored, try to fix with newer prettier / tsc\n    if (e.message === complementErrorMessage) {\n      if (ensureOptimizations) {\n        PRINT_WARNING(\n          `${failedOptimizationPrefixMsg}` +\n            `\\tUnable to optimize: < ${regExp.toString()} >\\n` +\n            \"\\tComplement Sets cannot be automatically optimized.\\n\" +\n            \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n            \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#COMPLEMENT for details.\",\n        );\n      }\n    } else {\n      let msgSuffix = \"\";\n      if (ensureOptimizations) {\n        msgSuffix =\n          \"\\n\\tThis will disable the lexer's first char optimizations.\\n\" +\n          \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#REGEXP_PARSING for details.\";\n      }\n      PRINT_ERROR(\n        `${failedOptimizationPrefixMsg}\\n` +\n          `\\tFailed parsing: < ${regExp.toString()} >\\n` +\n          `\\tUsing the @chevrotain/regexp-to-ast library\\n` +\n          \"\\tPlease open an issue at: https://github.com/chevrotain/chevrotain/issues\" +\n          msgSuffix,\n      );\n    }\n  }\n\n  return [];\n}\n\nexport function firstCharOptimizedIndices(\n  ast: ASTNode,\n  result: { [charCode: number]: number },\n  ignoreCase: boolean,\n): number[] {\n  switch (ast.type) {\n    case \"Disjunction\":\n      for (let i = 0; i < ast.value.length; i++) {\n        firstCharOptimizedIndices(ast.value[i], result, ignoreCase);\n      }\n      break;\n    case \"Alternative\":\n      const terms = ast.value;\n      for (let i = 0; i < terms.length; i++) {\n        const term = terms[i];\n\n        // skip terms that cannot effect the first char results\n        switch (term.type) {\n          case \"EndAnchor\":\n          // A group back reference cannot affect potential starting char.\n          // because if a back reference is the first production than automatically\n          // the group being referenced has had to come BEFORE so its codes have already been added\n          case \"GroupBackReference\":\n          // assertions do not affect potential starting codes\n          case \"Lookahead\":\n          case \"NegativeLookahead\":\n          case \"StartAnchor\":\n          case \"WordBoundary\":\n          case \"NonWordBoundary\":\n            continue;\n        }\n\n        const atom = term;\n        switch (atom.type) {\n          case \"Character\":\n            addOptimizedIdxToResult(atom.value, result, ignoreCase);\n            break;\n          case \"Set\":\n            if (atom.complement === true) {\n              throw Error(complementErrorMessage);\n            }\n            forEach(atom.value, (code) => {\n              if (typeof code === \"number\") {\n                addOptimizedIdxToResult(code, result, ignoreCase);\n              } else {\n                // range\n                const range = code as any;\n                // cannot optimize when ignoreCase is\n                if (ignoreCase === true) {\n                  for (\n                    let rangeCode = range.from;\n                    rangeCode <= range.to;\n                    rangeCode++\n                  ) {\n                    addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                  }\n                }\n                // Optimization (2 orders of magnitude less work for very large ranges)\n                else {\n                  // handle unoptimized values\n                  for (\n                    let rangeCode = range.from;\n                    rangeCode <= range.to && rangeCode < minOptimizationVal;\n                    rangeCode++\n                  ) {\n                    addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                  }\n\n                  // Less common charCode where we optimize for faster init time, by using larger \"buckets\"\n                  if (range.to >= minOptimizationVal) {\n                    const minUnOptVal =\n                      range.from >= minOptimizationVal\n                        ? range.from\n                        : minOptimizationVal;\n                    const maxUnOptVal = range.to;\n                    const minOptIdx = charCodeToOptimizedIndex(minUnOptVal);\n                    const maxOptIdx = charCodeToOptimizedIndex(maxUnOptVal);\n\n                    for (\n                      let currOptIdx = minOptIdx;\n                      currOptIdx <= maxOptIdx;\n                      currOptIdx++\n                    ) {\n                      result[currOptIdx] = currOptIdx;\n                    }\n                  }\n                }\n              }\n            });\n            break;\n          case \"Group\":\n            firstCharOptimizedIndices(atom.value, result, ignoreCase);\n            break;\n          /* istanbul ignore next */\n          default:\n            throw Error(\"Non Exhaustive Match\");\n        }\n\n        // reached a mandatory production, no more **start** codes can be found on this alternative\n        const isOptionalQuantifier =\n          atom.quantifier !== undefined && atom.quantifier.atLeast === 0;\n        if (\n          // A group may be optional due to empty contents /(?:)/\n          // or if everything inside it is optional /((a)?)/\n          (atom.type === \"Group\" && isWholeOptional(atom) === false) ||\n          // If this term is not a group it may only be optional if it has an optional quantifier\n          (atom.type !== \"Group\" && isOptionalQuantifier === false)\n        ) {\n          break;\n        }\n      }\n      break;\n    /* istanbul ignore next */\n    default:\n      throw Error(\"non exhaustive match!\");\n  }\n\n  // console.log(Object.keys(result).length)\n  return values(result);\n}\n\nfunction addOptimizedIdxToResult(\n  code: number,\n  result: { [charCode: number]: number },\n  ignoreCase: boolean,\n) {\n  const optimizedCharIdx = charCodeToOptimizedIndex(code);\n  result[optimizedCharIdx] = optimizedCharIdx;\n\n  if (ignoreCase === true) {\n    handleIgnoreCase(code, result);\n  }\n}\n\nfunction handleIgnoreCase(\n  code: number,\n  result: { [charCode: number]: number },\n) {\n  const char = String.fromCharCode(code);\n  const upperChar = char.toUpperCase();\n  /* istanbul ignore else */\n  if (upperChar !== char) {\n    const optimizedCharIdx = charCodeToOptimizedIndex(upperChar.charCodeAt(0));\n    result[optimizedCharIdx] = optimizedCharIdx;\n  } else {\n    const lowerChar = char.toLowerCase();\n    if (lowerChar !== char) {\n      const optimizedCharIdx = charCodeToOptimizedIndex(\n        lowerChar.charCodeAt(0),\n      );\n      result[optimizedCharIdx] = optimizedCharIdx;\n    }\n  }\n}\n\nfunction findCode(setNode: Set, targetCharCodes: number[]) {\n  return find(setNode.value, (codeOrRange) => {\n    if (typeof codeOrRange === \"number\") {\n      return includes(targetCharCodes, codeOrRange);\n    } else {\n      // range\n      const range = <any>codeOrRange;\n      return (\n        find(\n          targetCharCodes,\n          (targetCode) => range.from <= targetCode && targetCode <= range.to,\n        ) !== undefined\n      );\n    }\n  });\n}\n\nfunction isWholeOptional(ast: any): boolean {\n  const quantifier = (ast as Atom).quantifier;\n  if (quantifier && quantifier.atLeast === 0) {\n    return true;\n  }\n\n  if (!ast.value) {\n    return false;\n  }\n\n  return isArray(ast.value)\n    ? every(ast.value, isWholeOptional)\n    : isWholeOptional(ast.value);\n}\n\nclass CharCodeFinder extends BaseRegExpVisitor {\n  found: boolean = false;\n\n  constructor(private targetCharCodes: number[]) {\n    super();\n  }\n\n  visitChildren(node: ASTNode) {\n    // No need to keep looking...\n    if (this.found === true) {\n      return;\n    }\n\n    // switch lookaheads as they do not actually consume any characters thus\n    // finding a charCode at lookahead context does not mean that regexp can actually contain it in a match.\n    switch (node.type) {\n      case \"Lookahead\":\n        this.visitLookahead(node);\n        return;\n      case \"NegativeLookahead\":\n        this.visitNegativeLookahead(node);\n        return;\n    }\n\n    super.visitChildren(node);\n  }\n\n  visitCharacter(node: Character) {\n    if (includes(this.targetCharCodes, node.value)) {\n      this.found = true;\n    }\n  }\n\n  visitSet(node: Set) {\n    if (node.complement) {\n      if (findCode(node, this.targetCharCodes) === undefined) {\n        this.found = true;\n      }\n    } else {\n      if (findCode(node, this.targetCharCodes) !== undefined) {\n        this.found = true;\n      }\n    }\n  }\n}\n\nexport function canMatchCharCode(\n  charCodes: number[],\n  pattern: RegExp | string,\n) {\n  if (pattern instanceof RegExp) {\n    const ast = getRegExpAst(pattern);\n    const charCodeFinder = new CharCodeFinder(charCodes);\n    charCodeFinder.visit(ast);\n    return charCodeFinder.found;\n  } else {\n    return (\n      find(<any>pattern, (char) => {\n        return includes(charCodes, (<string>char).charCodeAt(0));\n      }) !== undefined\n    );\n  }\n}\n","import {\n  Alternative,\n  Assertion,\n  Atom,\n  Disjunction,\n  RegExpParser,\n  RegExpPattern,\n} from \"@chevrotain/regexp-to-ast\";\n\nlet regExpAstCache: { [regex: string]: RegExpPattern } = {};\nconst regExpParser = new RegExpParser();\n\n// this should be moved to regexp-to-ast\nexport type ASTNode =\n  | RegExpPattern\n  | Disjunction\n  | Alternative\n  | Assertion\n  | Atom;\n\nexport function getRegExpAst(regExp: RegExp): RegExpPattern {\n  const regExpStr = regExp.toString();\n  if (regExpAstCache.hasOwnProperty(regExpStr)) {\n    return regExpAstCache[regExpStr];\n  } else {\n    const regExpAst = regExpParser.pattern(regExpStr);\n    regExpAstCache[regExpStr] = regExpAst;\n    return regExpAst;\n  }\n}\n\nexport function clearRegExpParserCache() {\n  regExpAstCache = {};\n}\n","import {\n  analyzeTokenTypes,\n  charCodeToOptimizedIndex,\n  cloneEmptyGroups,\n  DEFAULT_MODE,\n  IAnalyzeResult,\n  IPatternConfig,\n  LineTerminatorOptimizedTester,\n  performRuntimeChecks,\n  performWarningRuntimeChecks,\n  SUPPORT_STICKY,\n  validatePatterns,\n} from \"./lexer.js\";\nimport {\n  assign,\n  clone,\n  forEach,\n  identity,\n  isArray,\n  isEmpty,\n  isUndefined,\n  keys,\n  last,\n  map,\n  noop,\n  reduce,\n  reject,\n} from \"lodash-es\";\nimport { PRINT_WARNING, timer, toFastProperties } from \"@chevrotain/utils\";\nimport { augmentTokenTypes } from \"./tokens.js\";\nimport {\n  CustomPatternMatcherFunc,\n  CustomPatternMatcherReturn,\n  ILexerConfig,\n  ILexerDefinitionError,\n  ILexingError,\n  IMultiModeLexerDefinition,\n  IToken,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { defaultLexerErrorProvider } from \"./lexer_errors_public.js\";\nimport { clearRegExpParserCache } from \"./reg_exp_parser.js\";\n\nexport interface ILexingResult {\n  tokens: IToken[];\n  groups: { [groupName: string]: IToken[] };\n  errors: ILexingError[];\n}\n\nexport enum LexerDefinitionErrorType {\n  MISSING_PATTERN,\n  INVALID_PATTERN,\n  EOI_ANCHOR_FOUND,\n  UNSUPPORTED_FLAGS_FOUND,\n  DUPLICATE_PATTERNS_FOUND,\n  INVALID_GROUP_TYPE_FOUND,\n  PUSH_MODE_DOES_NOT_EXIST,\n  MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE,\n  MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY,\n  MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST,\n  LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED,\n  SOI_ANCHOR_FOUND,\n  EMPTY_MATCH_PATTERN,\n  NO_LINE_BREAKS_FLAGS,\n  UNREACHABLE_PATTERN,\n  IDENTIFY_TERMINATOR,\n  CUSTOM_LINE_BREAK,\n  MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE,\n}\n\nexport interface IRegExpExec {\n  exec: CustomPatternMatcherFunc;\n}\n\nconst DEFAULT_LEXER_CONFIG: Required<ILexerConfig> = {\n  deferDefinitionErrorsHandling: false,\n  positionTracking: \"full\",\n  lineTerminatorsPattern: /\\n|\\r\\n?/g,\n  lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n  ensureOptimizations: false,\n  safeMode: false,\n  errorMessageProvider: defaultLexerErrorProvider,\n  traceInitPerf: false,\n  skipValidations: false,\n  recoveryEnabled: true,\n};\n\nObject.freeze(DEFAULT_LEXER_CONFIG);\n\nexport class Lexer {\n  public static SKIPPED =\n    \"This marks a skipped Token pattern, this means each token identified by it will\" +\n    \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\n\n  public static NA = /NOT_APPLICABLE/;\n  public lexerDefinitionErrors: ILexerDefinitionError[] = [];\n  public lexerDefinitionWarning: ILexerDefinitionError[] = [];\n\n  protected patternIdxToConfig: Record<string, IPatternConfig[]> = {};\n  protected charCodeToPatternIdxToConfig: {\n    [modeName: string]: { [charCode: number]: IPatternConfig[] };\n  } = {};\n\n  protected modes: string[] = [];\n  protected defaultMode!: string;\n  protected emptyGroups: { [groupName: string]: IToken } = {};\n\n  private config: Required<ILexerConfig>;\n  private trackStartLines: boolean = true;\n  private trackEndLines: boolean = true;\n  private hasCustom: boolean = false;\n  private canModeBeOptimized: Record<string, boolean> = {};\n\n  private traceInitPerf!: boolean | number;\n  private traceInitMaxIdent!: number;\n  private traceInitIndent: number;\n\n  constructor(\n    protected lexerDefinition: TokenType[] | IMultiModeLexerDefinition,\n    config: ILexerConfig = DEFAULT_LEXER_CONFIG,\n  ) {\n    if (typeof config === \"boolean\") {\n      throw Error(\n        \"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" +\n          \"a boolean 2nd argument is no longer supported\",\n      );\n    }\n\n    // todo: defaults func?\n    this.config = assign({}, DEFAULT_LEXER_CONFIG, config) as any;\n\n    const traceInitVal = this.config.traceInitPerf;\n    if (traceInitVal === true) {\n      this.traceInitMaxIdent = Infinity;\n      this.traceInitPerf = true;\n    } else if (typeof traceInitVal === \"number\") {\n      this.traceInitMaxIdent = traceInitVal;\n      this.traceInitPerf = true;\n    }\n    this.traceInitIndent = -1;\n\n    this.TRACE_INIT(\"Lexer Constructor\", () => {\n      let actualDefinition!: IMultiModeLexerDefinition;\n      let hasOnlySingleMode = true;\n      this.TRACE_INIT(\"Lexer Config handling\", () => {\n        if (\n          this.config.lineTerminatorsPattern ===\n          DEFAULT_LEXER_CONFIG.lineTerminatorsPattern\n        ) {\n          // optimized built-in implementation for the defaults definition of lineTerminators\n          this.config.lineTerminatorsPattern = LineTerminatorOptimizedTester;\n        } else {\n          if (\n            this.config.lineTerminatorCharacters ===\n            DEFAULT_LEXER_CONFIG.lineTerminatorCharacters\n          ) {\n            throw Error(\n              \"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" +\n                \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\",\n            );\n          }\n        }\n\n        if (config.safeMode && config.ensureOptimizations) {\n          throw Error(\n            '\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.',\n          );\n        }\n\n        this.trackStartLines = /full|onlyStart/i.test(\n          this.config.positionTracking,\n        );\n        this.trackEndLines = /full/i.test(this.config.positionTracking);\n\n        // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n        if (isArray(lexerDefinition)) {\n          actualDefinition = {\n            modes: { defaultMode: clone(lexerDefinition) },\n            defaultMode: DEFAULT_MODE,\n          };\n        } else {\n          // no conversion needed, input should already be a IMultiModeLexerDefinition\n          hasOnlySingleMode = false;\n          actualDefinition = clone(<IMultiModeLexerDefinition>lexerDefinition);\n        }\n      });\n\n      if (this.config.skipValidations === false) {\n        this.TRACE_INIT(\"performRuntimeChecks\", () => {\n          this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(\n            performRuntimeChecks(\n              actualDefinition,\n              this.trackStartLines,\n              this.config.lineTerminatorCharacters,\n            ),\n          );\n        });\n\n        this.TRACE_INIT(\"performWarningRuntimeChecks\", () => {\n          this.lexerDefinitionWarning = this.lexerDefinitionWarning.concat(\n            performWarningRuntimeChecks(\n              actualDefinition,\n              this.trackStartLines,\n              this.config.lineTerminatorCharacters,\n            ),\n          );\n        });\n      }\n\n      // for extra robustness to avoid throwing an none informative error message\n      actualDefinition.modes = actualDefinition.modes\n        ? actualDefinition.modes\n        : {};\n\n      // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n      // this transformation is to increase robustness in the case of partially invalid lexer definition.\n      forEach(actualDefinition.modes, (currModeValue, currModeName) => {\n        actualDefinition.modes[currModeName] = reject<TokenType>(\n          currModeValue,\n          (currTokType) => isUndefined(currTokType),\n        );\n      });\n\n      const allModeNames = keys(actualDefinition.modes);\n\n      forEach(\n        actualDefinition.modes,\n        (currModDef: TokenType[], currModName) => {\n          this.TRACE_INIT(`Mode: <${currModName}> processing`, () => {\n            this.modes.push(currModName);\n\n            if (this.config.skipValidations === false) {\n              this.TRACE_INIT(`validatePatterns`, () => {\n                this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(\n                  validatePatterns(currModDef, allModeNames),\n                );\n              });\n            }\n\n            // If definition errors were encountered, the analysis phase may fail unexpectedly/\n            // Considering a lexer with definition errors may never be used, there is no point\n            // to performing the analysis anyhow...\n            if (isEmpty(this.lexerDefinitionErrors)) {\n              augmentTokenTypes(currModDef);\n\n              let currAnalyzeResult!: IAnalyzeResult;\n              this.TRACE_INIT(`analyzeTokenTypes`, () => {\n                currAnalyzeResult = analyzeTokenTypes(currModDef, {\n                  lineTerminatorCharacters:\n                    this.config.lineTerminatorCharacters,\n                  positionTracking: config.positionTracking,\n                  ensureOptimizations: config.ensureOptimizations,\n                  safeMode: config.safeMode,\n                  tracer: this.TRACE_INIT,\n                });\n              });\n\n              this.patternIdxToConfig[currModName] =\n                currAnalyzeResult.patternIdxToConfig;\n\n              this.charCodeToPatternIdxToConfig[currModName] =\n                currAnalyzeResult.charCodeToPatternIdxToConfig;\n\n              this.emptyGroups = assign(\n                {},\n                this.emptyGroups,\n                currAnalyzeResult.emptyGroups,\n              ) as any;\n\n              this.hasCustom = currAnalyzeResult.hasCustom || this.hasCustom;\n\n              this.canModeBeOptimized[currModName] =\n                currAnalyzeResult.canBeOptimized;\n            }\n          });\n        },\n      );\n\n      this.defaultMode = actualDefinition.defaultMode;\n\n      if (\n        !isEmpty(this.lexerDefinitionErrors) &&\n        !this.config.deferDefinitionErrorsHandling\n      ) {\n        const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n          return error.message;\n        });\n        const allErrMessagesString = allErrMessages.join(\n          \"-----------------------\\n\",\n        );\n        throw new Error(\n          \"Errors detected in definition of Lexer:\\n\" + allErrMessagesString,\n        );\n      }\n\n      // Only print warning if there are no errors, This will avoid pl\n      forEach(this.lexerDefinitionWarning, (warningDescriptor) => {\n        PRINT_WARNING(warningDescriptor.message);\n      });\n\n      this.TRACE_INIT(\"Choosing sub-methods implementations\", () => {\n        // Choose the relevant internal implementations for this specific parser.\n        // These implementations should be in-lined by the JavaScript engine\n        // to provide optimal performance in each scenario.\n        if (SUPPORT_STICKY) {\n          this.chopInput = <any>identity;\n          this.match = this.matchWithTest;\n        } else {\n          this.updateLastIndex = noop;\n          this.match = this.matchWithExec;\n        }\n\n        if (hasOnlySingleMode) {\n          this.handleModes = noop;\n        }\n\n        if (this.trackStartLines === false) {\n          this.computeNewColumn = identity;\n        }\n\n        if (this.trackEndLines === false) {\n          this.updateTokenEndLineColumnLocation = noop;\n        }\n\n        if (/full/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createFullToken;\n        } else if (/onlyStart/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createStartOnlyToken;\n        } else if (/onlyOffset/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createOffsetOnlyToken;\n        } else {\n          throw Error(\n            `Invalid <positionTracking> config option: \"${this.config.positionTracking}\"`,\n          );\n        }\n\n        if (this.hasCustom) {\n          this.addToken = this.addTokenUsingPush;\n          this.handlePayload = this.handlePayloadWithCustom;\n        } else {\n          this.addToken = this.addTokenUsingMemberAccess;\n          this.handlePayload = this.handlePayloadNoCustom;\n        }\n      });\n\n      this.TRACE_INIT(\"Failed Optimization Warnings\", () => {\n        const unOptimizedModes = reduce(\n          this.canModeBeOptimized,\n          (cannotBeOptimized, canBeOptimized, modeName) => {\n            if (canBeOptimized === false) {\n              cannotBeOptimized.push(modeName);\n            }\n            return cannotBeOptimized;\n          },\n          [] as string[],\n        );\n\n        if (config.ensureOptimizations && !isEmpty(unOptimizedModes)) {\n          throw Error(\n            `Lexer Modes: < ${unOptimizedModes.join(\n              \", \",\n            )} > cannot be optimized.\\n` +\n              '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' +\n              \"\\t Or inspect the console log for details on how to resolve these issues.\",\n          );\n        }\n      });\n\n      this.TRACE_INIT(\"clearRegExpParserCache\", () => {\n        clearRegExpParserCache();\n      });\n\n      this.TRACE_INIT(\"toFastProperties\", () => {\n        toFastProperties(this);\n      });\n    });\n  }\n\n  public tokenize(\n    text: string,\n    initialMode: string = this.defaultMode,\n  ): ILexingResult {\n    if (!isEmpty(this.lexerDefinitionErrors)) {\n      const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n        return error.message;\n      });\n      const allErrMessagesString = allErrMessages.join(\n        \"-----------------------\\n\",\n      );\n      throw new Error(\n        \"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" +\n          allErrMessagesString,\n      );\n    }\n\n    return this.tokenizeInternal(text, initialMode);\n  }\n\n  // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n  // This is intentional due to performance considerations.\n  // this method also used quite a bit of `!` none null assertions because it is too optimized\n  // for `tsc` to always understand it is \"safe\"\n  private tokenizeInternal(text: string, initialMode: string): ILexingResult {\n    let i,\n      j,\n      k,\n      matchAltImage,\n      longerAlt,\n      matchedImage: string | null,\n      payload,\n      altPayload,\n      imageLength,\n      group,\n      tokType,\n      newToken: IToken,\n      errLength,\n      droppedChar,\n      msg,\n      match;\n    const orgText = text;\n    const orgLength = orgText.length;\n    let offset = 0;\n    let matchedTokensIndex = 0;\n    // initializing the tokensArray to the \"guessed\" size.\n    // guessing too little will still reduce the number of array re-sizes on pushes.\n    // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n    // but would still have a faster runtime by avoiding (All but one) array resizing.\n    const guessedNumberOfTokens = this.hasCustom\n      ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n      : Math.floor(text.length / 10);\n    const matchedTokens = new Array(guessedNumberOfTokens);\n    const errors: ILexingError[] = [];\n    let line = this.trackStartLines ? 1 : undefined;\n    let column = this.trackStartLines ? 1 : undefined;\n    const groups: any = cloneEmptyGroups(this.emptyGroups);\n    const trackLines = this.trackStartLines;\n    const lineTerminatorPattern = this.config.lineTerminatorsPattern;\n\n    let currModePatternsLength = 0;\n    let patternIdxToConfig: IPatternConfig[] = [];\n    let currCharCodeToPatternIdxToConfig: {\n      [charCode: number]: IPatternConfig[];\n    } = [];\n\n    const modeStack: string[] = [];\n\n    const emptyArray: IPatternConfig[] = [];\n    Object.freeze(emptyArray);\n    let getPossiblePatterns!: (charCode: number) => IPatternConfig[];\n\n    function getPossiblePatternsSlow() {\n      return patternIdxToConfig;\n    }\n\n    function getPossiblePatternsOptimized(charCode: number): IPatternConfig[] {\n      const optimizedCharIdx = charCodeToOptimizedIndex(charCode);\n      const possiblePatterns =\n        currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n      if (possiblePatterns === undefined) {\n        return emptyArray;\n      } else {\n        return possiblePatterns;\n      }\n    }\n\n    const pop_mode = (popToken: IToken) => {\n      // TODO: perhaps avoid this error in the edge case there is no more input?\n      if (\n        modeStack.length === 1 &&\n        // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n        // So no error should occur.\n        popToken.tokenType.PUSH_MODE === undefined\n      ) {\n        // if we try to pop the last mode there lexer will no longer have ANY mode.\n        // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n        const msg =\n          this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(\n            popToken,\n          );\n\n        errors.push({\n          offset: popToken.startOffset,\n          line: popToken.startLine,\n          column: popToken.startColumn,\n          length: popToken.image.length,\n          message: msg,\n        });\n      } else {\n        modeStack.pop();\n        const newMode = last(modeStack)!;\n        patternIdxToConfig = this.patternIdxToConfig[newMode];\n        currCharCodeToPatternIdxToConfig =\n          this.charCodeToPatternIdxToConfig[newMode];\n        currModePatternsLength = patternIdxToConfig.length;\n        const modeCanBeOptimized =\n          this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n\n        if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n          getPossiblePatterns = getPossiblePatternsOptimized;\n        } else {\n          getPossiblePatterns = getPossiblePatternsSlow;\n        }\n      }\n    };\n\n    function push_mode(this: Lexer, newMode: string) {\n      modeStack.push(newMode);\n      currCharCodeToPatternIdxToConfig =\n        this.charCodeToPatternIdxToConfig[newMode];\n\n      patternIdxToConfig = this.patternIdxToConfig[newMode];\n      currModePatternsLength = patternIdxToConfig.length;\n\n      currModePatternsLength = patternIdxToConfig.length;\n      const modeCanBeOptimized =\n        this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n\n      if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n        getPossiblePatterns = getPossiblePatternsOptimized;\n      } else {\n        getPossiblePatterns = getPossiblePatternsSlow;\n      }\n    }\n\n    // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n    // seem to matter performance wise.\n    push_mode.call(this, initialMode);\n\n    let currConfig!: IPatternConfig;\n\n    const recoveryEnabled = this.config.recoveryEnabled;\n\n    while (offset < orgLength) {\n      matchedImage = null;\n\n      const nextCharCode = orgText.charCodeAt(offset);\n      const chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n      const chosenPatternsLength = chosenPatternIdxToConfig.length;\n\n      for (i = 0; i < chosenPatternsLength; i++) {\n        currConfig = chosenPatternIdxToConfig[i];\n        const currPattern = currConfig.pattern;\n        payload = null;\n\n        // manually in-lined because > 600 chars won't be in-lined in V8\n        const singleCharCode = currConfig.short;\n        if (singleCharCode !== false) {\n          if (nextCharCode === singleCharCode) {\n            // single character string\n            matchedImage = currPattern as string;\n          }\n        } else if (currConfig.isCustom === true) {\n          match = (currPattern as IRegExpExec).exec(\n            orgText,\n            offset,\n            matchedTokens,\n            groups,\n          );\n          if (match !== null) {\n            matchedImage = match[0];\n            if ((match as CustomPatternMatcherReturn).payload !== undefined) {\n              payload = (match as CustomPatternMatcherReturn).payload;\n            }\n          } else {\n            matchedImage = null;\n          }\n        } else {\n          this.updateLastIndex(currPattern as RegExp, offset);\n          matchedImage = this.match(currPattern as RegExp, text, offset);\n        }\n\n        if (matchedImage !== null) {\n          // even though this pattern matched we must try a another longer alternative.\n          // this can be used to prioritize keywords over identifiers\n          longerAlt = currConfig.longerAlt;\n          if (longerAlt !== undefined) {\n            // TODO: micro optimize, avoid extra prop access\n            // by saving/linking longerAlt on the original config?\n            const longerAltLength = longerAlt.length;\n            for (k = 0; k < longerAltLength; k++) {\n              const longerAltConfig = patternIdxToConfig[longerAlt[k]];\n              const longerAltPattern = longerAltConfig.pattern;\n              altPayload = null;\n\n              // single Char can never be a longer alt so no need to test it.\n              // manually in-lined because > 600 chars won't be in-lined in V8\n              if (longerAltConfig.isCustom === true) {\n                match = (longerAltPattern as IRegExpExec).exec(\n                  orgText,\n                  offset,\n                  matchedTokens,\n                  groups,\n                );\n                if (match !== null) {\n                  matchAltImage = match[0];\n                  if (\n                    (match as CustomPatternMatcherReturn).payload !== undefined\n                  ) {\n                    altPayload = (match as CustomPatternMatcherReturn).payload;\n                  }\n                } else {\n                  matchAltImage = null;\n                }\n              } else {\n                this.updateLastIndex(longerAltPattern as RegExp, offset);\n                matchAltImage = this.match(\n                  longerAltPattern as RegExp,\n                  text,\n                  offset,\n                );\n              }\n\n              if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                matchedImage = matchAltImage;\n                payload = altPayload;\n                currConfig = longerAltConfig;\n                // Exit the loop early after matching one of the longer alternatives\n                // The first matched alternative takes precedence\n                break;\n              }\n            }\n          }\n          break;\n        }\n      }\n\n      // successful match\n      if (matchedImage !== null) {\n        imageLength = matchedImage.length;\n        group = currConfig.group;\n        if (group !== undefined) {\n          tokType = currConfig.tokenTypeIdx;\n          // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n          // createFullToken method\n          newToken = this.createTokenInstance(\n            matchedImage,\n            offset,\n            tokType,\n            currConfig.tokenType,\n            line,\n            column,\n            imageLength,\n          );\n\n          this.handlePayload(newToken, payload);\n\n          // TODO: optimize NOOP in case there are no special groups?\n          if (group === false) {\n            matchedTokensIndex = this.addToken(\n              matchedTokens,\n              matchedTokensIndex,\n              newToken,\n            );\n          } else {\n            groups[group].push(newToken);\n          }\n        }\n        text = this.chopInput(text, imageLength);\n        offset = offset + imageLength;\n\n        // TODO: with newlines the column may be assigned twice\n        column = this.computeNewColumn(column!, imageLength);\n\n        if (trackLines === true && currConfig.canLineTerminator === true) {\n          let numOfLTsInMatch = 0;\n          let foundTerminator;\n          let lastLTEndOffset: number;\n          lineTerminatorPattern.lastIndex = 0;\n          do {\n            foundTerminator = lineTerminatorPattern.test(matchedImage);\n            if (foundTerminator === true) {\n              lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n              numOfLTsInMatch++;\n            }\n          } while (foundTerminator === true);\n\n          if (numOfLTsInMatch !== 0) {\n            line = line! + numOfLTsInMatch;\n            column = imageLength - lastLTEndOffset!;\n            this.updateTokenEndLineColumnLocation(\n              newToken!,\n              group!,\n              lastLTEndOffset!,\n              numOfLTsInMatch,\n              line,\n              column,\n              imageLength,\n            );\n          }\n        }\n        // will be NOOP if no modes present\n        this.handleModes(currConfig, pop_mode, push_mode, newToken!);\n      } else {\n        // error recovery, drop characters until we identify a valid token's start point\n        const errorStartOffset = offset;\n        const errorLine = line;\n        const errorColumn = column;\n        let foundResyncPoint = recoveryEnabled === false;\n\n        while (foundResyncPoint === false && offset < orgLength) {\n          // Identity Func (when sticky flag is enabled)\n          text = this.chopInput(text, 1);\n          offset++;\n          for (j = 0; j < currModePatternsLength; j++) {\n            const currConfig = patternIdxToConfig[j];\n            const currPattern = currConfig.pattern;\n\n            // manually in-lined because > 600 chars won't be in-lined in V8\n            const singleCharCode = currConfig.short;\n            if (singleCharCode !== false) {\n              if (orgText.charCodeAt(offset) === singleCharCode) {\n                // single character string\n                foundResyncPoint = true;\n              }\n            } else if (currConfig.isCustom === true) {\n              foundResyncPoint =\n                (currPattern as IRegExpExec).exec(\n                  orgText,\n                  offset,\n                  matchedTokens,\n                  groups,\n                ) !== null;\n            } else {\n              this.updateLastIndex(currPattern as RegExp, offset);\n              foundResyncPoint = (currPattern as RegExp).exec(text) !== null;\n            }\n\n            if (foundResyncPoint === true) {\n              break;\n            }\n          }\n        }\n\n        errLength = offset - errorStartOffset;\n        column = this.computeNewColumn(column!, errLength);\n        // at this point we either re-synced or reached the end of the input text\n        msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(\n          orgText,\n          errorStartOffset,\n          errLength,\n          errorLine,\n          errorColumn,\n        );\n        errors.push({\n          offset: errorStartOffset,\n          line: errorLine,\n          column: errorColumn,\n          length: errLength,\n          message: msg,\n        });\n\n        if (recoveryEnabled === false) {\n          break;\n        }\n      }\n    }\n\n    // if we do have custom patterns which push directly into the\n    // TODO: custom tokens should not push directly??\n    if (!this.hasCustom) {\n      // if we guessed a too large size for the tokens array this will shrink it to the right size.\n      matchedTokens.length = matchedTokensIndex;\n    }\n\n    return {\n      tokens: matchedTokens,\n      groups: groups,\n      errors: errors,\n    };\n  }\n\n  private handleModes(\n    config: IPatternConfig,\n    pop_mode: (tok: IToken) => void,\n    push_mode: (this: Lexer, pushMode: string) => void,\n    newToken: IToken,\n  ) {\n    if (config.pop === true) {\n      // need to save the PUSH_MODE property as if the mode is popped\n      // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n      const pushMode = config.push;\n      pop_mode(newToken);\n      if (pushMode !== undefined) {\n        push_mode.call(this, pushMode);\n      }\n    } else if (config.push !== undefined) {\n      push_mode.call(this, config.push);\n    }\n  }\n\n  private chopInput(text: string, length: number): string {\n    return text.substring(length);\n  }\n\n  private updateLastIndex(regExp: RegExp, newLastIndex: number): void {\n    regExp.lastIndex = newLastIndex;\n  }\n\n  // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n  private updateTokenEndLineColumnLocation(\n    newToken: IToken,\n    group: string | false,\n    lastLTIdx: number,\n    numOfLTsInMatch: number,\n    line: number,\n    column: number,\n    imageLength: number,\n  ): void {\n    let lastCharIsLT, fixForEndingInLT;\n    if (group !== undefined) {\n      // a none skipped multi line Token, need to update endLine/endColumn\n      lastCharIsLT = lastLTIdx === imageLength - 1;\n      fixForEndingInLT = lastCharIsLT ? -1 : 0;\n      if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n        // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n        newToken.endLine = line + fixForEndingInLT;\n        // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n        // inclusive to exclusive range.\n        newToken.endColumn = column - 1 + -fixForEndingInLT;\n      }\n      // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n    }\n  }\n\n  private computeNewColumn(oldColumn: number, imageLength: number) {\n    return oldColumn + imageLength;\n  }\n\n  // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n  /* istanbul ignore next - place holder */\n  private createTokenInstance!: (...args: any[]) => IToken;\n\n  private createOffsetOnlyToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n  ) {\n    return {\n      image,\n      startOffset,\n      tokenTypeIdx,\n      tokenType,\n    };\n  }\n\n  private createStartOnlyToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n    startLine: number,\n    startColumn: number,\n  ) {\n    return {\n      image,\n      startOffset,\n      startLine,\n      startColumn,\n      tokenTypeIdx,\n      tokenType,\n    };\n  }\n\n  private createFullToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n    startLine: number,\n    startColumn: number,\n    imageLength: number,\n  ): IToken {\n    return {\n      image,\n      startOffset,\n      endOffset: startOffset + imageLength - 1,\n      startLine,\n      endLine: startLine,\n      startColumn,\n      endColumn: startColumn + imageLength - 1,\n      tokenTypeIdx,\n      tokenType,\n    };\n  }\n\n  // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n  /* istanbul ignore next - place holder */\n  private addToken!: (\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken,\n  ) => number;\n\n  private addTokenUsingPush(\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken,\n  ): number {\n    tokenVector.push(tokenToAdd);\n    return index;\n  }\n\n  private addTokenUsingMemberAccess(\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken,\n  ): number {\n    tokenVector[index] = tokenToAdd;\n    index++;\n    return index;\n  }\n\n  // Place holder, will be replaced by the correct variant according to the hasCustom flag option at runtime.\n  private handlePayload: (token: IToken, payload: any) => void;\n\n  private handlePayloadNoCustom(token: IToken, payload: any): void {}\n\n  private handlePayloadWithCustom(token: IToken, payload: any): void {\n    if (payload !== null) {\n      token.payload = payload;\n    }\n  }\n\n  // place holder to be replaced with chosen alternative at runtime\n  private match!: (\n    pattern: RegExp,\n    text: string,\n    offset: number,\n  ) => string | null;\n\n  private matchWithTest(\n    pattern: RegExp,\n    text: string,\n    offset: number,\n  ): string | null {\n    const found = pattern.test(text);\n    if (found === true) {\n      return text.substring(offset, pattern.lastIndex);\n    }\n    return null;\n  }\n\n  private matchWithExec(pattern: RegExp, text: string): string | null {\n    const regExpArray = pattern.exec(text);\n    return regExpArray !== null ? regExpArray[0] : null;\n  }\n\n  // Duplicated from the parser's perf trace trait to allow future extraction\n  // of the lexer to a separate package.\n  TRACE_INIT = <T>(phaseDesc: string, phaseImpl: () => T): T => {\n    // No need to optimize this using NOOP pattern because\n    // It is not called in a hot spot...\n    if (this.traceInitPerf === true) {\n      this.traceInitIndent++;\n      const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        console.log(`${indent}--> <${phaseDesc}>`);\n      }\n      const { time, value } = timer(phaseImpl);\n      /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n      const traceMethod = time > 10 ? console.warn : console.log;\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n      }\n      this.traceInitIndent--;\n      return value;\n    } else {\n      return phaseImpl();\n    }\n  };\n}\n","import {\n  clone,\n  compact,\n  difference,\n  flatten,\n  forEach,\n  has,\n  includes,\n  isArray,\n  isEmpty,\n  map,\n} from \"lodash-es\";\nimport { IToken, TokenType } from \"@chevrotain/types\";\n\nexport function tokenStructuredMatcher(\n  tokInstance: IToken,\n  tokConstructor: TokenType,\n) {\n  const instanceType = tokInstance.tokenTypeIdx;\n  if (instanceType === tokConstructor.tokenTypeIdx) {\n    return true;\n  } else {\n    return (\n      tokConstructor.isParent === true &&\n      tokConstructor.categoryMatchesMap![instanceType] === true\n    );\n  }\n}\n\n// Optimized tokenMatcher in case our grammar does not use token categories\n// Being so tiny it is much more likely to be in-lined and this avoid the function call overhead\nexport function tokenStructuredMatcherNoCategories(\n  token: IToken,\n  tokType: TokenType,\n) {\n  return token.tokenTypeIdx === tokType.tokenTypeIdx;\n}\n\nexport let tokenShortNameIdx = 1;\nexport const tokenIdxToClass: { [tokenIdx: number]: TokenType } = {};\n\nexport function augmentTokenTypes(tokenTypes: TokenType[]): void {\n  // collect the parent Token Types as well.\n  const tokenTypesAndParents = expandCategories(tokenTypes);\n\n  // add required tokenType and categoryMatches properties\n  assignTokenDefaultProps(tokenTypesAndParents);\n\n  // fill up the categoryMatches\n  assignCategoriesMapProp(tokenTypesAndParents);\n  assignCategoriesTokensProp(tokenTypesAndParents);\n\n  forEach(tokenTypesAndParents, (tokType) => {\n    tokType.isParent = tokType.categoryMatches!.length > 0;\n  });\n}\n\nexport function expandCategories(tokenTypes: TokenType[]): TokenType[] {\n  let result = clone(tokenTypes);\n\n  let categories = tokenTypes;\n  let searching = true;\n  while (searching) {\n    categories = compact(\n      flatten(map(categories, (currTokType) => currTokType.CATEGORIES)),\n    );\n\n    const newCategories = difference(categories, result);\n\n    result = result.concat(newCategories);\n\n    if (isEmpty(newCategories)) {\n      searching = false;\n    } else {\n      categories = newCategories;\n    }\n  }\n  return result;\n}\n\nexport function assignTokenDefaultProps(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    if (!hasShortKeyProperty(currTokType)) {\n      tokenIdxToClass[tokenShortNameIdx] = currTokType;\n      (<any>currTokType).tokenTypeIdx = tokenShortNameIdx++;\n    }\n\n    // CATEGORIES? : TokenType | TokenType[]\n    if (\n      hasCategoriesProperty(currTokType) &&\n      !isArray(currTokType.CATEGORIES)\n      // &&\n      // !isUndefined(currTokType.CATEGORIES.PATTERN)\n    ) {\n      currTokType.CATEGORIES = [currTokType.CATEGORIES as unknown as TokenType];\n    }\n\n    if (!hasCategoriesProperty(currTokType)) {\n      currTokType.CATEGORIES = [];\n    }\n\n    if (!hasExtendingTokensTypesProperty(currTokType)) {\n      currTokType.categoryMatches = [];\n    }\n\n    if (!hasExtendingTokensTypesMapProperty(currTokType)) {\n      currTokType.categoryMatchesMap = {};\n    }\n  });\n}\n\nexport function assignCategoriesTokensProp(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    // avoid duplications\n    currTokType.categoryMatches = [];\n    forEach(currTokType.categoryMatchesMap!, (val, key) => {\n      currTokType.categoryMatches!.push(\n        tokenIdxToClass[key as unknown as number].tokenTypeIdx!,\n      );\n    });\n  });\n}\n\nexport function assignCategoriesMapProp(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    singleAssignCategoriesToksMap([], currTokType);\n  });\n}\n\nexport function singleAssignCategoriesToksMap(\n  path: TokenType[],\n  nextNode: TokenType,\n): void {\n  forEach(path, (pathNode) => {\n    nextNode.categoryMatchesMap![pathNode.tokenTypeIdx!] = true;\n  });\n\n  forEach(nextNode.CATEGORIES, (nextCategory) => {\n    const newPath = path.concat(nextNode);\n    // avoids infinite loops due to cyclic categories.\n    if (!includes(newPath, nextCategory)) {\n      singleAssignCategoriesToksMap(newPath, nextCategory);\n    }\n  });\n}\n\nexport function hasShortKeyProperty(tokType: TokenType): boolean {\n  return has(tokType, \"tokenTypeIdx\");\n}\n\nexport function hasCategoriesProperty(tokType: TokenType): boolean {\n  return has(tokType, \"CATEGORIES\");\n}\n\nexport function hasExtendingTokensTypesProperty(tokType: TokenType): boolean {\n  return has(tokType, \"categoryMatches\");\n}\n\nexport function hasExtendingTokensTypesMapProperty(\n  tokType: TokenType,\n): boolean {\n  return has(tokType, \"categoryMatchesMap\");\n}\n\nexport function isTokenType(tokType: TokenType): boolean {\n  return has(tokType, \"tokenTypeIdx\");\n}\n","import { ILexerErrorMessageProvider, IToken } from \"@chevrotain/types\";\n\nexport const defaultLexerErrorProvider: ILexerErrorMessageProvider = {\n  buildUnableToPopLexerModeMessage(token: IToken): string {\n    return `Unable to pop Lexer Mode after encountering Token ->${token.image}<- The Mode Stack is empty`;\n  },\n\n  buildUnexpectedCharactersMessage(\n    fullText: string,\n    startOffset: number,\n    length: number,\n    line?: number,\n    column?: number,\n  ): string {\n    return (\n      `unexpected character: ->${fullText.charAt(\n        startOffset,\n      )}<- at offset: ${startOffset},` + ` skipped ${length} characters.`\n    );\n  },\n};\n","import { hasTokenLabel, tokenLabel } from \"../scan/tokens_public.js\";\nimport { first, map, reduce } from \"lodash-es\";\nimport {\n  Alternation,\n  getProductionDslName,\n  NonTerminal,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport {\n  IParserErrorMessageProvider,\n  IProductionWithOccurrence,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  IGrammarResolverErrorMessageProvider,\n  IGrammarValidatorErrorMessageProvider,\n} from \"./grammar/types.js\";\n\nexport const defaultParserErrorProvider: IParserErrorMessageProvider = {\n  buildMismatchTokenMessage({ expected, actual, previous, ruleName }): string {\n    const hasLabel = hasTokenLabel(expected);\n    const expectedMsg = hasLabel\n      ? `--> ${tokenLabel(expected)} <--`\n      : `token of type --> ${expected.name} <--`;\n\n    const msg = `Expecting ${expectedMsg} but found --> '${actual.image}' <--`;\n\n    return msg;\n  },\n\n  buildNotAllInputParsedMessage({ firstRedundant, ruleName }): string {\n    return \"Redundant input, expecting EOF but found: \" + firstRedundant.image;\n  },\n\n  buildNoViableAltMessage({\n    expectedPathsPerAlt,\n    actual,\n    previous,\n    customUserDescription,\n    ruleName,\n  }): string {\n    const errPrefix = \"Expecting: \";\n    // TODO: issue: No Viable Alternative Error may have incomplete details. #502\n    const actualText = first(actual)!.image;\n    const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n\n    if (customUserDescription) {\n      return errPrefix + customUserDescription + errSuffix;\n    } else {\n      const allLookAheadPaths = reduce(\n        expectedPathsPerAlt,\n        (result, currAltPaths) => result.concat(currAltPaths),\n        [] as TokenType[][],\n      );\n      const nextValidTokenSequences = map(\n        allLookAheadPaths,\n        (currPath) =>\n          `[${map(currPath, (currTokenType) => tokenLabel(currTokenType)).join(\n            \", \",\n          )}]`,\n      );\n      const nextValidSequenceItems = map(\n        nextValidTokenSequences,\n        (itemMsg, idx) => `  ${idx + 1}. ${itemMsg}`,\n      );\n      const calculatedDescription = `one of these possible Token sequences:\\n${nextValidSequenceItems.join(\n        \"\\n\",\n      )}`;\n\n      return errPrefix + calculatedDescription + errSuffix;\n    }\n  },\n\n  buildEarlyExitMessage({\n    expectedIterationPaths,\n    actual,\n    customUserDescription,\n    ruleName,\n  }): string {\n    const errPrefix = \"Expecting: \";\n    // TODO: issue: No Viable Alternative Error may have incomplete details. #502\n    const actualText = first(actual)!.image;\n    const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n\n    if (customUserDescription) {\n      return errPrefix + customUserDescription + errSuffix;\n    } else {\n      const nextValidTokenSequences = map(\n        expectedIterationPaths,\n        (currPath) =>\n          `[${map(currPath, (currTokenType) => tokenLabel(currTokenType)).join(\n            \",\",\n          )}]`,\n      );\n      const calculatedDescription =\n        `expecting at least one iteration which starts with one of these possible Token sequences::\\n  ` +\n        `<${nextValidTokenSequences.join(\" ,\")}>`;\n\n      return errPrefix + calculatedDescription + errSuffix;\n    }\n  },\n};\n\nObject.freeze(defaultParserErrorProvider);\n\nexport const defaultGrammarResolverErrorProvider: IGrammarResolverErrorMessageProvider =\n  {\n    buildRuleNotFoundError(\n      topLevelRule: Rule,\n      undefinedRule: NonTerminal,\n    ): string {\n      const msg =\n        \"Invalid grammar, reference to a rule which is not defined: ->\" +\n        undefinedRule.nonTerminalName +\n        \"<-\\n\" +\n        \"inside top level rule: ->\" +\n        topLevelRule.name +\n        \"<-\";\n      return msg;\n    },\n  };\n\nexport const defaultGrammarValidatorErrorProvider: IGrammarValidatorErrorMessageProvider =\n  {\n    buildDuplicateFoundError(\n      topLevelRule: Rule,\n      duplicateProds: IProductionWithOccurrence[],\n    ): string {\n      function getExtraProductionArgument(\n        prod: IProductionWithOccurrence,\n      ): string {\n        if (prod instanceof Terminal) {\n          return prod.terminalType.name;\n        } else if (prod instanceof NonTerminal) {\n          return prod.nonTerminalName;\n        } else {\n          return \"\";\n        }\n      }\n\n      const topLevelName = topLevelRule.name;\n      const duplicateProd = first(duplicateProds)!;\n      const index = duplicateProd.idx;\n      const dslName = getProductionDslName(duplicateProd);\n      const extraArgument = getExtraProductionArgument(duplicateProd);\n\n      const hasExplicitIndex = index > 0;\n      let msg = `->${dslName}${hasExplicitIndex ? index : \"\"}<- ${\n        extraArgument ? `with argument: ->${extraArgument}<-` : \"\"\n      }\n                  appears more than once (${\n                    duplicateProds.length\n                  } times) in the top level rule: ->${topLevelName}<-.                  \n                  For further details see: https://chevrotain.io/docs/FAQ.html#NUMERICAL_SUFFIXES \n                  `;\n\n      // white space trimming time! better to trim afterwards as it allows to use WELL formatted multi line template strings...\n      msg = msg.replace(/[ \\t]+/g, \" \");\n      msg = msg.replace(/\\s\\s+/g, \"\\n\");\n\n      return msg;\n    },\n\n    buildNamespaceConflictError(rule: Rule): string {\n      const errMsg =\n        `Namespace conflict found in grammar.\\n` +\n        `The grammar has both a Terminal(Token) and a Non-Terminal(Rule) named: <${rule.name}>.\\n` +\n        `To resolve this make sure each Terminal and Non-Terminal names are unique\\n` +\n        `This is easy to accomplish by using the convention that Terminal names start with an uppercase letter\\n` +\n        `and Non-Terminal names start with a lower case letter.`;\n\n      return errMsg;\n    },\n\n    buildAlternationPrefixAmbiguityError(options: {\n      topLevelRule: Rule;\n      prefixPath: TokenType[];\n      ambiguityIndices: number[];\n      alternation: Alternation;\n    }): string {\n      const pathMsg = map(options.prefixPath, (currTok) =>\n        tokenLabel(currTok),\n      ).join(\", \");\n      const occurrence =\n        options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n      const errMsg =\n        `Ambiguous alternatives: <${options.ambiguityIndices.join(\n          \" ,\",\n        )}> due to common lookahead prefix\\n` +\n        `in <OR${occurrence}> inside <${options.topLevelRule.name}> Rule,\\n` +\n        `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n` +\n        `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#COMMON_PREFIX\\n` +\n        `For Further details.`;\n\n      return errMsg;\n    },\n\n    buildAlternationAmbiguityError(options: {\n      topLevelRule: Rule;\n      prefixPath: TokenType[];\n      ambiguityIndices: number[];\n      alternation: Alternation;\n    }): string {\n      const pathMsg = map(options.prefixPath, (currtok) =>\n        tokenLabel(currtok),\n      ).join(\", \");\n      const occurrence =\n        options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n      let currMessage =\n        `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\n          \" ,\",\n        )}> in <OR${occurrence}>` +\n        ` inside <${options.topLevelRule.name}> Rule,\\n` +\n        `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n`;\n\n      currMessage =\n        currMessage +\n        `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\\n` +\n        `For Further details.`;\n      return currMessage;\n    },\n\n    buildEmptyRepetitionError(options: {\n      topLevelRule: Rule;\n      repetition: IProductionWithOccurrence;\n    }): string {\n      let dslName = getProductionDslName(options.repetition);\n      if (options.repetition.idx !== 0) {\n        dslName += options.repetition.idx;\n      }\n\n      const errMsg =\n        `The repetition <${dslName}> within Rule <${options.topLevelRule.name}> can never consume any tokens.\\n` +\n        `This could lead to an infinite loop.`;\n\n      return errMsg;\n    },\n\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildTokenNameError(options: {\n      tokenType: TokenType;\n      expectedPattern: RegExp;\n    }): string {\n      /* istanbul ignore next */\n      return \"deprecated\";\n    },\n\n    buildEmptyAlternationError(options: {\n      topLevelRule: Rule;\n      alternation: Alternation;\n      emptyChoiceIdx: number;\n    }): string {\n      const errMsg =\n        `Ambiguous empty alternative: <${options.emptyChoiceIdx + 1}>` +\n        ` in <OR${options.alternation.idx}> inside <${options.topLevelRule.name}> Rule.\\n` +\n        `Only the last alternative may be an empty alternative.`;\n\n      return errMsg;\n    },\n\n    buildTooManyAlternativesError(options: {\n      topLevelRule: Rule;\n      alternation: Alternation;\n    }): string {\n      const errMsg =\n        `An Alternation cannot have more than 256 alternatives:\\n` +\n        `<OR${options.alternation.idx}> inside <${\n          options.topLevelRule.name\n        }> Rule.\\n has ${\n          options.alternation.definition.length + 1\n        } alternatives.`;\n\n      return errMsg;\n    },\n\n    buildLeftRecursionError(options: {\n      topLevelRule: Rule;\n      leftRecursionPath: Rule[];\n    }): string {\n      const ruleName = options.topLevelRule.name;\n      const pathNames = map(\n        options.leftRecursionPath,\n        (currRule) => currRule.name,\n      );\n      const leftRecursivePath = `${ruleName} --> ${pathNames\n        .concat([ruleName])\n        .join(\" --> \")}`;\n      const errMsg =\n        `Left Recursion found in grammar.\\n` +\n        `rule: <${ruleName}> can be invoked from itself (directly or indirectly)\\n` +\n        `without consuming any Tokens. The grammar path that causes this is: \\n ${leftRecursivePath}\\n` +\n        ` To fix this refactor your grammar to remove the left recursion.\\n` +\n        `see: https://en.wikipedia.org/wiki/LL_parser#Left_factoring.`;\n\n      return errMsg;\n    },\n\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildInvalidRuleNameError(options: {\n      topLevelRule: Rule;\n      expectedPattern: RegExp;\n    }): string {\n      /* istanbul ignore next */\n      return \"deprecated\";\n    },\n\n    buildDuplicateRuleNameError(options: {\n      topLevelRule: Rule | string;\n      grammarName: string;\n    }): string {\n      let ruleName;\n      if (options.topLevelRule instanceof Rule) {\n        ruleName = options.topLevelRule.name;\n      } else {\n        ruleName = options.topLevelRule;\n      }\n\n      const errMsg = `Duplicate definition, rule: ->${ruleName}<- is already defined in the grammar: ->${options.grammarName}<-`;\n\n      return errMsg;\n    },\n  };\n","import { Rule } from \"@chevrotain/gast\";\nimport { defaults, forEach } from \"lodash-es\";\nimport { resolveGrammar as orgResolveGrammar } from \"../resolver.js\";\nimport { validateGrammar as orgValidateGrammar } from \"../checks.js\";\nimport {\n  defaultGrammarResolverErrorProvider,\n  defaultGrammarValidatorErrorProvider,\n} from \"../../errors_public.js\";\nimport { TokenType } from \"@chevrotain/types\";\nimport {\n  IGrammarResolverErrorMessageProvider,\n  IGrammarValidatorErrorMessageProvider,\n  IParserDefinitionError,\n} from \"../types.js\";\n\ntype ResolveGrammarOpts = {\n  rules: Rule[];\n  errMsgProvider?: IGrammarResolverErrorMessageProvider;\n};\nexport function resolveGrammar(\n  options: ResolveGrammarOpts,\n): IParserDefinitionError[] {\n  const actualOptions: Required<ResolveGrammarOpts> = defaults(options, {\n    errMsgProvider: defaultGrammarResolverErrorProvider,\n  });\n\n  const topRulesTable: { [ruleName: string]: Rule } = {};\n  forEach(options.rules, (rule) => {\n    topRulesTable[rule.name] = rule;\n  });\n  return orgResolveGrammar(topRulesTable, actualOptions.errMsgProvider);\n}\n\nexport function validateGrammar(options: {\n  rules: Rule[];\n  tokenTypes: TokenType[];\n  grammarName: string;\n  errMsgProvider: IGrammarValidatorErrorMessageProvider;\n}): IParserDefinitionError[] {\n  options = defaults(options, {\n    errMsgProvider: defaultGrammarValidatorErrorProvider,\n  });\n\n  return orgValidateGrammar(\n    options.rules,\n    options.tokenTypes,\n    options.errMsgProvider,\n    options.grammarName,\n  );\n}\n","import {\n  IParserUnresolvedRefDefinitionError,\n  ParserDefinitionErrorType,\n} from \"../parser/parser.js\";\nimport { forEach, values } from \"lodash-es\";\nimport { GAstVisitor, NonTerminal, Rule } from \"@chevrotain/gast\";\nimport {\n  IGrammarResolverErrorMessageProvider,\n  IParserDefinitionError,\n} from \"./types.js\";\n\nexport function resolveGrammar(\n  topLevels: Record<string, Rule>,\n  errMsgProvider: IGrammarResolverErrorMessageProvider,\n): IParserDefinitionError[] {\n  const refResolver = new GastRefResolverVisitor(topLevels, errMsgProvider);\n  refResolver.resolveRefs();\n  return refResolver.errors;\n}\n\nexport class GastRefResolverVisitor extends GAstVisitor {\n  public errors: IParserUnresolvedRefDefinitionError[] = [];\n  private currTopLevel: Rule;\n\n  constructor(\n    private nameToTopRule: Record<string, Rule>,\n    private errMsgProvider: IGrammarResolverErrorMessageProvider,\n  ) {\n    super();\n  }\n\n  public resolveRefs(): void {\n    forEach(values(this.nameToTopRule), (prod) => {\n      this.currTopLevel = prod;\n      prod.accept(this);\n    });\n  }\n\n  public visitNonTerminal(node: NonTerminal): void {\n    const ref = this.nameToTopRule[node.nonTerminalName];\n\n    if (!ref) {\n      const msg = this.errMsgProvider.buildRuleNotFoundError(\n        this.currTopLevel,\n        node,\n      );\n      this.errors.push({\n        message: msg,\n        type: ParserDefinitionErrorType.UNRESOLVED_SUBRULE_REF,\n        ruleName: this.currTopLevel.name,\n        unresolvedRefName: node.nonTerminalName,\n      });\n    } else {\n      node.referencedRule = ref;\n    }\n  }\n}\n","import {\n  clone,\n  compact,\n  difference,\n  drop,\n  dropRight,\n  filter,\n  first,\n  flatMap,\n  flatten,\n  forEach,\n  groupBy,\n  includes,\n  isEmpty,\n  map,\n  pickBy,\n  reduce,\n  reject,\n  values,\n} from \"lodash-es\";\nimport {\n  IParserAmbiguousAlternativesDefinitionError,\n  IParserDuplicatesDefinitionError,\n  IParserEmptyAlternativeDefinitionError,\n  ParserDefinitionErrorType,\n} from \"../parser/parser.js\";\nimport {\n  Alternation,\n  Alternative as AlternativeGAST,\n  GAstVisitor,\n  getProductionDslName,\n  isOptionalProd,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport {\n  Alternative,\n  containsPath,\n  getLookaheadPathsForOptionalProd,\n  getLookaheadPathsForOr,\n  getProdType,\n  isStrictPrefixOfPath,\n} from \"./lookahead.js\";\nimport { nextPossibleTokensAfter } from \"./interpreter.js\";\nimport {\n  ILookaheadStrategy,\n  IProduction,\n  IProductionWithOccurrence,\n  Rule,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  IGrammarValidatorErrorMessageProvider,\n  IParserDefinitionError,\n} from \"./types.js\";\nimport { tokenStructuredMatcher } from \"../../scan/tokens.js\";\n\nexport function validateLookahead(options: {\n  lookaheadStrategy: ILookaheadStrategy;\n  rules: Rule[];\n  tokenTypes: TokenType[];\n  grammarName: string;\n}): IParserDefinitionError[] {\n  const lookaheadValidationErrorMessages = options.lookaheadStrategy.validate({\n    rules: options.rules,\n    tokenTypes: options.tokenTypes,\n    grammarName: options.grammarName,\n  });\n  return map(lookaheadValidationErrorMessages, (errorMessage) => ({\n    type: ParserDefinitionErrorType.CUSTOM_LOOKAHEAD_VALIDATION,\n    ...errorMessage,\n  }));\n}\n\nexport function validateGrammar(\n  topLevels: Rule[],\n  tokenTypes: TokenType[],\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n  grammarName: string,\n): IParserDefinitionError[] {\n  const duplicateErrors: IParserDefinitionError[] = flatMap(\n    topLevels,\n    (currTopLevel) =>\n      validateDuplicateProductions(currTopLevel, errMsgProvider),\n  );\n\n  const termsNamespaceConflictErrors = checkTerminalAndNoneTerminalsNameSpace(\n    topLevels,\n    tokenTypes,\n    errMsgProvider,\n  );\n\n  const tooManyAltsErrors = flatMap(topLevels, (curRule) =>\n    validateTooManyAlts(curRule, errMsgProvider),\n  );\n\n  const duplicateRulesError = flatMap(topLevels, (curRule) =>\n    validateRuleDoesNotAlreadyExist(\n      curRule,\n      topLevels,\n      grammarName,\n      errMsgProvider,\n    ),\n  );\n\n  return duplicateErrors.concat(\n    termsNamespaceConflictErrors,\n    tooManyAltsErrors,\n    duplicateRulesError,\n  );\n}\n\nfunction validateDuplicateProductions(\n  topLevelRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDuplicatesDefinitionError[] {\n  const collectorVisitor = new OccurrenceValidationCollector();\n  topLevelRule.accept(collectorVisitor);\n  const allRuleProductions = collectorVisitor.allProductions;\n\n  const productionGroups = groupBy(\n    allRuleProductions,\n    identifyProductionForDuplicates,\n  );\n\n  const duplicates: any = pickBy(productionGroups, (currGroup) => {\n    return currGroup.length > 1;\n  });\n\n  const errors = map(values(duplicates), (currDuplicates: any) => {\n    const firstProd: any = first(currDuplicates);\n    const msg = errMsgProvider.buildDuplicateFoundError(\n      topLevelRule,\n      currDuplicates,\n    );\n    const dslName = getProductionDslName(firstProd);\n    const defError: IParserDuplicatesDefinitionError = {\n      message: msg,\n      type: ParserDefinitionErrorType.DUPLICATE_PRODUCTIONS,\n      ruleName: topLevelRule.name,\n      dslName: dslName,\n      occurrence: firstProd.idx,\n    };\n\n    const param = getExtraProductionArgument(firstProd);\n    if (param) {\n      defError.parameter = param;\n    }\n\n    return defError;\n  });\n  return errors;\n}\n\nexport function identifyProductionForDuplicates(\n  prod: IProductionWithOccurrence,\n): string {\n  return `${getProductionDslName(prod)}_#_${\n    prod.idx\n  }_#_${getExtraProductionArgument(prod)}`;\n}\n\nfunction getExtraProductionArgument(prod: IProductionWithOccurrence): string {\n  if (prod instanceof Terminal) {\n    return prod.terminalType.name;\n  } else if (prod instanceof NonTerminal) {\n    return prod.nonTerminalName;\n  } else {\n    return \"\";\n  }\n}\n\nexport class OccurrenceValidationCollector extends GAstVisitor {\n  public allProductions: IProductionWithOccurrence[] = [];\n\n  public visitNonTerminal(subrule: NonTerminal): void {\n    this.allProductions.push(subrule);\n  }\n\n  public visitOption(option: Option): void {\n    this.allProductions.push(option);\n  }\n\n  public visitRepetitionWithSeparator(manySep: RepetitionWithSeparator): void {\n    this.allProductions.push(manySep);\n  }\n\n  public visitRepetitionMandatory(atLeastOne: RepetitionMandatory): void {\n    this.allProductions.push(atLeastOne);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    atLeastOneSep: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.allProductions.push(atLeastOneSep);\n  }\n\n  public visitRepetition(many: Repetition): void {\n    this.allProductions.push(many);\n  }\n\n  public visitAlternation(or: Alternation): void {\n    this.allProductions.push(or);\n  }\n\n  public visitTerminal(terminal: Terminal): void {\n    this.allProductions.push(terminal);\n  }\n}\n\nexport function validateRuleDoesNotAlreadyExist(\n  rule: Rule,\n  allRules: Rule[],\n  className: string,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const errors = [];\n  const occurrences = reduce(\n    allRules,\n    (result, curRule) => {\n      if (curRule.name === rule.name) {\n        return result + 1;\n      }\n      return result;\n    },\n    0,\n  );\n  if (occurrences > 1) {\n    const errMsg = errMsgProvider.buildDuplicateRuleNameError({\n      topLevelRule: rule,\n      grammarName: className,\n    });\n    errors.push({\n      message: errMsg,\n      type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n      ruleName: rule.name,\n    });\n  }\n\n  return errors;\n}\n\n// TODO: is there anyway to get only the rule names of rules inherited from the super grammars?\n// This is not part of the IGrammarErrorProvider because the validation cannot be performed on\n// The grammar structure, only at runtime.\nexport function validateRuleIsOverridden(\n  ruleName: string,\n  definedRulesNames: string[],\n  className: string,\n): IParserDefinitionError[] {\n  const errors = [];\n  let errMsg;\n\n  if (!includes(definedRulesNames, ruleName)) {\n    errMsg =\n      `Invalid rule override, rule: ->${ruleName}<- cannot be overridden in the grammar: ->${className}<-` +\n      `as it is not defined in any of the super grammars `;\n    errors.push({\n      message: errMsg,\n      type: ParserDefinitionErrorType.INVALID_RULE_OVERRIDE,\n      ruleName: ruleName,\n    });\n  }\n\n  return errors;\n}\n\nexport function validateNoLeftRecursion(\n  topRule: Rule,\n  currRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n  path: Rule[] = [],\n): IParserDefinitionError[] {\n  const errors: IParserDefinitionError[] = [];\n  const nextNonTerminals = getFirstNoneTerminal(currRule.definition);\n  if (isEmpty(nextNonTerminals)) {\n    return [];\n  } else {\n    const ruleName = topRule.name;\n    const foundLeftRecursion = includes(nextNonTerminals, topRule);\n    if (foundLeftRecursion) {\n      errors.push({\n        message: errMsgProvider.buildLeftRecursionError({\n          topLevelRule: topRule,\n          leftRecursionPath: path,\n        }),\n        type: ParserDefinitionErrorType.LEFT_RECURSION,\n        ruleName: ruleName,\n      });\n    }\n\n    // we are only looking for cyclic paths leading back to the specific topRule\n    // other cyclic paths are ignored, we still need this difference to avoid infinite loops...\n    const validNextSteps = difference(nextNonTerminals, path.concat([topRule]));\n    const errorsFromNextSteps = flatMap(validNextSteps, (currRefRule) => {\n      const newPath = clone(path);\n      newPath.push(currRefRule);\n      return validateNoLeftRecursion(\n        topRule,\n        currRefRule,\n        errMsgProvider,\n        newPath,\n      );\n    });\n\n    return errors.concat(errorsFromNextSteps);\n  }\n}\n\nexport function getFirstNoneTerminal(definition: IProduction[]): Rule[] {\n  let result: Rule[] = [];\n  if (isEmpty(definition)) {\n    return result;\n  }\n  const firstProd = first(definition);\n\n  /* istanbul ignore else */\n  if (firstProd instanceof NonTerminal) {\n    result.push(firstProd.referencedRule);\n  } else if (\n    firstProd instanceof AlternativeGAST ||\n    firstProd instanceof Option ||\n    firstProd instanceof RepetitionMandatory ||\n    firstProd instanceof RepetitionMandatoryWithSeparator ||\n    firstProd instanceof RepetitionWithSeparator ||\n    firstProd instanceof Repetition\n  ) {\n    result = result.concat(\n      getFirstNoneTerminal(<IProduction[]>firstProd.definition),\n    );\n  } else if (firstProd instanceof Alternation) {\n    // each sub definition in alternation is a FLAT\n    result = flatten(\n      map(firstProd.definition, (currSubDef) =>\n        getFirstNoneTerminal((<AlternativeGAST>currSubDef).definition),\n      ),\n    );\n  } else if (firstProd instanceof Terminal) {\n    // nothing to see, move along\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n\n  const isFirstOptional = isOptionalProd(firstProd);\n  const hasMore = definition.length > 1;\n  if (isFirstOptional && hasMore) {\n    const rest = drop(definition);\n    return result.concat(getFirstNoneTerminal(rest));\n  } else {\n    return result;\n  }\n}\n\nclass OrCollector extends GAstVisitor {\n  public alternations: Alternation[] = [];\n\n  public visitAlternation(node: Alternation): void {\n    this.alternations.push(node);\n  }\n}\n\nexport function validateEmptyOrAlternative(\n  topLevelRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserEmptyAlternativeDefinitionError[] {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  const ors = orCollector.alternations;\n\n  const errors = flatMap<Alternation, IParserEmptyAlternativeDefinitionError>(\n    ors,\n    (currOr) => {\n      const exceptLast = dropRight(currOr.definition);\n      return flatMap(exceptLast, (currAlternative, currAltIdx) => {\n        const possibleFirstInAlt = nextPossibleTokensAfter(\n          [currAlternative],\n          [],\n          tokenStructuredMatcher,\n          1,\n        );\n        if (isEmpty(possibleFirstInAlt)) {\n          return [\n            {\n              message: errMsgProvider.buildEmptyAlternationError({\n                topLevelRule: topLevelRule,\n                alternation: currOr,\n                emptyChoiceIdx: currAltIdx,\n              }),\n              type: ParserDefinitionErrorType.NONE_LAST_EMPTY_ALT,\n              ruleName: topLevelRule.name,\n              occurrence: currOr.idx,\n              alternative: currAltIdx + 1,\n            },\n          ];\n        } else {\n          return [];\n        }\n      });\n    },\n  );\n\n  return errors;\n}\n\nexport function validateAmbiguousAlternationAlternatives(\n  topLevelRule: Rule,\n  globalMaxLookahead: number,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserAmbiguousAlternativesDefinitionError[] {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  let ors = orCollector.alternations;\n\n  // New Handling of ignoring ambiguities\n  // - https://github.com/chevrotain/chevrotain/issues/869\n  ors = reject(ors, (currOr) => currOr.ignoreAmbiguities === true);\n\n  const errors = flatMap(ors, (currOr: Alternation) => {\n    const currOccurrence = currOr.idx;\n    const actualMaxLookahead = currOr.maxLookahead || globalMaxLookahead;\n    const alternatives = getLookaheadPathsForOr(\n      currOccurrence,\n      topLevelRule,\n      actualMaxLookahead,\n      currOr,\n    );\n    const altsAmbiguityErrors = checkAlternativesAmbiguities(\n      alternatives,\n      currOr,\n      topLevelRule,\n      errMsgProvider,\n    );\n    const altsPrefixAmbiguityErrors = checkPrefixAlternativesAmbiguities(\n      alternatives,\n      currOr,\n      topLevelRule,\n      errMsgProvider,\n    );\n\n    return altsAmbiguityErrors.concat(altsPrefixAmbiguityErrors);\n  });\n\n  return errors;\n}\n\nexport class RepetitionCollector extends GAstVisitor {\n  public allProductions: (IProductionWithOccurrence & {\n    maxLookahead?: number;\n  })[] = [];\n\n  public visitRepetitionWithSeparator(manySep: RepetitionWithSeparator): void {\n    this.allProductions.push(manySep);\n  }\n\n  public visitRepetitionMandatory(atLeastOne: RepetitionMandatory): void {\n    this.allProductions.push(atLeastOne);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    atLeastOneSep: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.allProductions.push(atLeastOneSep);\n  }\n\n  public visitRepetition(many: Repetition): void {\n    this.allProductions.push(many);\n  }\n}\n\nexport function validateTooManyAlts(\n  topLevelRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  const ors = orCollector.alternations;\n\n  const errors = flatMap(ors, (currOr) => {\n    if (currOr.definition.length > 255) {\n      return [\n        {\n          message: errMsgProvider.buildTooManyAlternativesError({\n            topLevelRule: topLevelRule,\n            alternation: currOr,\n          }),\n          type: ParserDefinitionErrorType.TOO_MANY_ALTS,\n          ruleName: topLevelRule.name,\n          occurrence: currOr.idx,\n        },\n      ];\n    } else {\n      return [];\n    }\n  });\n\n  return errors;\n}\n\nexport function validateSomeNonEmptyLookaheadPath(\n  topLevelRules: Rule[],\n  maxLookahead: number,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const errors: IParserDefinitionError[] = [];\n  forEach(topLevelRules, (currTopRule) => {\n    const collectorVisitor = new RepetitionCollector();\n    currTopRule.accept(collectorVisitor);\n    const allRuleProductions = collectorVisitor.allProductions;\n    forEach(allRuleProductions, (currProd) => {\n      const prodType = getProdType(currProd);\n      const actualMaxLookahead = currProd.maxLookahead || maxLookahead;\n      const currOccurrence = currProd.idx;\n      const paths = getLookaheadPathsForOptionalProd(\n        currOccurrence,\n        currTopRule,\n        prodType,\n        actualMaxLookahead,\n      );\n      const pathsInsideProduction = paths[0];\n      if (isEmpty(flatten(pathsInsideProduction))) {\n        const errMsg = errMsgProvider.buildEmptyRepetitionError({\n          topLevelRule: currTopRule,\n          repetition: currProd,\n        });\n        errors.push({\n          message: errMsg,\n          type: ParserDefinitionErrorType.NO_NON_EMPTY_LOOKAHEAD,\n          ruleName: currTopRule.name,\n        });\n      }\n    });\n  });\n\n  return errors;\n}\n\nexport interface IAmbiguityDescriptor {\n  alts: number[];\n  path: TokenType[];\n}\n\nfunction checkAlternativesAmbiguities(\n  alternatives: Alternative[],\n  alternation: Alternation,\n  rule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserAmbiguousAlternativesDefinitionError[] {\n  const foundAmbiguousPaths: Alternative = [];\n  const identicalAmbiguities = reduce(\n    alternatives,\n    (result, currAlt, currAltIdx) => {\n      // ignore (skip) ambiguities with this alternative\n      if (alternation.definition[currAltIdx].ignoreAmbiguities === true) {\n        return result;\n      }\n\n      forEach(currAlt, (currPath) => {\n        const altsCurrPathAppearsIn = [currAltIdx];\n        forEach(alternatives, (currOtherAlt, currOtherAltIdx) => {\n          if (\n            currAltIdx !== currOtherAltIdx &&\n            containsPath(currOtherAlt, currPath) &&\n            // ignore (skip) ambiguities with this \"other\" alternative\n            alternation.definition[currOtherAltIdx].ignoreAmbiguities !== true\n          ) {\n            altsCurrPathAppearsIn.push(currOtherAltIdx);\n          }\n        });\n\n        if (\n          altsCurrPathAppearsIn.length > 1 &&\n          !containsPath(foundAmbiguousPaths, currPath)\n        ) {\n          foundAmbiguousPaths.push(currPath);\n          result.push({\n            alts: altsCurrPathAppearsIn,\n            path: currPath,\n          });\n        }\n      });\n      return result;\n    },\n    [] as { alts: number[]; path: TokenType[] }[],\n  );\n\n  const currErrors = map(identicalAmbiguities, (currAmbDescriptor) => {\n    const ambgIndices = map(\n      currAmbDescriptor.alts,\n      (currAltIdx) => currAltIdx + 1,\n    );\n\n    const currMessage = errMsgProvider.buildAlternationAmbiguityError({\n      topLevelRule: rule,\n      alternation: alternation,\n      ambiguityIndices: ambgIndices,\n      prefixPath: currAmbDescriptor.path,\n    });\n\n    return {\n      message: currMessage,\n      type: ParserDefinitionErrorType.AMBIGUOUS_ALTS,\n      ruleName: rule.name,\n      occurrence: alternation.idx,\n      alternatives: currAmbDescriptor.alts,\n    };\n  });\n\n  return currErrors;\n}\n\nexport function checkPrefixAlternativesAmbiguities(\n  alternatives: Alternative[],\n  alternation: Alternation,\n  rule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserAmbiguousAlternativesDefinitionError[] {\n  // flatten\n  const pathsAndIndices = reduce(\n    alternatives,\n    (result, currAlt, idx) => {\n      const currPathsAndIdx = map(currAlt, (currPath) => {\n        return { idx: idx, path: currPath };\n      });\n      return result.concat(currPathsAndIdx);\n    },\n    [] as { idx: number; path: TokenType[] }[],\n  );\n\n  const errors = compact(\n    flatMap(pathsAndIndices, (currPathAndIdx) => {\n      const alternativeGast = alternation.definition[currPathAndIdx.idx];\n      // ignore (skip) ambiguities with this alternative\n      if (alternativeGast.ignoreAmbiguities === true) {\n        return [];\n      }\n      const targetIdx = currPathAndIdx.idx;\n      const targetPath = currPathAndIdx.path;\n\n      const prefixAmbiguitiesPathsAndIndices = filter(\n        pathsAndIndices,\n        (searchPathAndIdx) => {\n          // prefix ambiguity can only be created from lower idx (higher priority) path\n          return (\n            // ignore (skip) ambiguities with this \"other\" alternative\n            alternation.definition[searchPathAndIdx.idx].ignoreAmbiguities !==\n              true &&\n            searchPathAndIdx.idx < targetIdx &&\n            // checking for strict prefix because identical lookaheads\n            // will be be detected using a different validation.\n            isStrictPrefixOfPath(searchPathAndIdx.path, targetPath)\n          );\n        },\n      );\n\n      const currPathPrefixErrors = map(\n        prefixAmbiguitiesPathsAndIndices,\n        (currAmbPathAndIdx): IParserAmbiguousAlternativesDefinitionError => {\n          const ambgIndices = [currAmbPathAndIdx.idx + 1, targetIdx + 1];\n          const occurrence = alternation.idx === 0 ? \"\" : alternation.idx;\n\n          const message = errMsgProvider.buildAlternationPrefixAmbiguityError({\n            topLevelRule: rule,\n            alternation: alternation,\n            ambiguityIndices: ambgIndices,\n            prefixPath: currAmbPathAndIdx.path,\n          });\n          return {\n            message: message,\n            type: ParserDefinitionErrorType.AMBIGUOUS_PREFIX_ALTS,\n            ruleName: rule.name,\n            occurrence: occurrence,\n            alternatives: ambgIndices,\n          };\n        },\n      );\n\n      return currPathPrefixErrors;\n    }),\n  );\n\n  return errors;\n}\n\nfunction checkTerminalAndNoneTerminalsNameSpace(\n  topLevels: Rule[],\n  tokenTypes: TokenType[],\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const errors: IParserDefinitionError[] = [];\n\n  const tokenNames = map(tokenTypes, (currToken) => currToken.name);\n\n  forEach(topLevels, (currRule) => {\n    const currRuleName = currRule.name;\n    if (includes(tokenNames, currRuleName)) {\n      const errMsg = errMsgProvider.buildNamespaceConflictError(currRule);\n\n      errors.push({\n        message: errMsg,\n        type: ParserDefinitionErrorType.CONFLICT_TOKENS_RULES_NAMESPACE,\n        ruleName: currRuleName,\n      });\n    }\n  });\n\n  return errors;\n}\n","import { every, flatten, forEach, has, isEmpty, map, reduce } from \"lodash-es\";\nimport { possiblePathsFrom } from \"./interpreter.js\";\nimport { RestWalker } from \"./rest.js\";\nimport { Predicate, TokenMatcher } from \"../parser/parser.js\";\nimport {\n  tokenStructuredMatcher,\n  tokenStructuredMatcherNoCategories,\n} from \"../../scan/tokens.js\";\nimport {\n  Alternation,\n  Alternative as AlternativeGAST,\n  GAstVisitor,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n} from \"@chevrotain/gast\";\nimport {\n  BaseParser,\n  IOrAlt,\n  IProduction,\n  IProductionWithOccurrence,\n  LookaheadProductionType,\n  LookaheadSequence,\n  Rule,\n  TokenType,\n} from \"@chevrotain/types\";\n\nexport enum PROD_TYPE {\n  OPTION,\n  REPETITION,\n  REPETITION_MANDATORY,\n  REPETITION_MANDATORY_WITH_SEPARATOR,\n  REPETITION_WITH_SEPARATOR,\n  ALTERNATION,\n}\n\nexport function getProdType(\n  prod: IProduction | LookaheadProductionType,\n): PROD_TYPE {\n  /* istanbul ignore else */\n  if (prod instanceof Option || prod === \"Option\") {\n    return PROD_TYPE.OPTION;\n  } else if (prod instanceof Repetition || prod === \"Repetition\") {\n    return PROD_TYPE.REPETITION;\n  } else if (\n    prod instanceof RepetitionMandatory ||\n    prod === \"RepetitionMandatory\"\n  ) {\n    return PROD_TYPE.REPETITION_MANDATORY;\n  } else if (\n    prod instanceof RepetitionMandatoryWithSeparator ||\n    prod === \"RepetitionMandatoryWithSeparator\"\n  ) {\n    return PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR;\n  } else if (\n    prod instanceof RepetitionWithSeparator ||\n    prod === \"RepetitionWithSeparator\"\n  ) {\n    return PROD_TYPE.REPETITION_WITH_SEPARATOR;\n  } else if (prod instanceof Alternation || prod === \"Alternation\") {\n    return PROD_TYPE.ALTERNATION;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexport function getLookaheadPaths(options: {\n  occurrence: number;\n  rule: Rule;\n  prodType: LookaheadProductionType;\n  maxLookahead: number;\n}): LookaheadSequence[] {\n  const { occurrence, rule, prodType, maxLookahead } = options;\n  const type = getProdType(prodType);\n  if (type === PROD_TYPE.ALTERNATION) {\n    return getLookaheadPathsForOr(occurrence, rule, maxLookahead);\n  } else {\n    return getLookaheadPathsForOptionalProd(\n      occurrence,\n      rule,\n      type,\n      maxLookahead,\n    );\n  }\n}\n\nexport function buildLookaheadFuncForOr(\n  occurrence: number,\n  ruleGrammar: Rule,\n  maxLookahead: number,\n  hasPredicates: boolean,\n  dynamicTokensEnabled: boolean,\n  laFuncBuilder: Function,\n): (orAlts?: IOrAlt<any>[]) => number | undefined {\n  const lookAheadPaths = getLookaheadPathsForOr(\n    occurrence,\n    ruleGrammar,\n    maxLookahead,\n  );\n\n  const tokenMatcher = areTokenCategoriesNotUsed(lookAheadPaths)\n    ? tokenStructuredMatcherNoCategories\n    : tokenStructuredMatcher;\n\n  return laFuncBuilder(\n    lookAheadPaths,\n    hasPredicates,\n    tokenMatcher,\n    dynamicTokensEnabled,\n  );\n}\n\n/**\n *  When dealing with an Optional production (OPTION/MANY/2nd iteration of AT_LEAST_ONE/...) we need to compare\n *  the lookahead \"inside\" the production and the lookahead immediately \"after\" it in the same top level rule (context free).\n *\n *  Example: given a production:\n *  ABC(DE)?DF\n *\n *  The optional '(DE)?' should only be entered if we see 'DE'. a single Token 'D' is not sufficient to distinguish between the two\n *  alternatives.\n *\n *  @returns A Lookahead function which will return true IFF the parser should parse the Optional production.\n */\nexport function buildLookaheadFuncForOptionalProd(\n  occurrence: number,\n  ruleGrammar: Rule,\n  k: number,\n  dynamicTokensEnabled: boolean,\n  prodType: PROD_TYPE,\n  lookaheadBuilder: (\n    lookAheadSequence: LookaheadSequence,\n    tokenMatcher: TokenMatcher,\n    dynamicTokensEnabled: boolean,\n  ) => () => boolean,\n): () => boolean {\n  const lookAheadPaths = getLookaheadPathsForOptionalProd(\n    occurrence,\n    ruleGrammar,\n    prodType,\n    k,\n  );\n\n  const tokenMatcher = areTokenCategoriesNotUsed(lookAheadPaths)\n    ? tokenStructuredMatcherNoCategories\n    : tokenStructuredMatcher;\n\n  return lookaheadBuilder(\n    lookAheadPaths[0],\n    tokenMatcher,\n    dynamicTokensEnabled,\n  );\n}\n\nexport type Alternative = TokenType[][];\n\nexport function buildAlternativesLookAheadFunc(\n  alts: LookaheadSequence[],\n  hasPredicates: boolean,\n  tokenMatcher: TokenMatcher,\n  dynamicTokensEnabled: boolean,\n): (orAlts: IOrAlt<any>[]) => number | undefined {\n  const numOfAlts = alts.length;\n  const areAllOneTokenLookahead = every(alts, (currAlt) => {\n    return every(currAlt, (currPath) => {\n      return currPath.length === 1;\n    });\n  });\n\n  // This version takes into account the predicates as well.\n  if (hasPredicates) {\n    /**\n     * @returns {number} - The chosen alternative index\n     */\n    return function (\n      this: BaseParser,\n      orAlts: IOrAlt<any>[],\n    ): number | undefined {\n      // unfortunately the predicates must be extracted every single time\n      // as they cannot be cached due to references to parameters(vars) which are no longer valid.\n      // note that in the common case of no predicates, no cpu time will be wasted on this (see else block)\n      const predicates: (Predicate | undefined)[] = map(\n        orAlts,\n        (currAlt) => currAlt.GATE,\n      );\n\n      for (let t = 0; t < numOfAlts; t++) {\n        const currAlt = alts[t];\n        const currNumOfPaths = currAlt.length;\n\n        const currPredicate = predicates[t];\n        if (currPredicate !== undefined && currPredicate.call(this) === false) {\n          // if the predicate does not match there is no point in checking the paths\n          continue;\n        }\n        nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n          const currPath = currAlt[j];\n          const currPathLength = currPath.length;\n          for (let i = 0; i < currPathLength; i++) {\n            const nextToken = this.LA(i + 1);\n            if (tokenMatcher(nextToken, currPath[i]) === false) {\n              // mismatch in current path\n              // try the next pth\n              continue nextPath;\n            }\n          }\n          // found a full path that matches.\n          // this will also work for an empty ALT as the loop will be skipped\n          return t;\n        }\n        // none of the paths for the current alternative matched\n        // try the next alternative\n      }\n      // none of the alternatives could be matched\n      return undefined;\n    };\n  } else if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n    // optimized (common) case of all the lookaheads paths requiring only\n    // a single token lookahead. These Optimizations cannot work if dynamically defined Tokens are used.\n    const singleTokenAlts = map(alts, (currAlt) => {\n      return flatten(currAlt);\n    });\n\n    const choiceToAlt = reduce(\n      singleTokenAlts,\n      (result, currAlt, idx) => {\n        forEach(currAlt, (currTokType) => {\n          if (!has(result, currTokType.tokenTypeIdx!)) {\n            result[currTokType.tokenTypeIdx!] = idx;\n          }\n          forEach(currTokType.categoryMatches!, (currExtendingType) => {\n            if (!has(result, currExtendingType)) {\n              result[currExtendingType] = idx;\n            }\n          });\n        });\n        return result;\n      },\n      {} as Record<number, number>,\n    );\n\n    /**\n     * @returns {number} - The chosen alternative index\n     */\n    return function (this: BaseParser): number {\n      const nextToken = this.LA(1);\n      return choiceToAlt[nextToken.tokenTypeIdx];\n    };\n  } else {\n    // optimized lookahead without needing to check the predicates at all.\n    // this causes code duplication which is intentional to improve performance.\n    /**\n     * @returns {number} - The chosen alternative index\n     */\n    return function (this: BaseParser): number | undefined {\n      for (let t = 0; t < numOfAlts; t++) {\n        const currAlt = alts[t];\n        const currNumOfPaths = currAlt.length;\n        nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n          const currPath = currAlt[j];\n          const currPathLength = currPath.length;\n          for (let i = 0; i < currPathLength; i++) {\n            const nextToken = this.LA(i + 1);\n            if (tokenMatcher(nextToken, currPath[i]) === false) {\n              // mismatch in current path\n              // try the next pth\n              continue nextPath;\n            }\n          }\n          // found a full path that matches.\n          // this will also work for an empty ALT as the loop will be skipped\n          return t;\n        }\n        // none of the paths for the current alternative matched\n        // try the next alternative\n      }\n      // none of the alternatives could be matched\n      return undefined;\n    };\n  }\n}\n\nexport function buildSingleAlternativeLookaheadFunction(\n  alt: LookaheadSequence,\n  tokenMatcher: TokenMatcher,\n  dynamicTokensEnabled: boolean,\n): () => boolean {\n  const areAllOneTokenLookahead = every(alt, (currPath) => {\n    return currPath.length === 1;\n  });\n\n  const numOfPaths = alt.length;\n\n  // optimized (common) case of all the lookaheads paths requiring only\n  // a single token lookahead.\n  if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n    const singleTokensTypes = flatten(alt);\n\n    if (\n      singleTokensTypes.length === 1 &&\n      isEmpty((<any>singleTokensTypes[0]).categoryMatches)\n    ) {\n      const expectedTokenType = singleTokensTypes[0];\n      const expectedTokenUniqueKey = (<any>expectedTokenType).tokenTypeIdx;\n\n      return function (this: BaseParser): boolean {\n        return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey;\n      };\n    } else {\n      const choiceToAlt = reduce(\n        singleTokensTypes,\n        (result, currTokType, idx) => {\n          result[currTokType.tokenTypeIdx!] = true;\n          forEach(currTokType.categoryMatches!, (currExtendingType) => {\n            result[currExtendingType] = true;\n          });\n          return result;\n        },\n        [] as boolean[],\n      );\n\n      return function (this: BaseParser): boolean {\n        const nextToken = this.LA(1);\n        return choiceToAlt[nextToken.tokenTypeIdx] === true;\n      };\n    }\n  } else {\n    return function (this: BaseParser): boolean {\n      nextPath: for (let j = 0; j < numOfPaths; j++) {\n        const currPath = alt[j];\n        const currPathLength = currPath.length;\n        for (let i = 0; i < currPathLength; i++) {\n          const nextToken = this.LA(i + 1);\n          if (tokenMatcher(nextToken, currPath[i]) === false) {\n            // mismatch in current path\n            // try the next pth\n            continue nextPath;\n          }\n        }\n        // found a full path that matches.\n        return true;\n      }\n\n      // none of the paths matched\n      return false;\n    };\n  }\n}\n\nclass RestDefinitionFinderWalker extends RestWalker {\n  private restDef: IProduction[];\n\n  constructor(\n    private topProd: Rule,\n    private targetOccurrence: number,\n    private targetProdType: PROD_TYPE,\n  ) {\n    super();\n  }\n\n  startWalking(): IProduction[] {\n    this.walk(this.topProd);\n    return this.restDef;\n  }\n\n  private checkIsTarget(\n    node: IProductionWithOccurrence,\n    expectedProdType: PROD_TYPE,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): boolean {\n    if (\n      node.idx === this.targetOccurrence &&\n      this.targetProdType === expectedProdType\n    ) {\n      this.restDef = currRest.concat(prevRest);\n      return true;\n    }\n    // performance optimization, do not iterate over the entire Grammar ast after we have found the target\n    return false;\n  }\n\n  walkOption(\n    optionProd: Option,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (!this.checkIsTarget(optionProd, PROD_TYPE.OPTION, currRest, prevRest)) {\n      super.walkOption(optionProd, currRest, prevRest);\n    }\n  }\n\n  walkAtLeastOne(\n    atLeastOneProd: RepetitionMandatory,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(\n        atLeastOneProd,\n        PROD_TYPE.REPETITION_MANDATORY,\n        currRest,\n        prevRest,\n      )\n    ) {\n      super.walkOption(atLeastOneProd, currRest, prevRest);\n    }\n  }\n\n  walkAtLeastOneSep(\n    atLeastOneSepProd: RepetitionMandatoryWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(\n        atLeastOneSepProd,\n        PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR,\n        currRest,\n        prevRest,\n      )\n    ) {\n      super.walkOption(atLeastOneSepProd, currRest, prevRest);\n    }\n  }\n\n  walkMany(\n    manyProd: Repetition,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(manyProd, PROD_TYPE.REPETITION, currRest, prevRest)\n    ) {\n      super.walkOption(manyProd, currRest, prevRest);\n    }\n  }\n\n  walkManySep(\n    manySepProd: RepetitionWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(\n        manySepProd,\n        PROD_TYPE.REPETITION_WITH_SEPARATOR,\n        currRest,\n        prevRest,\n      )\n    ) {\n      super.walkOption(manySepProd, currRest, prevRest);\n    }\n  }\n}\n\n/**\n * Returns the definition of a target production in a top level level rule.\n */\nclass InsideDefinitionFinderVisitor extends GAstVisitor {\n  public result: IProduction[] = [];\n\n  constructor(\n    private targetOccurrence: number,\n    private targetProdType: PROD_TYPE,\n    private targetRef?: any,\n  ) {\n    super();\n  }\n\n  private checkIsTarget(\n    node: { definition: IProduction[] } & IProductionWithOccurrence,\n    expectedProdName: PROD_TYPE,\n  ): void {\n    if (\n      node.idx === this.targetOccurrence &&\n      this.targetProdType === expectedProdName &&\n      (this.targetRef === undefined || node === this.targetRef)\n    ) {\n      this.result = node.definition;\n    }\n  }\n\n  public visitOption(node: Option): void {\n    this.checkIsTarget(node, PROD_TYPE.OPTION);\n  }\n\n  public visitRepetition(node: Repetition): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION);\n  }\n\n  public visitRepetitionMandatory(node: RepetitionMandatory): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    node: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR);\n  }\n\n  public visitRepetitionWithSeparator(node: RepetitionWithSeparator): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_WITH_SEPARATOR);\n  }\n\n  public visitAlternation(node: Alternation): void {\n    this.checkIsTarget(node, PROD_TYPE.ALTERNATION);\n  }\n}\n\nfunction initializeArrayOfArrays(size: number): any[][] {\n  const result = new Array(size);\n  for (let i = 0; i < size; i++) {\n    result[i] = [];\n  }\n  return result;\n}\n\n/**\n * A sort of hash function between a Path in the grammar and a string.\n * Note that this returns multiple \"hashes\" to support the scenario of token categories.\n * -  A single path with categories may match multiple **actual** paths.\n */\nfunction pathToHashKeys(path: TokenType[]): string[] {\n  let keys = [\"\"];\n  for (let i = 0; i < path.length; i++) {\n    const tokType = path[i];\n    const longerKeys = [];\n    for (let j = 0; j < keys.length; j++) {\n      const currShorterKey = keys[j];\n      longerKeys.push(currShorterKey + \"_\" + tokType.tokenTypeIdx);\n      for (let t = 0; t < tokType.categoryMatches!.length; t++) {\n        const categoriesKeySuffix = \"_\" + tokType.categoryMatches![t];\n        longerKeys.push(currShorterKey + categoriesKeySuffix);\n      }\n    }\n    keys = longerKeys;\n  }\n  return keys;\n}\n\n/**\n * Imperative style due to being called from a hot spot\n */\nfunction isUniquePrefixHash(\n  altKnownPathsKeys: Record<string, boolean>[],\n  searchPathKeys: string[],\n  idx: number,\n): boolean {\n  for (\n    let currAltIdx = 0;\n    currAltIdx < altKnownPathsKeys.length;\n    currAltIdx++\n  ) {\n    // We only want to test vs the other alternatives\n    if (currAltIdx === idx) {\n      continue;\n    }\n    const otherAltKnownPathsKeys = altKnownPathsKeys[currAltIdx];\n    for (let searchIdx = 0; searchIdx < searchPathKeys.length; searchIdx++) {\n      const searchKey = searchPathKeys[searchIdx];\n      if (otherAltKnownPathsKeys[searchKey] === true) {\n        return false;\n      }\n    }\n  }\n  // None of the SearchPathKeys were found in any of the other alternatives\n  return true;\n}\n\nexport function lookAheadSequenceFromAlternatives(\n  altsDefs: IProduction[],\n  k: number,\n): LookaheadSequence[] {\n  const partialAlts = map(altsDefs, (currAlt) =>\n    possiblePathsFrom([currAlt], 1),\n  );\n  const finalResult = initializeArrayOfArrays(partialAlts.length);\n  const altsHashes = map(partialAlts, (currAltPaths) => {\n    const dict: { [key: string]: boolean } = {};\n    forEach(currAltPaths, (item) => {\n      const keys = pathToHashKeys(item.partialPath);\n      forEach(keys, (currKey) => {\n        dict[currKey] = true;\n      });\n    });\n    return dict;\n  });\n  let newData = partialAlts;\n\n  // maxLookahead loop\n  for (let pathLength = 1; pathLength <= k; pathLength++) {\n    const currDataset = newData;\n    newData = initializeArrayOfArrays(currDataset.length);\n\n    // alternatives loop\n    for (let altIdx = 0; altIdx < currDataset.length; altIdx++) {\n      const currAltPathsAndSuffixes = currDataset[altIdx];\n      // paths in current alternative loop\n      for (\n        let currPathIdx = 0;\n        currPathIdx < currAltPathsAndSuffixes.length;\n        currPathIdx++\n      ) {\n        const currPathPrefix = currAltPathsAndSuffixes[currPathIdx].partialPath;\n        const suffixDef = currAltPathsAndSuffixes[currPathIdx].suffixDef;\n        const prefixKeys = pathToHashKeys(currPathPrefix);\n        const isUnique = isUniquePrefixHash(altsHashes, prefixKeys, altIdx);\n        // End of the line for this path.\n        if (isUnique || isEmpty(suffixDef) || currPathPrefix.length === k) {\n          const currAltResult = finalResult[altIdx];\n          // TODO: Can we implement a containsPath using Maps/Dictionaries?\n          if (containsPath(currAltResult, currPathPrefix) === false) {\n            currAltResult.push(currPathPrefix);\n            // Update all new  keys for the current path.\n            for (let j = 0; j < prefixKeys.length; j++) {\n              const currKey = prefixKeys[j];\n              altsHashes[altIdx][currKey] = true;\n            }\n          }\n        }\n        // Expand longer paths\n        else {\n          const newPartialPathsAndSuffixes = possiblePathsFrom(\n            suffixDef,\n            pathLength + 1,\n            currPathPrefix,\n          );\n          newData[altIdx] = newData[altIdx].concat(newPartialPathsAndSuffixes);\n\n          // Update keys for new known paths\n          forEach(newPartialPathsAndSuffixes, (item) => {\n            const prefixKeys = pathToHashKeys(item.partialPath);\n            forEach(prefixKeys, (key) => {\n              altsHashes[altIdx][key] = true;\n            });\n          });\n        }\n      }\n    }\n  }\n\n  return finalResult;\n}\n\nexport function getLookaheadPathsForOr(\n  occurrence: number,\n  ruleGrammar: Rule,\n  k: number,\n  orProd?: Alternation,\n): LookaheadSequence[] {\n  const visitor = new InsideDefinitionFinderVisitor(\n    occurrence,\n    PROD_TYPE.ALTERNATION,\n    orProd,\n  );\n  ruleGrammar.accept(visitor);\n  return lookAheadSequenceFromAlternatives(visitor.result, k);\n}\n\nexport function getLookaheadPathsForOptionalProd(\n  occurrence: number,\n  ruleGrammar: Rule,\n  prodType: PROD_TYPE,\n  k: number,\n): LookaheadSequence[] {\n  const insideDefVisitor = new InsideDefinitionFinderVisitor(\n    occurrence,\n    prodType,\n  );\n  ruleGrammar.accept(insideDefVisitor);\n  const insideDef = insideDefVisitor.result;\n\n  const afterDefWalker = new RestDefinitionFinderWalker(\n    ruleGrammar,\n    occurrence,\n    prodType,\n  );\n  const afterDef = afterDefWalker.startWalking();\n\n  const insideFlat = new AlternativeGAST({ definition: insideDef });\n  const afterFlat = new AlternativeGAST({ definition: afterDef });\n\n  return lookAheadSequenceFromAlternatives([insideFlat, afterFlat], k);\n}\n\nexport function containsPath(\n  alternative: Alternative,\n  searchPath: TokenType[],\n): boolean {\n  compareOtherPath: for (let i = 0; i < alternative.length; i++) {\n    const otherPath = alternative[i];\n    if (otherPath.length !== searchPath.length) {\n      continue;\n    }\n    for (let j = 0; j < otherPath.length; j++) {\n      const searchTok = searchPath[j];\n      const otherTok = otherPath[j];\n\n      const matchingTokens =\n        searchTok === otherTok ||\n        otherTok.categoryMatchesMap![searchTok.tokenTypeIdx!] !== undefined;\n      if (matchingTokens === false) {\n        continue compareOtherPath;\n      }\n    }\n    return true;\n  }\n\n  return false;\n}\n\nexport function isStrictPrefixOfPath(\n  prefix: TokenType[],\n  other: TokenType[],\n): boolean {\n  return (\n    prefix.length < other.length &&\n    every(prefix, (tokType, idx) => {\n      const otherTokType = other[idx];\n      return (\n        tokType === otherTokType ||\n        otherTokType.categoryMatchesMap![tokType.tokenTypeIdx!]\n      );\n    })\n  );\n}\n\nexport function areTokenCategoriesNotUsed(\n  lookAheadPaths: LookaheadSequence[],\n): boolean {\n  return every(lookAheadPaths, (singleAltPaths) =>\n    every(singleAltPaths, (singlePath) =>\n      every(singlePath, (token) => isEmpty(token.categoryMatches!)),\n    ),\n  );\n}\n","import {\n  clone,\n  drop,\n  dropRight,\n  first as _first,\n  forEach,\n  isEmpty,\n  last,\n} from \"lodash-es\";\nimport { first } from \"./first.js\";\nimport { RestWalker } from \"./rest.js\";\nimport { TokenMatcher } from \"../parser/parser.js\";\nimport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport {\n  IGrammarPath,\n  IProduction,\n  ISyntacticContentAssistPath,\n  IToken,\n  ITokenGrammarPath,\n  TokenType,\n} from \"@chevrotain/types\";\n\nexport abstract class AbstractNextPossibleTokensWalker extends RestWalker {\n  protected possibleTokTypes: TokenType[] = [];\n  protected ruleStack: string[];\n  protected occurrenceStack: number[];\n\n  protected nextProductionName = \"\";\n  protected nextProductionOccurrence = 0;\n  protected found = false;\n  protected isAtEndOfPath = false;\n\n  constructor(\n    protected topProd: Rule,\n    protected path: IGrammarPath,\n  ) {\n    super();\n  }\n\n  startWalking(): TokenType[] {\n    this.found = false;\n\n    if (this.path.ruleStack[0] !== this.topProd.name) {\n      throw Error(\"The path does not start with the walker's top Rule!\");\n    }\n\n    // immutable for the win\n    this.ruleStack = clone(this.path.ruleStack).reverse(); // intelij bug requires assertion\n    this.occurrenceStack = clone(this.path.occurrenceStack).reverse(); // intelij bug requires assertion\n\n    // already verified that the first production is valid, we now seek the 2nd production\n    this.ruleStack.pop();\n    this.occurrenceStack.pop();\n\n    this.updateExpectedNext();\n    this.walk(this.topProd);\n\n    return this.possibleTokTypes;\n  }\n\n  walk(\n    prod: { definition: IProduction[] },\n    prevRest: IProduction[] = [],\n  ): void {\n    // stop scanning once we found the path\n    if (!this.found) {\n      super.walk(prod, prevRest);\n    }\n  }\n\n  walkProdRef(\n    refProd: NonTerminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // found the next production, need to keep walking in it\n    if (\n      refProd.referencedRule.name === this.nextProductionName &&\n      refProd.idx === this.nextProductionOccurrence\n    ) {\n      const fullRest = currRest.concat(prevRest);\n      this.updateExpectedNext();\n      this.walk(refProd.referencedRule, <any>fullRest);\n    }\n  }\n\n  updateExpectedNext(): void {\n    // need to consume the Terminal\n    if (isEmpty(this.ruleStack)) {\n      // must reset nextProductionXXX to avoid walking down another Top Level production while what we are\n      // really seeking is the last Terminal...\n      this.nextProductionName = \"\";\n      this.nextProductionOccurrence = 0;\n      this.isAtEndOfPath = true;\n    } else {\n      this.nextProductionName = this.ruleStack.pop()!;\n      this.nextProductionOccurrence = this.occurrenceStack.pop()!;\n    }\n  }\n}\n\nexport class NextAfterTokenWalker extends AbstractNextPossibleTokensWalker {\n  private nextTerminalName = \"\";\n  private nextTerminalOccurrence = 0;\n\n  constructor(\n    topProd: Rule,\n    protected path: ITokenGrammarPath,\n  ) {\n    super(topProd, path);\n    this.nextTerminalName = this.path.lastTok.name;\n    this.nextTerminalOccurrence = this.path.lastTokOccurrence;\n  }\n\n  walkTerminal(\n    terminal: Terminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      this.isAtEndOfPath &&\n      terminal.terminalType.name === this.nextTerminalName &&\n      terminal.idx === this.nextTerminalOccurrence &&\n      !this.found\n    ) {\n      const fullRest = currRest.concat(prevRest);\n      const restProd = new Alternative({ definition: fullRest });\n      this.possibleTokTypes = first(restProd);\n      this.found = true;\n    }\n  }\n}\n\nexport type AlternativesFirstTokens = TokenType[][];\n\nexport interface IFirstAfterRepetition {\n  token: TokenType | undefined;\n  occurrence: number | undefined;\n  isEndOfRule: boolean | undefined;\n}\n\n/**\n * This walker only \"walks\" a single \"TOP\" level in the Grammar Ast, this means\n * it never \"follows\" production refs\n */\nexport class AbstractNextTerminalAfterProductionWalker extends RestWalker {\n  protected result: IFirstAfterRepetition = {\n    token: undefined,\n    occurrence: undefined,\n    isEndOfRule: undefined,\n  };\n\n  constructor(\n    protected topRule: Rule,\n    protected occurrence: number,\n  ) {\n    super();\n  }\n\n  startWalking(): IFirstAfterRepetition {\n    this.walk(this.topRule);\n    return this.result;\n  }\n}\n\nexport class NextTerminalAfterManyWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkMany(\n    manyProd: Repetition,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (manyProd.idx === this.occurrence) {\n      const firstAfterMany = _first(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterMany === undefined;\n      if (firstAfterMany instanceof Terminal) {\n        this.result.token = firstAfterMany.terminalType;\n        this.result.occurrence = firstAfterMany.idx;\n      }\n    } else {\n      super.walkMany(manyProd, currRest, prevRest);\n    }\n  }\n}\n\nexport class NextTerminalAfterManySepWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkManySep(\n    manySepProd: RepetitionWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (manySepProd.idx === this.occurrence) {\n      const firstAfterManySep = _first(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterManySep === undefined;\n      if (firstAfterManySep instanceof Terminal) {\n        this.result.token = firstAfterManySep.terminalType;\n        this.result.occurrence = firstAfterManySep.idx;\n      }\n    } else {\n      super.walkManySep(manySepProd, currRest, prevRest);\n    }\n  }\n}\n\nexport class NextTerminalAfterAtLeastOneWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkAtLeastOne(\n    atLeastOneProd: RepetitionMandatory,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (atLeastOneProd.idx === this.occurrence) {\n      const firstAfterAtLeastOne = _first(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterAtLeastOne === undefined;\n      if (firstAfterAtLeastOne instanceof Terminal) {\n        this.result.token = firstAfterAtLeastOne.terminalType;\n        this.result.occurrence = firstAfterAtLeastOne.idx;\n      }\n    } else {\n      super.walkAtLeastOne(atLeastOneProd, currRest, prevRest);\n    }\n  }\n}\n\n// TODO: reduce code duplication in the AfterWalkers\nexport class NextTerminalAfterAtLeastOneSepWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkAtLeastOneSep(\n    atleastOneSepProd: RepetitionMandatoryWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (atleastOneSepProd.idx === this.occurrence) {\n      const firstAfterfirstAfterAtLeastOneSep = _first(\n        currRest.concat(prevRest),\n      );\n      this.result.isEndOfRule = firstAfterfirstAfterAtLeastOneSep === undefined;\n      if (firstAfterfirstAfterAtLeastOneSep instanceof Terminal) {\n        this.result.token = firstAfterfirstAfterAtLeastOneSep.terminalType;\n        this.result.occurrence = firstAfterfirstAfterAtLeastOneSep.idx;\n      }\n    } else {\n      super.walkAtLeastOneSep(atleastOneSepProd, currRest, prevRest);\n    }\n  }\n}\n\nexport interface PartialPathAndSuffixes {\n  partialPath: TokenType[];\n  suffixDef: IProduction[];\n}\n\nexport function possiblePathsFrom(\n  targetDef: IProduction[],\n  maxLength: number,\n  currPath: TokenType[] = [],\n): PartialPathAndSuffixes[] {\n  // avoid side effects\n  currPath = clone(currPath);\n  let result: PartialPathAndSuffixes[] = [];\n  let i = 0;\n\n  // TODO: avoid inner funcs\n  function remainingPathWith(nextDef: IProduction[]) {\n    return nextDef.concat(drop(targetDef, i + 1));\n  }\n\n  // TODO: avoid inner funcs\n  function getAlternativesForProd(definition: IProduction[]) {\n    const alternatives = possiblePathsFrom(\n      remainingPathWith(definition),\n      maxLength,\n      currPath,\n    );\n    return result.concat(alternatives);\n  }\n\n  /**\n   * Mandatory productions will halt the loop as the paths computed from their recursive calls will already contain the\n   * following (rest) of the targetDef.\n   *\n   * For optional productions (Option/Repetition/...) the loop will continue to represent the paths that do not include the\n   * the optional production.\n   */\n  while (currPath.length < maxLength && i < targetDef.length) {\n    const prod = targetDef[i];\n\n    /* istanbul ignore else */\n    if (prod instanceof Alternative) {\n      return getAlternativesForProd(prod.definition);\n    } else if (prod instanceof NonTerminal) {\n      return getAlternativesForProd(prod.definition);\n    } else if (prod instanceof Option) {\n      result = getAlternativesForProd(prod.definition);\n    } else if (prod instanceof RepetitionMandatory) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: prod.definition,\n        }),\n      ]);\n      return getAlternativesForProd(newDef);\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n      const newDef = [\n        new Alternative({ definition: prod.definition }),\n        new Repetition({\n          definition: [new Terminal({ terminalType: prod.separator })].concat(\n            <any>prod.definition,\n          ),\n        }),\n      ];\n      return getAlternativesForProd(newDef);\n    } else if (prod instanceof RepetitionWithSeparator) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: [new Terminal({ terminalType: prod.separator })].concat(\n            <any>prod.definition,\n          ),\n        }),\n      ]);\n      result = getAlternativesForProd(newDef);\n    } else if (prod instanceof Repetition) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: prod.definition,\n        }),\n      ]);\n      result = getAlternativesForProd(newDef);\n    } else if (prod instanceof Alternation) {\n      forEach(prod.definition, (currAlt) => {\n        // TODO: this is a limited check for empty alternatives\n        //   It would prevent a common case of infinite loops during parser initialization.\n        //   However **in-directly** empty alternatives may still cause issues.\n        if (isEmpty(currAlt.definition) === false) {\n          result = getAlternativesForProd(currAlt.definition);\n        }\n      });\n      return result;\n    } else if (prod instanceof Terminal) {\n      currPath.push(prod.terminalType);\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n\n    i++;\n  }\n  result.push({\n    partialPath: currPath,\n    suffixDef: drop(targetDef, i),\n  });\n\n  return result;\n}\n\ninterface IPathToExamine {\n  idx: number;\n  def: IProduction[];\n  ruleStack: string[];\n  occurrenceStack: number[];\n}\n\nexport function nextPossibleTokensAfter(\n  initialDef: IProduction[],\n  tokenVector: IToken[],\n  tokMatcher: TokenMatcher,\n  maxLookAhead: number,\n): ISyntacticContentAssistPath[] {\n  const EXIT_NON_TERMINAL: any = \"EXIT_NONE_TERMINAL\";\n  // to avoid creating a new Array each time.\n  const EXIT_NON_TERMINAL_ARR = [EXIT_NON_TERMINAL];\n  const EXIT_ALTERNATIVE: any = \"EXIT_ALTERNATIVE\";\n  let foundCompletePath = false;\n\n  const tokenVectorLength = tokenVector.length;\n  const minimalAlternativesIndex = tokenVectorLength - maxLookAhead - 1;\n\n  const result: ISyntacticContentAssistPath[] = [];\n\n  const possiblePaths: IPathToExamine[] = [];\n  possiblePaths.push({\n    idx: -1,\n    def: initialDef,\n    ruleStack: [],\n    occurrenceStack: [],\n  });\n\n  while (!isEmpty(possiblePaths)) {\n    const currPath = possiblePaths.pop()!;\n\n    // skip alternatives if no more results can be found (assuming deterministic grammar with fixed lookahead)\n    if (currPath === EXIT_ALTERNATIVE) {\n      if (\n        foundCompletePath &&\n        last(possiblePaths)!.idx <= minimalAlternativesIndex\n      ) {\n        // remove irrelevant alternative\n        possiblePaths.pop();\n      }\n      continue;\n    }\n\n    const currDef = currPath.def;\n    const currIdx = currPath.idx;\n    const currRuleStack = currPath.ruleStack;\n    const currOccurrenceStack = currPath.occurrenceStack;\n\n    // For Example: an empty path could exist in a valid grammar in the case of an EMPTY_ALT\n    if (isEmpty(currDef)) {\n      continue;\n    }\n\n    const prod = currDef[0];\n    /* istanbul ignore else */\n    if (prod === EXIT_NON_TERMINAL) {\n      const nextPath = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: dropRight(currRuleStack),\n        occurrenceStack: dropRight(currOccurrenceStack),\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof Terminal) {\n      /* istanbul ignore else */\n      if (currIdx < tokenVectorLength - 1) {\n        const nextIdx = currIdx + 1;\n        const actualToken = tokenVector[nextIdx];\n        if (tokMatcher!(actualToken, prod.terminalType)) {\n          const nextPath = {\n            idx: nextIdx,\n            def: drop(currDef),\n            ruleStack: currRuleStack,\n            occurrenceStack: currOccurrenceStack,\n          };\n          possiblePaths.push(nextPath);\n        }\n        // end of the line\n      } else if (currIdx === tokenVectorLength - 1) {\n        // IGNORE ABOVE ELSE\n        result.push({\n          nextTokenType: prod.terminalType,\n          nextTokenOccurrence: prod.idx,\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack,\n        });\n        foundCompletePath = true;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    } else if (prod instanceof NonTerminal) {\n      const newRuleStack = clone(currRuleStack);\n      newRuleStack.push(prod.nonTerminalName);\n\n      const newOccurrenceStack = clone(currOccurrenceStack);\n      newOccurrenceStack.push(prod.idx);\n\n      const nextPath = {\n        idx: currIdx,\n        def: prod.definition.concat(EXIT_NON_TERMINAL_ARR, drop(currDef)),\n        ruleStack: newRuleStack,\n        occurrenceStack: newOccurrenceStack,\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof Option) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWithout);\n      // required marker to avoid backtracking paths whose higher priority alternatives already matched\n      possiblePaths.push(EXIT_ALTERNATIVE);\n\n      const nextPathWith = {\n        idx: currIdx,\n        def: prod.definition.concat(drop(currDef)),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof RepetitionMandatory) {\n      // TODO:(THE NEW operators here take a while...) (convert once?)\n      const secondIteration = new Repetition({\n        definition: prod.definition,\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n      const nextPath = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n      // TODO:(THE NEW operators here take a while...) (convert once?)\n      const separatorGast = new Terminal({\n        terminalType: prod.separator,\n      });\n      const secondIteration = new Repetition({\n        definition: [<any>separatorGast].concat(prod.definition),\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n      const nextPath = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof RepetitionWithSeparator) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWithout);\n      // required marker to avoid backtracking paths whose higher priority alternatives already matched\n      possiblePaths.push(EXIT_ALTERNATIVE);\n\n      const separatorGast = new Terminal({\n        terminalType: prod.separator,\n      });\n      const nthRepetition = new Repetition({\n        definition: [<any>separatorGast].concat(prod.definition),\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n      const nextPathWith = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof Repetition) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWithout);\n      // required marker to avoid backtracking paths whose higher priority alternatives already matched\n      possiblePaths.push(EXIT_ALTERNATIVE);\n\n      // TODO: an empty repetition will cause infinite loops here, will the parser detect this in selfAnalysis?\n      const nthRepetition = new Repetition({\n        definition: prod.definition,\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n      const nextPathWith = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof Alternation) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      for (let i = prod.definition.length - 1; i >= 0; i--) {\n        const currAlt: any = prod.definition[i];\n        const currAltPath = {\n          idx: currIdx,\n          def: currAlt.definition.concat(drop(currDef)),\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack,\n        };\n        possiblePaths.push(currAltPath);\n        possiblePaths.push(EXIT_ALTERNATIVE);\n      }\n    } else if (prod instanceof Alternative) {\n      possiblePaths.push({\n        idx: currIdx,\n        def: prod.definition.concat(drop(currDef)),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      });\n    } else if (prod instanceof Rule) {\n      // last because we should only encounter at most a single one of these per invocation.\n      possiblePaths.push(\n        expandTopLevelRule(prod, currIdx, currRuleStack, currOccurrenceStack),\n      );\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n  return result;\n}\n\nfunction expandTopLevelRule(\n  topRule: Rule,\n  currIdx: number,\n  currRuleStack: string[],\n  currOccurrenceStack: number[],\n): IPathToExamine {\n  const newRuleStack = clone(currRuleStack);\n  newRuleStack.push(topRule.name);\n\n  const newCurrOccurrenceStack = clone(currOccurrenceStack);\n  // top rule is always assumed to have been called with occurrence index 1\n  newCurrOccurrenceStack.push(1);\n\n  return {\n    idx: currIdx,\n    def: topRule.definition,\n    ruleStack: newRuleStack,\n    occurrenceStack: newCurrOccurrenceStack,\n  };\n}\n","import {\n  createTokenInstance,\n  EOF,\n  tokenMatcher,\n} from \"../../../scan/tokens_public.js\";\nimport {\n  AbstractNextTerminalAfterProductionWalker,\n  IFirstAfterRepetition,\n} from \"../../grammar/interpreter.js\";\nimport {\n  clone,\n  dropRight,\n  find,\n  flatten,\n  has,\n  includes,\n  isEmpty,\n  map,\n} from \"lodash-es\";\nimport {\n  IParserConfig,\n  IToken,\n  ITokenGrammarPath,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { MismatchedTokenException } from \"../../exceptions_public.js\";\nimport { IN } from \"../../constants.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\nexport const EOF_FOLLOW_KEY: any = {};\n\nexport interface IFollowKey {\n  ruleName: string;\n  idxInCallingRule: number;\n  inRule: string;\n}\n\nexport const IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\n\nexport class InRuleRecoveryException extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = IN_RULE_RECOVERY_EXCEPTION;\n  }\n}\n\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\nexport class Recoverable {\n  recoveryEnabled: boolean;\n  firstAfterRepMap: Record<string, IFirstAfterRepetition>;\n  resyncFollows: Record<string, TokenType[]>;\n\n  initRecoverable(config: IParserConfig) {\n    this.firstAfterRepMap = {};\n    this.resyncFollows = {};\n\n    this.recoveryEnabled = has(config, \"recoveryEnabled\")\n      ? (config.recoveryEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.recoveryEnabled;\n\n    // performance optimization, NOOP will be inlined which\n    // effectively means that this optional feature does not exist\n    // when not used.\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery;\n    }\n  }\n\n  public getTokenToInsert(tokType: TokenType): IToken {\n    const tokToInsert = createTokenInstance(\n      tokType,\n      \"\",\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n    );\n    tokToInsert.isInsertedInRecovery = true;\n    return tokToInsert;\n  }\n\n  public canTokenTypeBeInsertedInRecovery(tokType: TokenType): boolean {\n    return true;\n  }\n\n  public canTokenTypeBeDeletedInRecovery(tokType: TokenType): boolean {\n    return true;\n  }\n\n  tryInRepetitionRecovery(\n    this: MixedInParser,\n    grammarRule: Function,\n    grammarRuleArgs: any[],\n    lookAheadFunc: () => boolean,\n    expectedTokType: TokenType,\n  ): void {\n    // TODO: can the resyncTokenType be cached?\n    const reSyncTokType = this.findReSyncTokenType();\n    const savedLexerState = this.exportLexerState();\n    const resyncedTokens: IToken[] = [];\n    let passedResyncPoint = false;\n\n    const nextTokenWithoutResync = this.LA(1);\n    let currToken = this.LA(1);\n\n    const generateErrorMessage = () => {\n      const previousToken = this.LA(0);\n      // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n      // the error that would have been thrown\n      const msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName(),\n      });\n      const error = new MismatchedTokenException(\n        msg,\n        nextTokenWithoutResync,\n        this.LA(0),\n      );\n      // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n      error.resyncedTokens = dropRight(resyncedTokens);\n      this.SAVE_ERROR(error);\n    };\n\n    while (!passedResyncPoint) {\n      // re-synced to a point where we can safely exit the repetition/\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage();\n        return; // must return here to avoid reverting the inputIdx\n      } else if (lookAheadFunc.call(this)) {\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n        generateErrorMessage();\n        // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n        grammarRule.apply(this, grammarRuleArgs);\n        return; // must return here to avoid reverting the inputIdx\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true;\n      } else {\n        currToken = this.SKIP_TOKEN();\n        this.addToResyncTokens(currToken, resyncedTokens);\n      }\n    }\n\n    // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n    // \"between rules\" resync recovery later in the flow.\n    this.importLexerState(savedLexerState);\n  }\n\n  shouldInRepetitionRecoveryBeTried(\n    this: MixedInParser,\n    expectTokAfterLastMatch: TokenType,\n    nextTokIdx: number,\n    notStuck: boolean | undefined,\n  ): boolean {\n    // Edge case of arriving from a MANY repetition which is stuck\n    // Attempting recovery in this case could cause an infinite loop\n    if (notStuck === false) {\n      return false;\n    }\n\n    // no need to recover, next token is what we expect...\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false;\n    }\n\n    // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n    // and prefer some backtracking path that includes recovered errors.\n    if (this.isBackTracking()) {\n      return false;\n    }\n\n    // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n    //noinspection RedundantIfStatementJS\n    if (\n      this.canPerformInRuleRecovery(\n        expectTokAfterLastMatch,\n        this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx),\n      )\n    ) {\n      return false;\n    }\n\n    return true;\n  }\n\n  // Error Recovery functionality\n  getFollowsForInRuleRecovery(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number,\n  ): TokenType[] {\n    const grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule);\n    const follows = this.getNextPossibleTokenTypes(grammarPath);\n    return follows;\n  }\n\n  tryInRuleRecovery(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[],\n  ): IToken {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      const tokToInsert = this.getTokenToInsert(expectedTokType);\n      return tokToInsert;\n    }\n\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      const nextTok = this.SKIP_TOKEN();\n      this.consumeToken();\n      return nextTok;\n    }\n\n    throw new InRuleRecoveryException(\"sad sad panda\");\n  }\n\n  canPerformInRuleRecovery(\n    this: MixedInParser,\n    expectedToken: TokenType,\n    follows: TokenType[],\n  ): boolean {\n    return (\n      this.canRecoverWithSingleTokenInsertion(expectedToken, follows) ||\n      this.canRecoverWithSingleTokenDeletion(expectedToken)\n    );\n  }\n\n  canRecoverWithSingleTokenInsertion(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[],\n  ): boolean {\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false;\n    }\n\n    // must know the possible following tokens to perform single token insertion\n    if (isEmpty(follows)) {\n      return false;\n    }\n\n    const mismatchedTok = this.LA(1);\n    const isMisMatchedTokInFollows =\n      find(follows, (possibleFollowsTokType: TokenType) => {\n        return this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n      }) !== undefined;\n\n    return isMisMatchedTokInFollows;\n  }\n\n  canRecoverWithSingleTokenDeletion(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n  ): boolean {\n    if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\n      return false;\n    }\n\n    const isNextTokenWhatIsExpected = this.tokenMatcher(\n      this.LA(2),\n      expectedTokType,\n    );\n    return isNextTokenWhatIsExpected;\n  }\n\n  isInCurrentRuleReSyncSet(\n    this: MixedInParser,\n    tokenTypeIdx: TokenType,\n  ): boolean {\n    const followKey = this.getCurrFollowKey();\n    const currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n    return includes(currentRuleReSyncSet, tokenTypeIdx);\n  }\n\n  findReSyncTokenType(this: MixedInParser): TokenType {\n    const allPossibleReSyncTokTypes = this.flattenFollowSet();\n    // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n    let nextToken = this.LA(1);\n    let k = 2;\n    while (true) {\n      const foundMatch = find(allPossibleReSyncTokTypes, (resyncTokType) => {\n        const canMatch = tokenMatcher(nextToken, resyncTokType);\n        return canMatch;\n      });\n      if (foundMatch !== undefined) {\n        return foundMatch;\n      }\n      nextToken = this.LA(k);\n      k++;\n    }\n  }\n\n  getCurrFollowKey(this: MixedInParser): IFollowKey {\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n    if (this.RULE_STACK.length === 1) {\n      return EOF_FOLLOW_KEY;\n    }\n    const currRuleShortName = this.getLastExplicitRuleShortName();\n    const currRuleIdx = this.getLastExplicitRuleOccurrenceIndex();\n    const prevRuleShortName = this.getPreviousExplicitRuleShortName();\n\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName),\n    };\n  }\n\n  buildFullFollowKeyStack(this: MixedInParser): IFollowKey[] {\n    const explicitRuleStack = this.RULE_STACK;\n    const explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK;\n\n    return map(explicitRuleStack, (ruleName, idx) => {\n      if (idx === 0) {\n        return EOF_FOLLOW_KEY;\n      }\n      return {\n        ruleName: this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: this.shortRuleNameToFullName(explicitRuleStack[idx - 1]),\n      };\n    });\n  }\n\n  flattenFollowSet(this: MixedInParser): TokenType[] {\n    const followStack = map(this.buildFullFollowKeyStack(), (currKey) => {\n      return this.getFollowSetFromFollowKey(currKey);\n    });\n    return <any>flatten(followStack);\n  }\n\n  getFollowSetFromFollowKey(\n    this: MixedInParser,\n    followKey: IFollowKey,\n  ): TokenType[] {\n    if (followKey === EOF_FOLLOW_KEY) {\n      return [EOF];\n    }\n\n    const followName =\n      followKey.ruleName + followKey.idxInCallingRule + IN + followKey.inRule;\n\n    return this.resyncFollows[followName];\n  }\n\n  // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n  addToResyncTokens(\n    this: MixedInParser,\n    token: IToken,\n    resyncTokens: IToken[],\n  ): IToken[] {\n    if (!this.tokenMatcher(token, EOF)) {\n      resyncTokens.push(token);\n    }\n    return resyncTokens;\n  }\n\n  reSyncTo(this: MixedInParser, tokType: TokenType): IToken[] {\n    const resyncedTokens: IToken[] = [];\n    let nextTok = this.LA(1);\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN();\n      this.addToResyncTokens(nextTok, resyncedTokens);\n    }\n    // the last token is not part of the error.\n    return dropRight(resyncedTokens);\n  }\n\n  attemptInRepetitionRecovery(\n    this: MixedInParser,\n    prodFunc: Function,\n    args: any[],\n    lookaheadFunc: () => boolean,\n    dslMethodIdx: number,\n    prodOccurrence: number,\n    nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n    notStuck?: boolean,\n  ): void {\n    // by default this is a NO-OP\n    // The actual implementation is with the function(not method) below\n  }\n\n  getCurrentGrammarPath(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number,\n  ): ITokenGrammarPath {\n    const pathRuleStack: string[] = this.getHumanReadableRuleStack();\n    const pathOccurrenceStack: number[] = clone(this.RULE_OCCURRENCE_STACK);\n    const grammarPath: any = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule,\n    };\n\n    return grammarPath;\n  }\n  getHumanReadableRuleStack(this: MixedInParser): string[] {\n    return map(this.RULE_STACK, (currShortName) =>\n      this.shortRuleNameToFullName(currShortName),\n    );\n  }\n}\n\nexport function attemptInRepetitionRecovery(\n  this: MixedInParser,\n  prodFunc: Function,\n  args: any[],\n  lookaheadFunc: () => boolean,\n  dslMethodIdx: number,\n  prodOccurrence: number,\n  nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n  notStuck?: boolean,\n): void {\n  const key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n  let firstAfterRepInfo = this.firstAfterRepMap[key];\n  if (firstAfterRepInfo === undefined) {\n    const currRuleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[currRuleName];\n    const walker: AbstractNextTerminalAfterProductionWalker =\n      new nextToksWalker(ruleGrammar, prodOccurrence);\n    firstAfterRepInfo = walker.startWalking();\n    this.firstAfterRepMap[key] = firstAfterRepInfo;\n  }\n\n  let expectTokAfterLastMatch = firstAfterRepInfo.token;\n  let nextTokIdx = firstAfterRepInfo.occurrence;\n  const isEndOfRule = firstAfterRepInfo.isEndOfRule;\n\n  // special edge case of a TOP most repetition after which the input should END.\n  // this will force an attempt for inRule recovery in that scenario.\n  if (\n    this.RULE_STACK.length === 1 &&\n    isEndOfRule &&\n    expectTokAfterLastMatch === undefined\n  ) {\n    expectTokAfterLastMatch = EOF;\n    nextTokIdx = 1;\n  }\n\n  // We don't have anything to re-sync to...\n  // this condition was extracted from `shouldInRepetitionRecoveryBeTried` to act as a type-guard\n  if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n    return;\n  }\n\n  if (\n    this.shouldInRepetitionRecoveryBeTried(\n      expectTokAfterLastMatch,\n      nextTokIdx,\n      notStuck,\n    )\n  ) {\n    // TODO: performance optimization: instead of passing the original args here, we modify\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n    // to avoid searching the cache for it once more.\n    this.tryInRepetitionRecovery(\n      prodFunc,\n      args,\n      lookaheadFunc,\n      expectTokAfterLastMatch,\n    );\n  }\n}\n","import { includes } from \"lodash-es\";\nimport {\n  IRecognitionException,\n  IRecognizerContext,\n  IToken,\n} from \"@chevrotain/types\";\n\nconst MISMATCHED_TOKEN_EXCEPTION = \"MismatchedTokenException\";\nconst NO_VIABLE_ALT_EXCEPTION = \"NoViableAltException\";\nconst EARLY_EXIT_EXCEPTION = \"EarlyExitException\";\nconst NOT_ALL_INPUT_PARSED_EXCEPTION = \"NotAllInputParsedException\";\n\nconst RECOGNITION_EXCEPTION_NAMES = [\n  MISMATCHED_TOKEN_EXCEPTION,\n  NO_VIABLE_ALT_EXCEPTION,\n  EARLY_EXIT_EXCEPTION,\n  NOT_ALL_INPUT_PARSED_EXCEPTION,\n];\n\nObject.freeze(RECOGNITION_EXCEPTION_NAMES);\n\n// hacks to bypass no support for custom Errors in javascript/typescript\nexport function isRecognitionException(error: Error) {\n  // can't do instanceof on hacked custom js exceptions\n  return includes(RECOGNITION_EXCEPTION_NAMES, error.name);\n}\n\nabstract class RecognitionException\n  extends Error\n  implements IRecognitionException\n{\n  context: IRecognizerContext;\n  resyncedTokens: IToken[] = [];\n\n  protected constructor(\n    message: string,\n    public token: IToken,\n  ) {\n    super(message);\n\n    // fix prototype chain when typescript target is ES5\n    Object.setPrototypeOf(this, new.target.prototype);\n\n    /* istanbul ignore next - V8 workaround to remove constructor from stacktrace when typescript target is ES5 */\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n  }\n}\n\nexport class MismatchedTokenException extends RecognitionException {\n  constructor(\n    message: string,\n    token: IToken,\n    public previousToken: IToken,\n  ) {\n    super(message, token);\n    this.name = MISMATCHED_TOKEN_EXCEPTION;\n  }\n}\n\nexport class NoViableAltException extends RecognitionException {\n  constructor(\n    message: string,\n    token: IToken,\n    public previousToken: IToken,\n  ) {\n    super(message, token);\n    this.name = NO_VIABLE_ALT_EXCEPTION;\n  }\n}\n\nexport class NotAllInputParsedException extends RecognitionException {\n  constructor(message: string, token: IToken) {\n    super(message, token);\n    this.name = NOT_ALL_INPUT_PARSED_EXCEPTION;\n  }\n}\n\nexport class EarlyExitException extends RecognitionException {\n  constructor(\n    message: string,\n    token: IToken,\n    public previousToken: IToken,\n  ) {\n    super(message, token);\n    this.name = EARLY_EXIT_EXCEPTION;\n  }\n}\n","import { forEach, has } from \"lodash-es\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\nimport {\n  ILookaheadStrategy,\n  IParserConfig,\n  OptionalProductionType,\n} from \"@chevrotain/types\";\nimport {\n  AT_LEAST_ONE_IDX,\n  AT_LEAST_ONE_SEP_IDX,\n  getKeyForAutomaticLookahead,\n  MANY_IDX,\n  MANY_SEP_IDX,\n  OPTION_IDX,\n  OR_IDX,\n} from \"../../grammar/keys.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport {\n  Alternation,\n  GAstVisitor,\n  getProductionDslName,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n} from \"@chevrotain/gast\";\nimport { LLkLookaheadStrategy } from \"../../grammar/llk_lookahead.js\";\n\n/**\n * Trait responsible for the lookahead related utilities and optimizations.\n */\nexport class LooksAhead {\n  maxLookahead: number;\n  lookAheadFuncsCache: any;\n  dynamicTokensEnabled: boolean;\n  lookaheadStrategy: ILookaheadStrategy;\n\n  initLooksAhead(config: IParserConfig) {\n    this.dynamicTokensEnabled = has(config, \"dynamicTokensEnabled\")\n      ? (config.dynamicTokensEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.dynamicTokensEnabled;\n\n    this.maxLookahead = has(config, \"maxLookahead\")\n      ? (config.maxLookahead as number) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.maxLookahead;\n\n    this.lookaheadStrategy = has(config, \"lookaheadStrategy\")\n      ? (config.lookaheadStrategy as ILookaheadStrategy) // assumes end user provides the correct config value/type\n      : new LLkLookaheadStrategy({ maxLookahead: this.maxLookahead });\n\n    this.lookAheadFuncsCache = new Map();\n  }\n\n  preComputeLookaheadFunctions(this: MixedInParser, rules: Rule[]): void {\n    forEach(rules, (currRule) => {\n      this.TRACE_INIT(`${currRule.name} Rule Lookahead`, () => {\n        const {\n          alternation,\n          repetition,\n          option,\n          repetitionMandatory,\n          repetitionMandatoryWithSeparator,\n          repetitionWithSeparator,\n        } = collectMethods(currRule);\n\n        forEach(alternation, (currProd) => {\n          const prodIdx = currProd.idx === 0 ? \"\" : currProd.idx;\n          this.TRACE_INIT(`${getProductionDslName(currProd)}${prodIdx}`, () => {\n            const laFunc = this.lookaheadStrategy.buildLookaheadForAlternation({\n              prodOccurrence: currProd.idx,\n              rule: currRule,\n              maxLookahead: currProd.maxLookahead || this.maxLookahead,\n              hasPredicates: currProd.hasPredicates,\n              dynamicTokensEnabled: this.dynamicTokensEnabled,\n            });\n\n            const key = getKeyForAutomaticLookahead(\n              this.fullRuleNameToShort[currRule.name],\n              OR_IDX,\n              currProd.idx,\n            );\n            this.setLaFuncCache(key, laFunc);\n          });\n        });\n\n        forEach(repetition, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            MANY_IDX,\n            \"Repetition\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(option, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            OPTION_IDX,\n            \"Option\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(repetitionMandatory, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            AT_LEAST_ONE_IDX,\n            \"RepetitionMandatory\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(repetitionMandatoryWithSeparator, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            AT_LEAST_ONE_SEP_IDX,\n            \"RepetitionMandatoryWithSeparator\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(repetitionWithSeparator, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            MANY_SEP_IDX,\n            \"RepetitionWithSeparator\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n      });\n    });\n  }\n\n  computeLookaheadFunc(\n    this: MixedInParser,\n    rule: Rule,\n    prodOccurrence: number,\n    prodKey: number,\n    prodType: OptionalProductionType,\n    prodMaxLookahead: number | undefined,\n    dslMethodName: string,\n  ): void {\n    this.TRACE_INIT(\n      `${dslMethodName}${prodOccurrence === 0 ? \"\" : prodOccurrence}`,\n      () => {\n        const laFunc = this.lookaheadStrategy.buildLookaheadForOptional({\n          prodOccurrence,\n          rule,\n          maxLookahead: prodMaxLookahead || this.maxLookahead,\n          dynamicTokensEnabled: this.dynamicTokensEnabled,\n          prodType,\n        });\n        const key = getKeyForAutomaticLookahead(\n          this.fullRuleNameToShort[rule.name],\n          prodKey,\n          prodOccurrence,\n        );\n        this.setLaFuncCache(key, laFunc);\n      },\n    );\n  }\n\n  // this actually returns a number, but it is always used as a string (object prop key)\n  getKeyForAutomaticLookahead(\n    this: MixedInParser,\n    dslMethodIdx: number,\n    occurrence: number,\n  ): number {\n    const currRuleShortName: any = this.getLastExplicitRuleShortName();\n    return getKeyForAutomaticLookahead(\n      currRuleShortName,\n      dslMethodIdx,\n      occurrence,\n    );\n  }\n\n  getLaFuncFromCache(this: MixedInParser, key: number): Function {\n    return this.lookAheadFuncsCache.get(key);\n  }\n\n  /* istanbul ignore next */\n  setLaFuncCache(this: MixedInParser, key: number, value: Function): void {\n    this.lookAheadFuncsCache.set(key, value);\n  }\n}\n\nclass DslMethodsCollectorVisitor extends GAstVisitor {\n  public dslMethods: {\n    option: Option[];\n    alternation: Alternation[];\n    repetition: Repetition[];\n    repetitionWithSeparator: RepetitionWithSeparator[];\n    repetitionMandatory: RepetitionMandatory[];\n    repetitionMandatoryWithSeparator: RepetitionMandatoryWithSeparator[];\n  } = {\n    option: [],\n    alternation: [],\n    repetition: [],\n    repetitionWithSeparator: [],\n    repetitionMandatory: [],\n    repetitionMandatoryWithSeparator: [],\n  };\n\n  reset() {\n    this.dslMethods = {\n      option: [],\n      alternation: [],\n      repetition: [],\n      repetitionWithSeparator: [],\n      repetitionMandatory: [],\n      repetitionMandatoryWithSeparator: [],\n    };\n  }\n\n  public visitOption(option: Option): void {\n    this.dslMethods.option.push(option);\n  }\n\n  public visitRepetitionWithSeparator(manySep: RepetitionWithSeparator): void {\n    this.dslMethods.repetitionWithSeparator.push(manySep);\n  }\n\n  public visitRepetitionMandatory(atLeastOne: RepetitionMandatory): void {\n    this.dslMethods.repetitionMandatory.push(atLeastOne);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    atLeastOneSep: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.dslMethods.repetitionMandatoryWithSeparator.push(atLeastOneSep);\n  }\n\n  public visitRepetition(many: Repetition): void {\n    this.dslMethods.repetition.push(many);\n  }\n\n  public visitAlternation(or: Alternation): void {\n    this.dslMethods.alternation.push(or);\n  }\n}\n\nconst collectorVisitor = new DslMethodsCollectorVisitor();\nexport function collectMethods(rule: Rule): {\n  option: Option[];\n  alternation: Alternation[];\n  repetition: Repetition[];\n  repetitionWithSeparator: RepetitionWithSeparator[];\n  repetitionMandatory: RepetitionMandatory[];\n  repetitionMandatoryWithSeparator: RepetitionMandatoryWithSeparator[];\n} {\n  collectorVisitor.reset();\n  rule.accept(collectorVisitor);\n  const dslMethods = collectorVisitor.dslMethods;\n  // avoid uncleaned references\n  collectorVisitor.reset();\n  return <any>dslMethods;\n}\n","// Lookahead keys are 32Bit integers in the form\n// TTTTTTTT-ZZZZZZZZZZZZ-YYYY-XXXXXXXX\n// XXXX -> Occurrence Index bitmap.\n// YYYY -> DSL Method Type bitmap.\n// ZZZZZZZZZZZZZZZ -> Rule short Index bitmap.\n// TTTTTTTTT -> alternation alternative index bitmap\n\nexport const BITS_FOR_METHOD_TYPE = 4;\nexport const BITS_FOR_OCCURRENCE_IDX = 8;\nexport const BITS_FOR_RULE_IDX = 12;\n// TODO: validation, this means that there may at most 2^8 --> 256 alternatives for an alternation.\nexport const BITS_FOR_ALT_IDX = 8;\n\n// short string used as part of mapping keys.\n// being short improves the performance when composing KEYS for maps out of these\n// The 5 - 8 bits (16 possible values, are reserved for the DSL method indices)\nexport const OR_IDX = 1 << BITS_FOR_OCCURRENCE_IDX;\nexport const OPTION_IDX = 2 << BITS_FOR_OCCURRENCE_IDX;\nexport const MANY_IDX = 3 << BITS_FOR_OCCURRENCE_IDX;\nexport const AT_LEAST_ONE_IDX = 4 << BITS_FOR_OCCURRENCE_IDX;\nexport const MANY_SEP_IDX = 5 << BITS_FOR_OCCURRENCE_IDX;\nexport const AT_LEAST_ONE_SEP_IDX = 6 << BITS_FOR_OCCURRENCE_IDX;\n\n// this actually returns a number, but it is always used as a string (object prop key)\nexport function getKeyForAutomaticLookahead(\n  ruleIdx: number,\n  dslMethodIdx: number,\n  occurrence: number,\n): number {\n  return occurrence | dslMethodIdx | ruleIdx;\n}\n\nconst BITS_START_FOR_ALT_IDX = 32 - BITS_FOR_ALT_IDX;\n","import {\n  ILookaheadStrategy,\n  ILookaheadValidationError,\n  IOrAlt,\n  OptionalProductionType,\n  Rule,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { flatMap, isEmpty } from \"lodash-es\";\nimport { defaultGrammarValidatorErrorProvider } from \"../errors_public.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser/parser.js\";\nimport {\n  validateAmbiguousAlternationAlternatives,\n  validateEmptyOrAlternative,\n  validateNoLeftRecursion,\n  validateSomeNonEmptyLookaheadPath,\n} from \"./checks.js\";\nimport {\n  buildAlternativesLookAheadFunc,\n  buildLookaheadFuncForOptionalProd,\n  buildLookaheadFuncForOr,\n  buildSingleAlternativeLookaheadFunction,\n  getProdType,\n} from \"./lookahead.js\";\nimport { IParserDefinitionError } from \"./types.js\";\n\nexport class LLkLookaheadStrategy implements ILookaheadStrategy {\n  readonly maxLookahead: number;\n\n  constructor(options?: { maxLookahead?: number }) {\n    this.maxLookahead =\n      options?.maxLookahead ?? DEFAULT_PARSER_CONFIG.maxLookahead;\n  }\n\n  validate(options: {\n    rules: Rule[];\n    tokenTypes: TokenType[];\n    grammarName: string;\n  }): ILookaheadValidationError[] {\n    const leftRecursionErrors = this.validateNoLeftRecursion(options.rules);\n\n    if (isEmpty(leftRecursionErrors)) {\n      const emptyAltErrors = this.validateEmptyOrAlternatives(options.rules);\n      const ambiguousAltsErrors = this.validateAmbiguousAlternationAlternatives(\n        options.rules,\n        this.maxLookahead,\n      );\n      const emptyRepetitionErrors = this.validateSomeNonEmptyLookaheadPath(\n        options.rules,\n        this.maxLookahead,\n      );\n      const allErrors = [\n        ...leftRecursionErrors,\n        ...emptyAltErrors,\n        ...ambiguousAltsErrors,\n        ...emptyRepetitionErrors,\n      ];\n      return allErrors;\n    }\n    return leftRecursionErrors;\n  }\n\n  validateNoLeftRecursion(rules: Rule[]): IParserDefinitionError[] {\n    return flatMap(rules, (currTopRule) =>\n      validateNoLeftRecursion(\n        currTopRule,\n        currTopRule,\n        defaultGrammarValidatorErrorProvider,\n      ),\n    );\n  }\n\n  validateEmptyOrAlternatives(rules: Rule[]): IParserDefinitionError[] {\n    return flatMap(rules, (currTopRule) =>\n      validateEmptyOrAlternative(\n        currTopRule,\n        defaultGrammarValidatorErrorProvider,\n      ),\n    );\n  }\n\n  validateAmbiguousAlternationAlternatives(\n    rules: Rule[],\n    maxLookahead: number,\n  ): IParserDefinitionError[] {\n    return flatMap(rules, (currTopRule) =>\n      validateAmbiguousAlternationAlternatives(\n        currTopRule,\n        maxLookahead,\n        defaultGrammarValidatorErrorProvider,\n      ),\n    );\n  }\n\n  validateSomeNonEmptyLookaheadPath(\n    rules: Rule[],\n    maxLookahead: number,\n  ): IParserDefinitionError[] {\n    return validateSomeNonEmptyLookaheadPath(\n      rules,\n      maxLookahead,\n      defaultGrammarValidatorErrorProvider,\n    );\n  }\n\n  buildLookaheadForAlternation(options: {\n    prodOccurrence: number;\n    rule: Rule;\n    maxLookahead: number;\n    hasPredicates: boolean;\n    dynamicTokensEnabled: boolean;\n  }): (orAlts?: IOrAlt<any>[] | undefined) => number | undefined {\n    return buildLookaheadFuncForOr(\n      options.prodOccurrence,\n      options.rule,\n      options.maxLookahead,\n      options.hasPredicates,\n      options.dynamicTokensEnabled,\n      buildAlternativesLookAheadFunc,\n    );\n  }\n\n  buildLookaheadForOptional(options: {\n    prodOccurrence: number;\n    prodType: OptionalProductionType;\n    rule: Rule;\n    maxLookahead: number;\n    dynamicTokensEnabled: boolean;\n  }): () => boolean {\n    return buildLookaheadFuncForOptionalProd(\n      options.prodOccurrence,\n      options.rule,\n      options.maxLookahead,\n      options.dynamicTokensEnabled,\n      getProdType(options.prodType),\n      buildSingleAlternativeLookaheadFunction,\n    );\n  }\n}\n","import { CstNode, CstNodeLocation, IToken } from \"@chevrotain/types\";\n\n/**\n * This nodeLocation tracking is not efficient and should only be used\n * when error recovery is enabled or the Token Vector contains virtual Tokens\n * (e.g, Python Indent/Outdent)\n * As it executes the calculation for every single terminal/nonTerminal\n * and does not rely on the fact the token vector is **sorted**\n */\nexport function setNodeLocationOnlyOffset(\n  currNodeLocation: CstNodeLocation,\n  newLocationInfo: Required<Pick<IToken, \"startOffset\" | \"endOffset\">>,\n): void {\n  // First (valid) update for this cst node\n  if (isNaN(currNodeLocation.startOffset) === true) {\n    // assumption1: Token location information is either NaN or a valid number\n    // assumption2: Token location information is fully valid if it exist\n    // (both start/end offsets exist and are numbers).\n    currNodeLocation.startOffset = newLocationInfo.startOffset;\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n  }\n  // Once the startOffset has been updated with a valid number it should never receive\n  // any farther updates as the Token vector is sorted.\n  // We still have to check this this condition for every new possible location info\n  // because with error recovery enabled we may encounter invalid tokens (NaN location props)\n  else if (currNodeLocation.endOffset! < newLocationInfo.endOffset === true) {\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n  }\n}\n\n/**\n * This nodeLocation tracking is not efficient and should only be used\n * when error recovery is enabled or the Token Vector contains virtual Tokens\n * (e.g, Python Indent/Outdent)\n * As it executes the calculation for every single terminal/nonTerminal\n * and does not rely on the fact the token vector is **sorted**\n */\nexport function setNodeLocationFull(\n  currNodeLocation: CstNodeLocation,\n  newLocationInfo: CstNodeLocation,\n): void {\n  // First (valid) update for this cst node\n  if (isNaN(currNodeLocation.startOffset) === true) {\n    // assumption1: Token location information is either NaN or a valid number\n    // assumption2: Token location information is fully valid if it exist\n    // (all start/end props exist and are numbers).\n    currNodeLocation.startOffset = newLocationInfo.startOffset;\n    currNodeLocation.startColumn = newLocationInfo.startColumn;\n    currNodeLocation.startLine = newLocationInfo.startLine;\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n    currNodeLocation.endColumn = newLocationInfo.endColumn;\n    currNodeLocation.endLine = newLocationInfo.endLine;\n  }\n  // Once the start props has been updated with a valid number it should never receive\n  // any farther updates as the Token vector is sorted.\n  // We still have to check this this condition for every new possible location info\n  // because with error recovery enabled we may encounter invalid tokens (NaN location props)\n  else if (currNodeLocation.endOffset! < newLocationInfo.endOffset! === true) {\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n    currNodeLocation.endColumn = newLocationInfo.endColumn;\n    currNodeLocation.endLine = newLocationInfo.endLine;\n  }\n}\n\nexport function addTerminalToCst(\n  node: CstNode,\n  token: IToken,\n  tokenTypeName: string,\n): void {\n  if (node.children[tokenTypeName] === undefined) {\n    node.children[tokenTypeName] = [token];\n  } else {\n    node.children[tokenTypeName].push(token);\n  }\n}\n\nexport function addNoneTerminalToCst(\n  node: CstNode,\n  ruleName: string,\n  ruleResult: any,\n): void {\n  if (node.children[ruleName] === undefined) {\n    node.children[ruleName] = [ruleResult];\n  } else {\n    node.children[ruleName].push(ruleResult);\n  }\n}\n","import {\n  addNoneTerminalToCst,\n  addTerminalToCst,\n  setNodeLocationFull,\n  setNodeLocationOnlyOffset,\n} from \"../../cst/cst.js\";\nimport { has, isUndefined, keys, noop } from \"lodash-es\";\nimport {\n  createBaseSemanticVisitorConstructor,\n  createBaseVisitorConstructorWithDefaults,\n} from \"../../cst/cst_visitor.js\";\nimport {\n  CstNode,\n  CstNodeLocation,\n  ICstVisitor,\n  IParserConfig,\n  IToken,\n  nodeLocationTrackingOptions,\n} from \"@chevrotain/types\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\n/**\n * This trait is responsible for the CST building logic.\n */\nexport class TreeBuilder {\n  outputCst: boolean;\n  CST_STACK: CstNode[];\n  baseCstVisitorConstructor: Function;\n  baseCstVisitorWithDefaultsConstructor: Function;\n\n  // dynamically assigned Methods\n  setNodeLocationFromNode: (\n    nodeLocation: CstNodeLocation,\n    locationInformation: CstNodeLocation,\n  ) => void;\n  setNodeLocationFromToken: (\n    nodeLocation: CstNodeLocation,\n    locationInformation: CstNodeLocation,\n  ) => void;\n  cstPostRule: (this: MixedInParser, ruleCstNode: CstNode) => void;\n\n  setInitialNodeLocation: (cstNode: CstNode) => void;\n  nodeLocationTracking: nodeLocationTrackingOptions;\n\n  initTreeBuilder(this: MixedInParser, config: IParserConfig) {\n    this.CST_STACK = [];\n\n    // outputCst is no longer exposed/defined in the pubic API\n    this.outputCst = (config as any).outputCst;\n\n    this.nodeLocationTracking = has(config, \"nodeLocationTracking\")\n      ? (config.nodeLocationTracking as nodeLocationTrackingOptions) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.nodeLocationTracking;\n\n    if (!this.outputCst) {\n      this.cstInvocationStateUpdate = noop;\n      this.cstFinallyStateUpdate = noop;\n      this.cstPostTerminal = noop;\n      this.cstPostNonTerminal = noop;\n      this.cstPostRule = noop;\n    } else {\n      if (/full/i.test(this.nodeLocationTracking)) {\n        if (this.recoveryEnabled) {\n          this.setNodeLocationFromToken = setNodeLocationFull;\n          this.setNodeLocationFromNode = setNodeLocationFull;\n          this.cstPostRule = noop;\n          this.setInitialNodeLocation = this.setInitialNodeLocationFullRecovery;\n        } else {\n          this.setNodeLocationFromToken = noop;\n          this.setNodeLocationFromNode = noop;\n          this.cstPostRule = this.cstPostRuleFull;\n          this.setInitialNodeLocation = this.setInitialNodeLocationFullRegular;\n        }\n      } else if (/onlyOffset/i.test(this.nodeLocationTracking)) {\n        if (this.recoveryEnabled) {\n          this.setNodeLocationFromToken = <any>setNodeLocationOnlyOffset;\n          this.setNodeLocationFromNode = <any>setNodeLocationOnlyOffset;\n          this.cstPostRule = noop;\n          this.setInitialNodeLocation =\n            this.setInitialNodeLocationOnlyOffsetRecovery;\n        } else {\n          this.setNodeLocationFromToken = noop;\n          this.setNodeLocationFromNode = noop;\n          this.cstPostRule = this.cstPostRuleOnlyOffset;\n          this.setInitialNodeLocation =\n            this.setInitialNodeLocationOnlyOffsetRegular;\n        }\n      } else if (/none/i.test(this.nodeLocationTracking)) {\n        this.setNodeLocationFromToken = noop;\n        this.setNodeLocationFromNode = noop;\n        this.cstPostRule = noop;\n        this.setInitialNodeLocation = noop;\n      } else {\n        throw Error(\n          `Invalid <nodeLocationTracking> config option: \"${config.nodeLocationTracking}\"`,\n        );\n      }\n    }\n  }\n\n  setInitialNodeLocationOnlyOffsetRecovery(\n    this: MixedInParser,\n    cstNode: any,\n  ): void {\n    cstNode.location = {\n      startOffset: NaN,\n      endOffset: NaN,\n    };\n  }\n\n  setInitialNodeLocationOnlyOffsetRegular(\n    this: MixedInParser,\n    cstNode: any,\n  ): void {\n    cstNode.location = {\n      // without error recovery the starting Location of a new CstNode is guaranteed\n      // To be the next Token's startOffset (for valid inputs).\n      // For invalid inputs there won't be any CSTOutput so this potential\n      // inaccuracy does not matter\n      startOffset: this.LA(1).startOffset,\n      endOffset: NaN,\n    };\n  }\n\n  setInitialNodeLocationFullRecovery(this: MixedInParser, cstNode: any): void {\n    cstNode.location = {\n      startOffset: NaN,\n      startLine: NaN,\n      startColumn: NaN,\n      endOffset: NaN,\n      endLine: NaN,\n      endColumn: NaN,\n    };\n  }\n\n  /**\n     *  @see setInitialNodeLocationOnlyOffsetRegular for explanation why this work\n\n     * @param cstNode\n     */\n  setInitialNodeLocationFullRegular(this: MixedInParser, cstNode: any): void {\n    const nextToken = this.LA(1);\n    cstNode.location = {\n      startOffset: nextToken.startOffset,\n      startLine: nextToken.startLine,\n      startColumn: nextToken.startColumn,\n      endOffset: NaN,\n      endLine: NaN,\n      endColumn: NaN,\n    };\n  }\n\n  cstInvocationStateUpdate(this: MixedInParser, fullRuleName: string): void {\n    const cstNode: CstNode = {\n      name: fullRuleName,\n      children: Object.create(null),\n    };\n\n    this.setInitialNodeLocation(cstNode);\n    this.CST_STACK.push(cstNode);\n  }\n\n  cstFinallyStateUpdate(this: MixedInParser): void {\n    this.CST_STACK.pop();\n  }\n\n  cstPostRuleFull(this: MixedInParser, ruleCstNode: CstNode): void {\n    // casts to `required<CstNodeLocation>` are safe because `cstPostRuleFull` should only be invoked when full location is enabled\n    const prevToken = this.LA(0) as Required<CstNodeLocation>;\n    const loc = ruleCstNode.location as Required<CstNodeLocation>;\n\n    // If this condition is true it means we consumed at least one Token\n    // In this CstNode.\n    if (loc.startOffset <= prevToken.startOffset === true) {\n      loc.endOffset = prevToken.endOffset;\n      loc.endLine = prevToken.endLine;\n      loc.endColumn = prevToken.endColumn;\n    }\n    // \"empty\" CstNode edge case\n    else {\n      loc.startOffset = NaN;\n      loc.startLine = NaN;\n      loc.startColumn = NaN;\n    }\n  }\n\n  cstPostRuleOnlyOffset(this: MixedInParser, ruleCstNode: CstNode): void {\n    const prevToken = this.LA(0);\n    // `location' is not null because `cstPostRuleOnlyOffset` will only be invoked when location tracking is enabled.\n    const loc = ruleCstNode.location!;\n\n    // If this condition is true it means we consumed at least one Token\n    // In this CstNode.\n    if (loc.startOffset <= prevToken.startOffset === true) {\n      loc.endOffset = prevToken.endOffset;\n    }\n    // \"empty\" CstNode edge case\n    else {\n      loc.startOffset = NaN;\n    }\n  }\n\n  cstPostTerminal(\n    this: MixedInParser,\n    key: string,\n    consumedToken: IToken,\n  ): void {\n    const rootCst = this.CST_STACK[this.CST_STACK.length - 1];\n    addTerminalToCst(rootCst, consumedToken, key);\n    // This is only used when **both** error recovery and CST Output are enabled.\n    this.setNodeLocationFromToken(rootCst.location!, <any>consumedToken);\n  }\n\n  cstPostNonTerminal(\n    this: MixedInParser,\n    ruleCstResult: CstNode,\n    ruleName: string,\n  ): void {\n    const preCstNode = this.CST_STACK[this.CST_STACK.length - 1];\n    addNoneTerminalToCst(preCstNode, ruleName, ruleCstResult);\n    // This is only used when **both** error recovery and CST Output are enabled.\n    this.setNodeLocationFromNode(preCstNode.location!, ruleCstResult.location!);\n  }\n\n  getBaseCstVisitorConstructor<IN = any, OUT = any>(\n    this: MixedInParser,\n  ): {\n    new (...args: any[]): ICstVisitor<IN, OUT>;\n  } {\n    if (isUndefined(this.baseCstVisitorConstructor)) {\n      const newBaseCstVisitorConstructor = createBaseSemanticVisitorConstructor(\n        this.className,\n        keys(this.gastProductionsCache),\n      );\n      this.baseCstVisitorConstructor = newBaseCstVisitorConstructor;\n      return newBaseCstVisitorConstructor;\n    }\n\n    return <any>this.baseCstVisitorConstructor;\n  }\n\n  getBaseCstVisitorConstructorWithDefaults<IN = any, OUT = any>(\n    this: MixedInParser,\n  ): {\n    new (...args: any[]): ICstVisitor<IN, OUT>;\n  } {\n    if (isUndefined(this.baseCstVisitorWithDefaultsConstructor)) {\n      const newConstructor = createBaseVisitorConstructorWithDefaults(\n        this.className,\n        keys(this.gastProductionsCache),\n        this.getBaseCstVisitorConstructor(),\n      );\n      this.baseCstVisitorWithDefaultsConstructor = newConstructor;\n      return newConstructor;\n    }\n\n    return <any>this.baseCstVisitorWithDefaultsConstructor;\n  }\n\n  getLastExplicitRuleShortName(this: MixedInParser): number {\n    const ruleStack = this.RULE_STACK;\n    return ruleStack[ruleStack.length - 1];\n  }\n\n  getPreviousExplicitRuleShortName(this: MixedInParser): number {\n    const ruleStack = this.RULE_STACK;\n    return ruleStack[ruleStack.length - 2];\n  }\n\n  getLastExplicitRuleOccurrenceIndex(this: MixedInParser): number {\n    const occurrenceStack = this.RULE_OCCURRENCE_STACK;\n    return occurrenceStack[occurrenceStack.length - 1];\n  }\n}\n","import {\n  compact,\n  filter,\n  forEach,\n  isArray,\n  isEmpty,\n  isFunction,\n  isUndefined,\n  keys,\n  map,\n} from \"lodash-es\";\nimport { defineNameProp } from \"../../lang/lang_extensions.js\";\nimport { CstNode, ICstVisitor } from \"@chevrotain/types\";\n\nexport function defaultVisit<IN>(ctx: any, param: IN): void {\n  const childrenNames = keys(ctx);\n  const childrenNamesLength = childrenNames.length;\n  for (let i = 0; i < childrenNamesLength; i++) {\n    const currChildName = childrenNames[i];\n    const currChildArray = ctx[currChildName];\n    const currChildArrayLength = currChildArray.length;\n    for (let j = 0; j < currChildArrayLength; j++) {\n      const currChild: any = currChildArray[j];\n      // distinction between Tokens Children and CstNode children\n      if (currChild.tokenTypeIdx === undefined) {\n        this[currChild.name](currChild.children, param);\n      }\n    }\n  }\n  // defaultVisit does not support generic out param\n}\n\nexport function createBaseSemanticVisitorConstructor(\n  grammarName: string,\n  ruleNames: string[],\n): {\n  new (...args: any[]): ICstVisitor<any, any>;\n} {\n  const derivedConstructor: any = function () {};\n\n  // can be overwritten according to:\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/\n  // name?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FGlobal_Objects%2FFunction%2Fname\n  defineNameProp(derivedConstructor, grammarName + \"BaseSemantics\");\n\n  const semanticProto = {\n    visit: function (cstNode: CstNode | CstNode[], param: any) {\n      // enables writing more concise visitor methods when CstNode has only a single child\n      if (isArray(cstNode)) {\n        // A CST Node's children dictionary can never have empty arrays as values\n        // If a key is defined there will be at least one element in the corresponding value array.\n        cstNode = cstNode[0];\n      }\n\n      // enables passing optional CstNodes concisely.\n      if (isUndefined(cstNode)) {\n        return undefined;\n      }\n\n      return this[cstNode.name](cstNode.children, param);\n    },\n\n    validateVisitor: function () {\n      const semanticDefinitionErrors = validateVisitor(this, ruleNames);\n      if (!isEmpty(semanticDefinitionErrors)) {\n        const errorMessages = map(\n          semanticDefinitionErrors,\n          (currDefError) => currDefError.msg,\n        );\n        throw Error(\n          `Errors Detected in CST Visitor <${this.constructor.name}>:\\n\\t` +\n            `${errorMessages.join(\"\\n\\n\").replace(/\\n/g, \"\\n\\t\")}`,\n        );\n      }\n    },\n  };\n\n  derivedConstructor.prototype = semanticProto;\n  derivedConstructor.prototype.constructor = derivedConstructor;\n\n  derivedConstructor._RULE_NAMES = ruleNames;\n\n  return derivedConstructor;\n}\n\nexport function createBaseVisitorConstructorWithDefaults(\n  grammarName: string,\n  ruleNames: string[],\n  baseConstructor: Function,\n): {\n  new (...args: any[]): ICstVisitor<any, any>;\n} {\n  const derivedConstructor: any = function () {};\n\n  // can be overwritten according to:\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/\n  // name?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FGlobal_Objects%2FFunction%2Fname\n  defineNameProp(derivedConstructor, grammarName + \"BaseSemanticsWithDefaults\");\n\n  const withDefaultsProto = Object.create(baseConstructor.prototype);\n  forEach(ruleNames, (ruleName) => {\n    withDefaultsProto[ruleName] = defaultVisit;\n  });\n\n  derivedConstructor.prototype = withDefaultsProto;\n  derivedConstructor.prototype.constructor = derivedConstructor;\n\n  return derivedConstructor;\n}\n\nexport enum CstVisitorDefinitionError {\n  REDUNDANT_METHOD,\n  MISSING_METHOD,\n}\n\nexport interface IVisitorDefinitionError {\n  msg: string;\n  type: CstVisitorDefinitionError;\n  methodName: string;\n}\n\nexport function validateVisitor(\n  visitorInstance: ICstVisitor<unknown, unknown>,\n  ruleNames: string[],\n): IVisitorDefinitionError[] {\n  const missingErrors = validateMissingCstMethods(visitorInstance, ruleNames);\n\n  return missingErrors;\n}\n\nexport function validateMissingCstMethods(\n  visitorInstance: ICstVisitor<unknown, unknown>,\n  ruleNames: string[],\n): IVisitorDefinitionError[] {\n  const missingRuleNames = filter(ruleNames, (currRuleName) => {\n    return isFunction((visitorInstance as any)[currRuleName]) === false;\n  });\n\n  const errors: IVisitorDefinitionError[] = map(\n    missingRuleNames,\n    (currRuleName) => {\n      return {\n        msg: `Missing visitor method: <${currRuleName}> on ${<any>(\n          visitorInstance.constructor.name\n        )} CST Visitor.`,\n        type: CstVisitorDefinitionError.MISSING_METHOD,\n        methodName: currRuleName,\n      };\n    },\n  );\n\n  return compact<IVisitorDefinitionError>(errors);\n}\n","const NAME = \"name\";\n\nexport function defineNameProp(obj: {}, nameValue: string): void {\n  Object.defineProperty(obj, NAME, {\n    enumerable: false,\n    configurable: true,\n    writable: false,\n    value: nameValue,\n  });\n}\n","import { END_OF_FILE } from \"../parser.js\";\nimport { IToken } from \"@chevrotain/types\";\nimport { MixedInParser } from \"./parser_traits.js\";\n\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\nexport class LexerAdapter {\n  tokVector: IToken[];\n  tokVectorLength: number;\n  currIdx: number;\n\n  initLexerAdapter() {\n    this.tokVector = [];\n    this.tokVectorLength = 0;\n    this.currIdx = -1;\n  }\n\n  set input(newInput: IToken[]) {\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    if (this.selfAnalysisDone !== true) {\n      throw Error(\n        `Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.`,\n      );\n    }\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    this.reset();\n    this.tokVector = newInput;\n    this.tokVectorLength = newInput.length;\n  }\n\n  get input(): IToken[] {\n    return this.tokVector;\n  }\n\n  // skips a token and returns the next token\n  SKIP_TOKEN(this: MixedInParser): IToken {\n    if (this.currIdx <= this.tokVector.length - 2) {\n      this.consumeToken();\n      return this.LA(1);\n    } else {\n      return END_OF_FILE;\n    }\n  }\n\n  // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n  // or lexers dependent on parser context.\n  LA(this: MixedInParser, howMuch: number): IToken {\n    const soughtIdx = this.currIdx + howMuch;\n    if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n      return END_OF_FILE;\n    } else {\n      return this.tokVector[soughtIdx];\n    }\n  }\n\n  consumeToken(this: MixedInParser) {\n    this.currIdx++;\n  }\n\n  exportLexerState(this: MixedInParser): number {\n    return this.currIdx;\n  }\n\n  importLexerState(this: MixedInParser, newState: number) {\n    this.currIdx = newState;\n  }\n\n  resetLexerState(this: MixedInParser): void {\n    this.currIdx = -1;\n  }\n\n  moveToTerminatedState(this: MixedInParser): void {\n    this.currIdx = this.tokVector.length - 1;\n  }\n\n  getLexerPosition(this: MixedInParser): number {\n    return this.exportLexerState();\n  }\n}\n","import {\n  AtLeastOneSepMethodOpts,\n  ConsumeMethodOpts,\n  DSLMethodOpts,\n  DSLMethodOptsWithErr,\n  GrammarAction,\n  IOrAlt,\n  IRuleConfig,\n  ISerializedGast,\n  IToken,\n  ManySepMethodOpts,\n  OrMethodOpts,\n  SubruleMethodOpts,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { includes, values } from \"lodash-es\";\nimport { isRecognitionException } from \"../../exceptions_public.js\";\nimport { DEFAULT_RULE_CONFIG, ParserDefinitionErrorType } from \"../parser.js\";\nimport { defaultGrammarValidatorErrorProvider } from \"../../errors_public.js\";\nimport { validateRuleIsOverridden } from \"../../grammar/checks.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { Rule, serializeGrammar } from \"@chevrotain/gast\";\nimport { IParserDefinitionError } from \"../../grammar/types.js\";\nimport { ParserMethodInternal } from \"../types.js\";\n\n/**\n * This trait is responsible for implementing the public API\n * for defining Chevrotain parsers, i.e:\n * - CONSUME\n * - RULE\n * - OPTION\n * - ...\n */\nexport class RecognizerApi {\n  ACTION<T>(this: MixedInParser, impl: () => T): T {\n    return impl.call(this);\n  }\n\n  consume(\n    this: MixedInParser,\n    idx: number,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, idx, options);\n  }\n\n  subrule<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    idx: number,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, idx, options);\n  }\n\n  option<OUT>(\n    this: MixedInParser,\n    idx: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, idx);\n  }\n\n  or(\n    this: MixedInParser,\n    idx: number,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<any>,\n  ): any {\n    return this.orInternal(altsOrOpts, idx);\n  }\n\n  many(\n    this: MixedInParser,\n    idx: number,\n    actionORMethodDef: GrammarAction<any> | DSLMethodOpts<any>,\n  ): void {\n    return this.manyInternal(idx, actionORMethodDef);\n  }\n\n  atLeastOne(\n    this: MixedInParser,\n    idx: number,\n    actionORMethodDef: GrammarAction<any> | DSLMethodOptsWithErr<any>,\n  ): void {\n    return this.atLeastOneInternal(idx, actionORMethodDef);\n  }\n\n  CONSUME(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 0, options);\n  }\n\n  CONSUME1(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 1, options);\n  }\n\n  CONSUME2(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 2, options);\n  }\n\n  CONSUME3(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 3, options);\n  }\n\n  CONSUME4(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 4, options);\n  }\n\n  CONSUME5(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 5, options);\n  }\n\n  CONSUME6(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 6, options);\n  }\n\n  CONSUME7(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 7, options);\n  }\n\n  CONSUME8(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 8, options);\n  }\n\n  CONSUME9(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 9, options);\n  }\n\n  SUBRULE<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 0, options);\n  }\n\n  SUBRULE1<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 1, options);\n  }\n\n  SUBRULE2<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 2, options);\n  }\n\n  SUBRULE3<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 3, options);\n  }\n\n  SUBRULE4<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 4, options);\n  }\n\n  SUBRULE5<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 5, options);\n  }\n\n  SUBRULE6<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 6, options);\n  }\n\n  SUBRULE7<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 7, options);\n  }\n\n  SUBRULE8<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 8, options);\n  }\n\n  SUBRULE9<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 9, options);\n  }\n\n  OPTION<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 0);\n  }\n\n  OPTION1<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 1);\n  }\n\n  OPTION2<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 2);\n  }\n\n  OPTION3<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 3);\n  }\n\n  OPTION4<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 4);\n  }\n\n  OPTION5<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 5);\n  }\n\n  OPTION6<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 6);\n  }\n\n  OPTION7<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 7);\n  }\n\n  OPTION8<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 8);\n  }\n\n  OPTION9<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 9);\n  }\n\n  OR<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 0);\n  }\n\n  OR1<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 1);\n  }\n\n  OR2<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 2);\n  }\n\n  OR3<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 3);\n  }\n\n  OR4<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 4);\n  }\n\n  OR5<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 5);\n  }\n\n  OR6<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 6);\n  }\n\n  OR7<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 7);\n  }\n\n  OR8<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 8);\n  }\n\n  OR9<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 9);\n  }\n\n  MANY<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(0, actionORMethodDef);\n  }\n\n  MANY1<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(1, actionORMethodDef);\n  }\n\n  MANY2<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(2, actionORMethodDef);\n  }\n\n  MANY3<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(3, actionORMethodDef);\n  }\n\n  MANY4<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(4, actionORMethodDef);\n  }\n\n  MANY5<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(5, actionORMethodDef);\n  }\n\n  MANY6<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(6, actionORMethodDef);\n  }\n\n  MANY7<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(7, actionORMethodDef);\n  }\n\n  MANY8<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(8, actionORMethodDef);\n  }\n\n  MANY9<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(9, actionORMethodDef);\n  }\n\n  MANY_SEP<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(0, options);\n  }\n\n  MANY_SEP1<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(1, options);\n  }\n\n  MANY_SEP2<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(2, options);\n  }\n\n  MANY_SEP3<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(3, options);\n  }\n\n  MANY_SEP4<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(4, options);\n  }\n\n  MANY_SEP5<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(5, options);\n  }\n\n  MANY_SEP6<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(6, options);\n  }\n\n  MANY_SEP7<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(7, options);\n  }\n\n  MANY_SEP8<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(8, options);\n  }\n\n  MANY_SEP9<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(9, options);\n  }\n\n  AT_LEAST_ONE<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(0, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE1<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    return this.atLeastOneInternal(1, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE2<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(2, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE3<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(3, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE4<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(4, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE5<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(5, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE6<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(6, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE7<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(7, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE8<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(8, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE9<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(9, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE_SEP<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(0, options);\n  }\n\n  AT_LEAST_ONE_SEP1<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(1, options);\n  }\n\n  AT_LEAST_ONE_SEP2<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(2, options);\n  }\n\n  AT_LEAST_ONE_SEP3<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(3, options);\n  }\n\n  AT_LEAST_ONE_SEP4<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(4, options);\n  }\n\n  AT_LEAST_ONE_SEP5<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(5, options);\n  }\n\n  AT_LEAST_ONE_SEP6<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(6, options);\n  }\n\n  AT_LEAST_ONE_SEP7<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(7, options);\n  }\n\n  AT_LEAST_ONE_SEP8<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(8, options);\n  }\n\n  AT_LEAST_ONE_SEP9<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(9, options);\n  }\n\n  RULE<T>(\n    this: MixedInParser,\n    name: string,\n    implementation: (...implArgs: any[]) => T,\n    config: IRuleConfig<T> = DEFAULT_RULE_CONFIG,\n  ): (idxInCallingRule?: number, ...args: any[]) => T | any {\n    if (includes(this.definedRulesNames, name)) {\n      const errMsg =\n        defaultGrammarValidatorErrorProvider.buildDuplicateRuleNameError({\n          topLevelRule: name,\n          grammarName: this.className,\n        });\n\n      const error = {\n        message: errMsg,\n        type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n        ruleName: name,\n      };\n      this.definitionErrors.push(error);\n    }\n\n    this.definedRulesNames.push(name);\n\n    const ruleImplementation = this.defineRule(name, implementation, config);\n    (this as any)[name] = ruleImplementation;\n    return ruleImplementation;\n  }\n\n  OVERRIDE_RULE<T>(\n    this: MixedInParser,\n    name: string,\n    impl: (...implArgs: any[]) => T,\n    config: IRuleConfig<T> = DEFAULT_RULE_CONFIG,\n  ): (idxInCallingRule?: number, ...args: any[]) => T {\n    const ruleErrors: IParserDefinitionError[] = validateRuleIsOverridden(\n      name,\n      this.definedRulesNames,\n      this.className,\n    );\n    this.definitionErrors = this.definitionErrors.concat(ruleErrors);\n\n    const ruleImplementation = this.defineRule(name, impl, config);\n    (this as any)[name] = ruleImplementation;\n    return ruleImplementation;\n  }\n\n  BACKTRACK<T>(\n    this: MixedInParser,\n    grammarRule: (...args: any[]) => T,\n    args?: any[],\n  ): () => boolean {\n    return function () {\n      // save org state\n      this.isBackTrackingStack.push(1);\n      const orgState = this.saveRecogState();\n      try {\n        grammarRule.apply(this, args);\n        // if no exception was thrown we have succeed parsing the rule.\n        return true;\n      } catch (e) {\n        if (isRecognitionException(e)) {\n          return false;\n        } else {\n          throw e;\n        }\n      } finally {\n        this.reloadRecogState(orgState);\n        this.isBackTrackingStack.pop();\n      }\n    };\n  }\n\n  // GAST export APIs\n  public getGAstProductions(this: MixedInParser): Record<string, Rule> {\n    return this.gastProductionsCache;\n  }\n\n  public getSerializedGastProductions(this: MixedInParser): ISerializedGast[] {\n    return serializeGrammar(values(this.gastProductionsCache));\n  }\n}\n","import {\n  AtLeastOneSepMethodOpts,\n  ConsumeMethodOpts,\n  DSLMethodOpts,\n  DSLMethodOptsWithErr,\n  GrammarAction,\n  IOrAlt,\n  IParserConfig,\n  IRuleConfig,\n  IToken,\n  ManySepMethodOpts,\n  OrMethodOpts,\n  ParserMethod,\n  SubruleMethodOpts,\n  TokenType,\n  TokenTypeDictionary,\n  TokenVocabulary,\n} from \"@chevrotain/types\";\nimport {\n  clone,\n  every,\n  flatten,\n  has,\n  isArray,\n  isEmpty,\n  isObject,\n  reduce,\n  uniq,\n  values,\n} from \"lodash-es\";\nimport {\n  AT_LEAST_ONE_IDX,\n  AT_LEAST_ONE_SEP_IDX,\n  BITS_FOR_METHOD_TYPE,\n  BITS_FOR_OCCURRENCE_IDX,\n  MANY_IDX,\n  MANY_SEP_IDX,\n  OPTION_IDX,\n  OR_IDX,\n} from \"../../grammar/keys.js\";\nimport {\n  isRecognitionException,\n  MismatchedTokenException,\n  NotAllInputParsedException,\n} from \"../../exceptions_public.js\";\nimport { PROD_TYPE } from \"../../grammar/lookahead.js\";\nimport {\n  AbstractNextTerminalAfterProductionWalker,\n  NextTerminalAfterAtLeastOneSepWalker,\n  NextTerminalAfterAtLeastOneWalker,\n  NextTerminalAfterManySepWalker,\n  NextTerminalAfterManyWalker,\n} from \"../../grammar/interpreter.js\";\nimport { DEFAULT_RULE_CONFIG, IParserState, TokenMatcher } from \"../parser.js\";\nimport { IN_RULE_RECOVERY_EXCEPTION } from \"./recoverable.js\";\nimport { EOF } from \"../../../scan/tokens_public.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport {\n  augmentTokenTypes,\n  isTokenType,\n  tokenStructuredMatcher,\n  tokenStructuredMatcherNoCategories,\n} from \"../../../scan/tokens.js\";\nimport { Rule } from \"@chevrotain/gast\";\nimport { ParserMethodInternal } from \"../types.js\";\n\n/**\n * This trait is responsible for the runtime parsing engine\n * Used by the official API (recognizer_api.ts)\n */\nexport class RecognizerEngine {\n  isBackTrackingStack: boolean[];\n  className: string;\n  RULE_STACK: number[];\n  RULE_OCCURRENCE_STACK: number[];\n  definedRulesNames: string[];\n  tokensMap: { [fqn: string]: TokenType };\n  gastProductionsCache: Record<string, Rule>;\n  shortRuleNameToFull: Record<string, string>;\n  fullRuleNameToShort: Record<string, number>;\n  // The shortName Index must be coded \"after\" the first 8bits to enable building unique lookahead keys\n  ruleShortNameIdx: number;\n  tokenMatcher: TokenMatcher;\n  subruleIdx: number;\n\n  initRecognizerEngine(\n    tokenVocabulary: TokenVocabulary,\n    config: IParserConfig,\n  ) {\n    this.className = this.constructor.name;\n    // TODO: would using an ES6 Map or plain object be faster (CST building scenario)\n    this.shortRuleNameToFull = {};\n    this.fullRuleNameToShort = {};\n    this.ruleShortNameIdx = 256;\n    this.tokenMatcher = tokenStructuredMatcherNoCategories;\n    this.subruleIdx = 0;\n\n    this.definedRulesNames = [];\n    this.tokensMap = {};\n    this.isBackTrackingStack = [];\n    this.RULE_STACK = [];\n    this.RULE_OCCURRENCE_STACK = [];\n    this.gastProductionsCache = {};\n\n    if (has(config, \"serializedGrammar\")) {\n      throw Error(\n        \"The Parser's configuration can no longer contain a <serializedGrammar> property.\\n\" +\n          \"\\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_6-0-0\\n\" +\n          \"\\tFor Further details.\",\n      );\n    }\n\n    if (isArray(tokenVocabulary)) {\n      // This only checks for Token vocabularies provided as arrays.\n      // That is good enough because the main objective is to detect users of pre-V4.0 APIs\n      // rather than all edge cases of empty Token vocabularies.\n      if (isEmpty(tokenVocabulary as any[])) {\n        throw Error(\n          \"A Token Vocabulary cannot be empty.\\n\" +\n            \"\\tNote that the first argument for the parser constructor\\n\" +\n            \"\\tis no longer a Token vector (since v4.0).\",\n        );\n      }\n\n      if (typeof (tokenVocabulary as any[])[0].startOffset === \"number\") {\n        throw Error(\n          \"The Parser constructor no longer accepts a token vector as the first argument.\\n\" +\n            \"\\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_4-0-0\\n\" +\n            \"\\tFor Further details.\",\n        );\n      }\n    }\n\n    if (isArray(tokenVocabulary)) {\n      this.tokensMap = reduce(\n        tokenVocabulary,\n        (acc, tokType: TokenType) => {\n          acc[tokType.name] = tokType;\n          return acc;\n        },\n        {} as { [tokenName: string]: TokenType },\n      );\n    } else if (\n      has(tokenVocabulary, \"modes\") &&\n      every(flatten(values((<any>tokenVocabulary).modes)), isTokenType)\n    ) {\n      const allTokenTypes = flatten(values((<any>tokenVocabulary).modes));\n      const uniqueTokens = uniq(allTokenTypes);\n      this.tokensMap = <any>reduce(\n        uniqueTokens,\n        (acc, tokType: TokenType) => {\n          acc[tokType.name] = tokType;\n          return acc;\n        },\n        {} as { [tokenName: string]: TokenType },\n      );\n    } else if (isObject(tokenVocabulary)) {\n      this.tokensMap = clone(tokenVocabulary as TokenTypeDictionary);\n    } else {\n      throw new Error(\n        \"<tokensDictionary> argument must be An Array of Token constructors,\" +\n          \" A dictionary of Token constructors or an IMultiModeLexerDefinition\",\n      );\n    }\n\n    // always add EOF to the tokenNames -> constructors map. it is useful to assure all the input has been\n    // parsed with a clear error message (\"expecting EOF but found ...\")\n    this.tokensMap[\"EOF\"] = EOF;\n\n    const allTokenTypes = has(tokenVocabulary, \"modes\")\n      ? flatten(values((<any>tokenVocabulary).modes))\n      : values(tokenVocabulary);\n    const noTokenCategoriesUsed = every(allTokenTypes, (tokenConstructor) =>\n      isEmpty(tokenConstructor.categoryMatches),\n    );\n\n    this.tokenMatcher = noTokenCategoriesUsed\n      ? tokenStructuredMatcherNoCategories\n      : tokenStructuredMatcher;\n\n    // Because ES2015+ syntax should be supported for creating Token classes\n    // We cannot assume that the Token classes were created using the \"extendToken\" utilities\n    // Therefore we must augment the Token classes both on Lexer initialization and on Parser initialization\n    augmentTokenTypes(values(this.tokensMap));\n  }\n\n  defineRule<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleName: string,\n    impl: (...args: ARGS) => R,\n    config: IRuleConfig<R>,\n  ): ParserMethodInternal<ARGS, R> {\n    if (this.selfAnalysisDone) {\n      throw Error(\n        `Grammar rule <${ruleName}> may not be defined after the 'performSelfAnalysis' method has been called'\\n` +\n          `Make sure that all grammar rule definitions are done before 'performSelfAnalysis' is called.`,\n      );\n    }\n    const resyncEnabled: boolean = has(config, \"resyncEnabled\")\n      ? (config.resyncEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_RULE_CONFIG.resyncEnabled;\n    const recoveryValueFunc = has(config, \"recoveryValueFunc\")\n      ? (config.recoveryValueFunc as () => R) // assumes end user provides the correct config value/type\n      : DEFAULT_RULE_CONFIG.recoveryValueFunc;\n\n    // performance optimization: Use small integers as keys for the longer human readable \"full\" rule names.\n    // this greatly improves Map access time (as much as 8% for some performance benchmarks).\n    const shortName =\n      this.ruleShortNameIdx << (BITS_FOR_METHOD_TYPE + BITS_FOR_OCCURRENCE_IDX);\n\n    this.ruleShortNameIdx++;\n    this.shortRuleNameToFull[shortName] = ruleName;\n    this.fullRuleNameToShort[ruleName] = shortName;\n\n    let invokeRuleWithTry: ParserMethod<ARGS, R>;\n\n    // Micro optimization, only check the condition **once** on rule definition\n    // instead of **every single** rule invocation.\n    if (this.outputCst === true) {\n      invokeRuleWithTry = function invokeRuleWithTry(\n        this: MixedInParser,\n        ...args: ARGS\n      ): R {\n        try {\n          this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n          impl.apply(this, args);\n          const cst = this.CST_STACK[this.CST_STACK.length - 1];\n          this.cstPostRule(cst);\n          return cst as unknown as R;\n        } catch (e) {\n          return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc) as R;\n        } finally {\n          this.ruleFinallyStateUpdate();\n        }\n      };\n    } else {\n      invokeRuleWithTry = function invokeRuleWithTryCst(\n        this: MixedInParser,\n        ...args: ARGS\n      ): R {\n        try {\n          this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n          return impl.apply(this, args);\n        } catch (e) {\n          return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc) as R;\n        } finally {\n          this.ruleFinallyStateUpdate();\n        }\n      };\n    }\n\n    const wrappedGrammarRule: ParserMethodInternal<ARGS, R> = Object.assign(\n      invokeRuleWithTry as any,\n      { ruleName, originalGrammarAction: impl },\n    );\n\n    return wrappedGrammarRule;\n  }\n\n  invokeRuleCatch(\n    this: MixedInParser,\n    e: Error,\n    resyncEnabledConfig: boolean,\n    recoveryValueFunc: Function,\n  ): unknown {\n    const isFirstInvokedRule = this.RULE_STACK.length === 1;\n    // note the reSync is always enabled for the first rule invocation, because we must always be able to\n    // reSync with EOF and just output some INVALID ParseTree\n    // during backtracking reSync recovery is disabled, otherwise we can't be certain the backtracking\n    // path is really the most valid one\n    const reSyncEnabled =\n      resyncEnabledConfig && !this.isBackTracking() && this.recoveryEnabled;\n\n    if (isRecognitionException(e)) {\n      const recogError: any = e;\n      if (reSyncEnabled) {\n        const reSyncTokType = this.findReSyncTokenType();\n        if (this.isInCurrentRuleReSyncSet(reSyncTokType)) {\n          recogError.resyncedTokens = this.reSyncTo(reSyncTokType);\n          if (this.outputCst) {\n            const partialCstResult: any =\n              this.CST_STACK[this.CST_STACK.length - 1];\n            partialCstResult.recoveredNode = true;\n            return partialCstResult;\n          } else {\n            return recoveryValueFunc(e);\n          }\n        } else {\n          if (this.outputCst) {\n            const partialCstResult: any =\n              this.CST_STACK[this.CST_STACK.length - 1];\n            partialCstResult.recoveredNode = true;\n            recogError.partialCstResult = partialCstResult;\n          }\n          // to be handled Further up the call stack\n          throw recogError;\n        }\n      } else if (isFirstInvokedRule) {\n        // otherwise a Redundant input error will be created as well and we cannot guarantee that this is indeed the case\n        this.moveToTerminatedState();\n        // the parser should never throw one of its own errors outside its flow.\n        // even if error recovery is disabled\n        return recoveryValueFunc(e);\n      } else {\n        // to be recovered Further up the call stack\n        throw recogError;\n      }\n    } else {\n      // some other Error type which we don't know how to handle (for example a built in JavaScript Error)\n      throw e;\n    }\n  }\n\n  // Implementation of parsing DSL\n  optionInternal<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    occurrence: number,\n  ): OUT | undefined {\n    const key = this.getKeyForAutomaticLookahead(OPTION_IDX, occurrence);\n    return this.optionInternalLogic(actionORMethodDef, occurrence, key);\n  }\n\n  optionInternalLogic<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    occurrence: number,\n    key: number,\n  ): OUT | undefined {\n    let lookAheadFunc = this.getLaFuncFromCache(key);\n    let action: GrammarAction<OUT>;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      // predicate present\n      if (predicate !== undefined) {\n        const orgLookaheadFunction = lookAheadFunc;\n        lookAheadFunc = () => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        };\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n\n    if (lookAheadFunc.call(this) === true) {\n      return action.call(this);\n    }\n    return undefined;\n  }\n\n  atLeastOneInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(\n      AT_LEAST_ONE_IDX,\n      prodOccurrence,\n    );\n    return this.atLeastOneInternalLogic(\n      prodOccurrence,\n      actionORMethodDef,\n      laKey,\n    );\n  }\n\n  atLeastOneInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n    key: number,\n  ): void {\n    let lookAheadFunc = this.getLaFuncFromCache(key);\n    let action;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      // predicate present\n      if (predicate !== undefined) {\n        const orgLookaheadFunction = lookAheadFunc;\n        lookAheadFunc = () => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        };\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n\n    if ((<Function>lookAheadFunc).call(this) === true) {\n      let notStuck = this.doSingleRepetition(action);\n      while (\n        (<Function>lookAheadFunc).call(this) === true &&\n        notStuck === true\n      ) {\n        notStuck = this.doSingleRepetition(action);\n      }\n    } else {\n      throw this.raiseEarlyExitException(\n        prodOccurrence,\n        PROD_TYPE.REPETITION_MANDATORY,\n        (<DSLMethodOptsWithErr<OUT>>actionORMethodDef).ERR_MSG,\n      );\n    }\n\n    // note that while it may seem that this can cause an error because by using a recursive call to\n    // AT_LEAST_ONE we change the grammar to AT_LEAST_TWO, AT_LEAST_THREE ... , the possible recursive call\n    // from the tryInRepetitionRecovery(...) will only happen IFF there really are TWO/THREE/.... items.\n\n    // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n    this.attemptInRepetitionRecovery(\n      this.atLeastOneInternal,\n      [prodOccurrence, actionORMethodDef],\n      <any>lookAheadFunc,\n      AT_LEAST_ONE_IDX,\n      prodOccurrence,\n      NextTerminalAfterAtLeastOneWalker,\n    );\n  }\n\n  atLeastOneSepFirstInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(\n      AT_LEAST_ONE_SEP_IDX,\n      prodOccurrence,\n    );\n    this.atLeastOneSepFirstInternalLogic(prodOccurrence, options, laKey);\n  }\n\n  atLeastOneSepFirstInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: AtLeastOneSepMethodOpts<OUT>,\n    key: number,\n  ): void {\n    const action = options.DEF;\n    const separator = options.SEP;\n\n    const firstIterationLookaheadFunc = this.getLaFuncFromCache(key);\n\n    // 1st iteration\n    if (firstIterationLookaheadFunc.call(this) === true) {\n      (<GrammarAction<OUT>>action).call(this);\n\n      //  TODO: Optimization can move this function construction into \"attemptInRepetitionRecovery\"\n      //  because it is only needed in error recovery scenarios.\n      const separatorLookAheadFunc = () => {\n        return this.tokenMatcher(this.LA(1), separator);\n      };\n\n      // 2nd..nth iterations\n      while (this.tokenMatcher(this.LA(1), separator) === true) {\n        // note that this CONSUME will never enter recovery because\n        // the separatorLookAheadFunc checks that the separator really does exist.\n        this.CONSUME(separator);\n        // No need for checking infinite loop here due to consuming the separator.\n        (<GrammarAction<OUT>>action).call(this);\n      }\n\n      // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n      this.attemptInRepetitionRecovery(\n        this.repetitionSepSecondInternal,\n        [\n          prodOccurrence,\n          separator,\n          separatorLookAheadFunc,\n          action,\n          NextTerminalAfterAtLeastOneSepWalker,\n        ],\n        separatorLookAheadFunc,\n        AT_LEAST_ONE_SEP_IDX,\n        prodOccurrence,\n        NextTerminalAfterAtLeastOneSepWalker,\n      );\n    } else {\n      throw this.raiseEarlyExitException(\n        prodOccurrence,\n        PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR,\n        options.ERR_MSG,\n      );\n    }\n  }\n\n  manyInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(MANY_IDX, prodOccurrence);\n    return this.manyInternalLogic(prodOccurrence, actionORMethodDef, laKey);\n  }\n\n  manyInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    key: number,\n  ) {\n    let lookaheadFunction = this.getLaFuncFromCache(key);\n    let action;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      // predicate present\n      if (predicate !== undefined) {\n        const orgLookaheadFunction = lookaheadFunction;\n        lookaheadFunction = () => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        };\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n\n    let notStuck = true;\n    while (lookaheadFunction.call(this) === true && notStuck === true) {\n      notStuck = this.doSingleRepetition(action);\n    }\n\n    // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n    this.attemptInRepetitionRecovery(\n      this.manyInternal,\n      [prodOccurrence, actionORMethodDef],\n      <any>lookaheadFunction,\n      MANY_IDX,\n      prodOccurrence,\n      NextTerminalAfterManyWalker,\n      // The notStuck parameter is only relevant when \"attemptInRepetitionRecovery\"\n      // is invoked from manyInternal, in the MANY_SEP case and AT_LEAST_ONE[_SEP]\n      // An infinite loop cannot occur as:\n      // - Either the lookahead is guaranteed to consume something (Single Token Separator)\n      // - AT_LEAST_ONE by definition is guaranteed to consume something (or error out).\n      notStuck,\n    );\n  }\n\n  manySepFirstInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: ManySepMethodOpts<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(\n      MANY_SEP_IDX,\n      prodOccurrence,\n    );\n    this.manySepFirstInternalLogic(prodOccurrence, options, laKey);\n  }\n\n  manySepFirstInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: ManySepMethodOpts<OUT>,\n    key: number,\n  ): void {\n    const action = options.DEF;\n    const separator = options.SEP;\n    const firstIterationLaFunc = this.getLaFuncFromCache(key);\n\n    // 1st iteration\n    if (firstIterationLaFunc.call(this) === true) {\n      action.call(this);\n\n      const separatorLookAheadFunc = () => {\n        return this.tokenMatcher(this.LA(1), separator);\n      };\n      // 2nd..nth iterations\n      while (this.tokenMatcher(this.LA(1), separator) === true) {\n        // note that this CONSUME will never enter recovery because\n        // the separatorLookAheadFunc checks that the separator really does exist.\n        this.CONSUME(separator);\n        // No need for checking infinite loop here due to consuming the separator.\n        action.call(this);\n      }\n\n      // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n      this.attemptInRepetitionRecovery(\n        this.repetitionSepSecondInternal,\n        [\n          prodOccurrence,\n          separator,\n          separatorLookAheadFunc,\n          action,\n          NextTerminalAfterManySepWalker,\n        ],\n        separatorLookAheadFunc,\n        MANY_SEP_IDX,\n        prodOccurrence,\n        NextTerminalAfterManySepWalker,\n      );\n    }\n  }\n\n  repetitionSepSecondInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    separator: TokenType,\n    separatorLookAheadFunc: () => boolean,\n    action: GrammarAction<OUT>,\n    nextTerminalAfterWalker: typeof AbstractNextTerminalAfterProductionWalker,\n  ): void {\n    while (separatorLookAheadFunc()) {\n      // note that this CONSUME will never enter recovery because\n      // the separatorLookAheadFunc checks that the separator really does exist.\n      this.CONSUME(separator);\n      action.call(this);\n    }\n\n    // we can only arrive to this function after an error\n    // has occurred (hence the name 'second') so the following\n    // IF will always be entered, its possible to remove it...\n    // however it is kept to avoid confusion and be consistent.\n    // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n    /* istanbul ignore else */\n    this.attemptInRepetitionRecovery(\n      this.repetitionSepSecondInternal,\n      [\n        prodOccurrence,\n        separator,\n        separatorLookAheadFunc,\n        action,\n        nextTerminalAfterWalker,\n      ],\n      separatorLookAheadFunc,\n      AT_LEAST_ONE_SEP_IDX,\n      prodOccurrence,\n      nextTerminalAfterWalker,\n    );\n  }\n\n  doSingleRepetition(this: MixedInParser, action: Function): any {\n    const beforeIteration = this.getLexerPosition();\n    action.call(this);\n    const afterIteration = this.getLexerPosition();\n\n    // This boolean will indicate if this repetition progressed\n    // or if we are \"stuck\" (potential infinite loop in the repetition).\n    return afterIteration > beforeIteration;\n  }\n\n  orInternal<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n    occurrence: number,\n  ): T {\n    const laKey = this.getKeyForAutomaticLookahead(OR_IDX, occurrence);\n    const alts = isArray(altsOrOpts) ? altsOrOpts : altsOrOpts.DEF;\n\n    const laFunc = this.getLaFuncFromCache(laKey);\n    const altIdxToTake = laFunc.call(this, alts);\n    if (altIdxToTake !== undefined) {\n      const chosenAlternative: any = alts[altIdxToTake];\n      return chosenAlternative.ALT.call(this);\n    }\n    this.raiseNoAltException(\n      occurrence,\n      (altsOrOpts as OrMethodOpts<unknown>).ERR_MSG,\n    );\n  }\n\n  ruleFinallyStateUpdate(this: MixedInParser): void {\n    this.RULE_STACK.pop();\n    this.RULE_OCCURRENCE_STACK.pop();\n\n    // NOOP when cst is disabled\n    this.cstFinallyStateUpdate();\n\n    if (this.RULE_STACK.length === 0 && this.isAtEndOfInput() === false) {\n      const firstRedundantTok = this.LA(1);\n      const errMsg = this.errorMessageProvider.buildNotAllInputParsedMessage({\n        firstRedundant: firstRedundantTok,\n        ruleName: this.getCurrRuleFullName(),\n      });\n      this.SAVE_ERROR(\n        new NotAllInputParsedException(errMsg, firstRedundantTok),\n      );\n    }\n  }\n\n  subruleInternal<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    idx: number,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    let ruleResult;\n    try {\n      const args = options !== undefined ? options.ARGS : undefined;\n      this.subruleIdx = idx;\n      ruleResult = ruleToCall.apply(this, args);\n      this.cstPostNonTerminal(\n        ruleResult,\n        options !== undefined && options.LABEL !== undefined\n          ? options.LABEL\n          : ruleToCall.ruleName,\n      );\n      return ruleResult;\n    } catch (e) {\n      throw this.subruleInternalError(e, options, ruleToCall.ruleName);\n    }\n  }\n\n  subruleInternalError(\n    this: MixedInParser,\n    e: any,\n    options: SubruleMethodOpts<unknown[]> | undefined,\n    ruleName: string,\n  ): void {\n    if (isRecognitionException(e) && e.partialCstResult !== undefined) {\n      this.cstPostNonTerminal(\n        e.partialCstResult,\n        options !== undefined && options.LABEL !== undefined\n          ? options.LABEL\n          : ruleName,\n      );\n\n      delete e.partialCstResult;\n    }\n    throw e;\n  }\n\n  consumeInternal(\n    this: MixedInParser,\n    tokType: TokenType,\n    idx: number,\n    options: ConsumeMethodOpts | undefined,\n  ): IToken {\n    let consumedToken!: IToken;\n    try {\n      const nextToken = this.LA(1);\n      if (this.tokenMatcher(nextToken, tokType) === true) {\n        this.consumeToken();\n        consumedToken = nextToken;\n      } else {\n        this.consumeInternalError(tokType, nextToken, options);\n      }\n    } catch (eFromConsumption) {\n      consumedToken = this.consumeInternalRecovery(\n        tokType,\n        idx,\n        eFromConsumption,\n      );\n    }\n\n    this.cstPostTerminal(\n      options !== undefined && options.LABEL !== undefined\n        ? options.LABEL\n        : tokType.name,\n      consumedToken,\n    );\n    return consumedToken;\n  }\n\n  consumeInternalError(\n    this: MixedInParser,\n    tokType: TokenType,\n    nextToken: IToken,\n    options: ConsumeMethodOpts | undefined,\n  ): void {\n    let msg;\n    const previousToken = this.LA(0);\n    if (options !== undefined && options.ERR_MSG) {\n      msg = options.ERR_MSG;\n    } else {\n      msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: tokType,\n        actual: nextToken,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName(),\n      });\n    }\n    throw this.SAVE_ERROR(\n      new MismatchedTokenException(msg, nextToken, previousToken),\n    );\n  }\n\n  consumeInternalRecovery(\n    this: MixedInParser,\n    tokType: TokenType,\n    idx: number,\n    eFromConsumption: Error,\n  ): IToken {\n    // no recovery allowed during backtracking, otherwise backtracking may recover invalid syntax and accept it\n    // but the original syntax could have been parsed successfully without any backtracking + recovery\n    if (\n      this.recoveryEnabled &&\n      // TODO: more robust checking of the exception type. Perhaps Typescript extending expressions?\n      eFromConsumption.name === \"MismatchedTokenException\" &&\n      !this.isBackTracking()\n    ) {\n      const follows = this.getFollowsForInRuleRecovery(<any>tokType, idx);\n      try {\n        return this.tryInRuleRecovery(<any>tokType, follows);\n      } catch (eFromInRuleRecovery) {\n        if (eFromInRuleRecovery.name === IN_RULE_RECOVERY_EXCEPTION) {\n          // failed in RuleRecovery.\n          // throw the original error in order to trigger reSync error recovery\n          throw eFromConsumption;\n        } else {\n          throw eFromInRuleRecovery;\n        }\n      }\n    } else {\n      throw eFromConsumption;\n    }\n  }\n\n  saveRecogState(this: MixedInParser): IParserState {\n    // errors is a getter which will clone the errors array\n    const savedErrors = this.errors;\n    const savedRuleStack = clone(this.RULE_STACK);\n    return {\n      errors: savedErrors,\n      lexerState: this.exportLexerState(),\n      RULE_STACK: savedRuleStack,\n      CST_STACK: this.CST_STACK,\n    };\n  }\n\n  reloadRecogState(this: MixedInParser, newState: IParserState) {\n    this.errors = newState.errors;\n    this.importLexerState(newState.lexerState);\n    this.RULE_STACK = newState.RULE_STACK;\n  }\n\n  ruleInvocationStateUpdate(\n    this: MixedInParser,\n    shortName: number,\n    fullName: string,\n    idxInCallingRule: number,\n  ): void {\n    this.RULE_OCCURRENCE_STACK.push(idxInCallingRule);\n    this.RULE_STACK.push(shortName);\n    // NOOP when cst is disabled\n    this.cstInvocationStateUpdate(fullName);\n  }\n\n  isBackTracking(this: MixedInParser): boolean {\n    return this.isBackTrackingStack.length !== 0;\n  }\n\n  getCurrRuleFullName(this: MixedInParser): string {\n    const shortName = this.getLastExplicitRuleShortName();\n    return this.shortRuleNameToFull[shortName];\n  }\n\n  shortRuleNameToFullName(this: MixedInParser, shortName: number) {\n    return this.shortRuleNameToFull[shortName];\n  }\n\n  public isAtEndOfInput(this: MixedInParser): boolean {\n    return this.tokenMatcher(this.LA(1), EOF);\n  }\n\n  public reset(this: MixedInParser): void {\n    this.resetLexerState();\n    this.subruleIdx = 0;\n    this.isBackTrackingStack = [];\n    this.errors = [];\n    this.RULE_STACK = [];\n    // TODO: extract a specific reset for TreeBuilder trait\n    this.CST_STACK = [];\n    this.RULE_OCCURRENCE_STACK = [];\n  }\n}\n","import {\n  IParserConfig,\n  IParserErrorMessageProvider,\n  IRecognitionException,\n} from \"@chevrotain/types\";\nimport {\n  EarlyExitException,\n  isRecognitionException,\n  NoViableAltException,\n} from \"../../exceptions_public.js\";\nimport { clone, has } from \"lodash-es\";\nimport {\n  getLookaheadPathsForOptionalProd,\n  getLookaheadPathsForOr,\n  PROD_TYPE,\n} from \"../../grammar/lookahead.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\n/**\n * Trait responsible for runtime parsing errors.\n */\nexport class ErrorHandler {\n  _errors: IRecognitionException[];\n  errorMessageProvider: IParserErrorMessageProvider;\n\n  initErrorHandler(config: IParserConfig) {\n    this._errors = [];\n    this.errorMessageProvider = has(config, \"errorMessageProvider\")\n      ? (config.errorMessageProvider as IParserErrorMessageProvider) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.errorMessageProvider;\n  }\n\n  SAVE_ERROR(\n    this: MixedInParser,\n    error: IRecognitionException,\n  ): IRecognitionException {\n    if (isRecognitionException(error)) {\n      error.context = {\n        ruleStack: this.getHumanReadableRuleStack(),\n        ruleOccurrenceStack: clone(this.RULE_OCCURRENCE_STACK),\n      };\n      this._errors.push(error);\n      return error;\n    } else {\n      throw Error(\n        \"Trying to save an Error which is not a RecognitionException\",\n      );\n    }\n  }\n\n  get errors(): IRecognitionException[] {\n    return clone(this._errors);\n  }\n\n  set errors(newErrors: IRecognitionException[]) {\n    this._errors = newErrors;\n  }\n\n  // TODO: consider caching the error message computed information\n  raiseEarlyExitException(\n    this: MixedInParser,\n    occurrence: number,\n    prodType: PROD_TYPE,\n    userDefinedErrMsg: string | undefined,\n  ): never {\n    const ruleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[ruleName];\n    const lookAheadPathsPerAlternative = getLookaheadPathsForOptionalProd(\n      occurrence,\n      ruleGrammar,\n      prodType,\n      this.maxLookahead,\n    );\n    const insideProdPaths = lookAheadPathsPerAlternative[0];\n    const actualTokens = [];\n    for (let i = 1; i <= this.maxLookahead; i++) {\n      actualTokens.push(this.LA(i));\n    }\n    const msg = this.errorMessageProvider.buildEarlyExitMessage({\n      expectedIterationPaths: insideProdPaths,\n      actual: actualTokens,\n      previous: this.LA(0),\n      customUserDescription: userDefinedErrMsg,\n      ruleName: ruleName,\n    });\n\n    throw this.SAVE_ERROR(new EarlyExitException(msg, this.LA(1), this.LA(0)));\n  }\n\n  // TODO: consider caching the error message computed information\n  raiseNoAltException(\n    this: MixedInParser,\n    occurrence: number,\n    errMsgTypes: string | undefined,\n  ): never {\n    const ruleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[ruleName];\n    // TODO: getLookaheadPathsForOr can be slow for large enough maxLookahead and certain grammars, consider caching ?\n    const lookAheadPathsPerAlternative = getLookaheadPathsForOr(\n      occurrence,\n      ruleGrammar,\n      this.maxLookahead,\n    );\n\n    const actualTokens = [];\n    for (let i = 1; i <= this.maxLookahead; i++) {\n      actualTokens.push(this.LA(i));\n    }\n    const previousToken = this.LA(0);\n\n    const errMsg = this.errorMessageProvider.buildNoViableAltMessage({\n      expectedPathsPerAlt: lookAheadPathsPerAlternative,\n      actual: actualTokens,\n      previous: previousToken,\n      customUserDescription: errMsgTypes,\n      ruleName: this.getCurrRuleFullName(),\n    });\n\n    throw this.SAVE_ERROR(\n      new NoViableAltException(errMsg, this.LA(1), previousToken),\n    );\n  }\n}\n","import {\n  ISyntacticContentAssistPath,\n  IToken,\n  ITokenGrammarPath,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  NextAfterTokenWalker,\n  nextPossibleTokensAfter,\n} from \"../../grammar/interpreter.js\";\nimport { first, isUndefined } from \"lodash-es\";\nimport { MixedInParser } from \"./parser_traits.js\";\n\nexport class ContentAssist {\n  initContentAssist() {}\n\n  public computeContentAssist(\n    this: MixedInParser,\n    startRuleName: string,\n    precedingInput: IToken[],\n  ): ISyntacticContentAssistPath[] {\n    const startRuleGast = this.gastProductionsCache[startRuleName];\n\n    if (isUndefined(startRuleGast)) {\n      throw Error(`Rule ->${startRuleName}<- does not exist in this grammar.`);\n    }\n\n    return nextPossibleTokensAfter(\n      [startRuleGast],\n      precedingInput,\n      this.tokenMatcher,\n      this.maxLookahead,\n    );\n  }\n\n  // TODO: should this be a member method or a utility? it does not have any state or usage of 'this'...\n  // TODO: should this be more explicitly part of the public API?\n  public getNextPossibleTokenTypes(\n    this: MixedInParser,\n    grammarPath: ITokenGrammarPath,\n  ): TokenType[] {\n    const topRuleName = first(grammarPath.ruleStack)!;\n    const gastProductions = this.getGAstProductions();\n    const topProduction = gastProductions[topRuleName];\n    const nextPossibleTokenTypes = new NextAfterTokenWalker(\n      topProduction,\n      grammarPath,\n    ).startWalking();\n    return nextPossibleTokenTypes;\n  }\n}\n","import {\n  AtLeastOneSepMethodOpts,\n  ConsumeMethodOpts,\n  CstNode,\n  DSLMethodOpts,\n  DSLMethodOptsWithErr,\n  GrammarAction,\n  IOrAlt,\n  IParserConfig,\n  IProduction,\n  IToken,\n  ManySepMethodOpts,\n  OrMethodOpts,\n  SubruleMethodOpts,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  forEach,\n  has,\n  isArray,\n  isFunction,\n  last as peek,\n  some,\n} from \"lodash-es\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport { Lexer } from \"../../../scan/lexer_public.js\";\nimport {\n  augmentTokenTypes,\n  hasShortKeyProperty,\n} from \"../../../scan/tokens.js\";\nimport {\n  createToken,\n  createTokenInstance,\n} from \"../../../scan/tokens_public.js\";\nimport { END_OF_FILE } from \"../parser.js\";\nimport { BITS_FOR_OCCURRENCE_IDX } from \"../../grammar/keys.js\";\nimport { ParserMethodInternal } from \"../types.js\";\n\ntype ProdWithDef = IProduction & { definition?: IProduction[] };\nconst RECORDING_NULL_OBJECT = {\n  description: \"This Object indicates the Parser is during Recording Phase\",\n};\nObject.freeze(RECORDING_NULL_OBJECT);\n\nconst HANDLE_SEPARATOR = true;\nconst MAX_METHOD_IDX = Math.pow(2, BITS_FOR_OCCURRENCE_IDX) - 1;\n\nconst RFT = createToken({ name: \"RECORDING_PHASE_TOKEN\", pattern: Lexer.NA });\naugmentTokenTypes([RFT]);\nconst RECORDING_PHASE_TOKEN = createTokenInstance(\n  RFT,\n  \"This IToken indicates the Parser is in Recording Phase\\n\\t\" +\n    \"\" +\n    \"See: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n  // Using \"-1\" instead of NaN (as in EOF) because an actual number is less likely to\n  // cause errors if the output of LA or CONSUME would be (incorrectly) used during the recording phase.\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n);\nObject.freeze(RECORDING_PHASE_TOKEN);\n\nconst RECORDING_PHASE_CSTNODE: CstNode = {\n  name:\n    \"This CSTNode indicates the Parser is in Recording Phase\\n\\t\" +\n    \"See: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n  children: {},\n};\n\n/**\n * This trait handles the creation of the GAST structure for Chevrotain Grammars\n */\nexport class GastRecorder {\n  recordingProdStack: ProdWithDef[];\n  RECORDING_PHASE: boolean;\n\n  initGastRecorder(this: MixedInParser, config: IParserConfig): void {\n    this.recordingProdStack = [];\n    this.RECORDING_PHASE = false;\n  }\n\n  enableRecording(this: MixedInParser): void {\n    this.RECORDING_PHASE = true;\n\n    this.TRACE_INIT(\"Enable Recording\", () => {\n      /**\n       * Warning Dark Voodoo Magic upcoming!\n       * We are \"replacing\" the public parsing DSL methods API\n       * With **new** alternative implementations on the Parser **instance**\n       *\n       * So far this is the only way I've found to avoid performance regressions during parsing time.\n       * - Approx 30% performance regression was measured on Chrome 75 Canary when attempting to replace the \"internal\"\n       *   implementations directly instead.\n       */\n      for (let i = 0; i < 10; i++) {\n        const idx = i > 0 ? i : \"\";\n        this[`CONSUME${idx}` as \"CONSUME\"] = function (arg1, arg2) {\n          return this.consumeInternalRecord(arg1, i, arg2);\n        };\n        this[`SUBRULE${idx}` as \"SUBRULE\"] = function (arg1, arg2) {\n          return this.subruleInternalRecord(arg1, i, arg2) as any;\n        };\n        this[`OPTION${idx}` as \"OPTION\"] = function (arg1) {\n          return this.optionInternalRecord(arg1, i);\n        };\n        this[`OR${idx}` as \"OR\"] = function (arg1) {\n          return this.orInternalRecord(arg1, i);\n        };\n        this[`MANY${idx}` as \"MANY\"] = function (arg1) {\n          this.manyInternalRecord(i, arg1);\n        };\n        this[`MANY_SEP${idx}` as \"MANY_SEP\"] = function (arg1) {\n          this.manySepFirstInternalRecord(i, arg1);\n        };\n        this[`AT_LEAST_ONE${idx}` as \"AT_LEAST_ONE\"] = function (arg1) {\n          this.atLeastOneInternalRecord(i, arg1);\n        };\n        this[`AT_LEAST_ONE_SEP${idx}` as \"AT_LEAST_ONE_SEP\"] = function (arg1) {\n          this.atLeastOneSepFirstInternalRecord(i, arg1);\n        };\n      }\n\n      // DSL methods with the idx(suffix) as an argument\n      this[`consume`] = function (idx, arg1, arg2) {\n        return this.consumeInternalRecord(arg1, idx, arg2);\n      };\n      this[`subrule`] = function (idx, arg1, arg2) {\n        return this.subruleInternalRecord(arg1, idx, arg2) as any;\n      };\n      this[`option`] = function (idx, arg1) {\n        return this.optionInternalRecord(arg1, idx);\n      };\n      this[`or`] = function (idx, arg1) {\n        return this.orInternalRecord(arg1, idx);\n      };\n      this[`many`] = function (idx, arg1) {\n        this.manyInternalRecord(idx, arg1);\n      };\n      this[`atLeastOne`] = function (idx, arg1) {\n        this.atLeastOneInternalRecord(idx, arg1);\n      };\n\n      this.ACTION = this.ACTION_RECORD;\n      this.BACKTRACK = this.BACKTRACK_RECORD;\n      this.LA = this.LA_RECORD;\n    });\n  }\n\n  disableRecording(this: MixedInParser) {\n    this.RECORDING_PHASE = false;\n    // By deleting these **instance** properties, any future invocation\n    // will be deferred to the original methods on the **prototype** object\n    // This seems to get rid of any incorrect optimizations that V8 may\n    // do during the recording phase.\n    this.TRACE_INIT(\"Deleting Recording methods\", () => {\n      const that: any = this;\n\n      for (let i = 0; i < 10; i++) {\n        const idx = i > 0 ? i : \"\";\n        delete that[`CONSUME${idx}`];\n        delete that[`SUBRULE${idx}`];\n        delete that[`OPTION${idx}`];\n        delete that[`OR${idx}`];\n        delete that[`MANY${idx}`];\n        delete that[`MANY_SEP${idx}`];\n        delete that[`AT_LEAST_ONE${idx}`];\n        delete that[`AT_LEAST_ONE_SEP${idx}`];\n      }\n\n      delete that[`consume`];\n      delete that[`subrule`];\n      delete that[`option`];\n      delete that[`or`];\n      delete that[`many`];\n      delete that[`atLeastOne`];\n\n      delete that.ACTION;\n      delete that.BACKTRACK;\n      delete that.LA;\n    });\n  }\n\n  //   Parser methods are called inside an ACTION?\n  //   Maybe try/catch/finally on ACTIONS while disabling the recorders state changes?\n  // @ts-expect-error -- noop place holder\n  ACTION_RECORD<T>(this: MixedInParser, impl: () => T): T {\n    // NO-OP during recording\n  }\n\n  // Executing backtracking logic will break our recording logic assumptions\n  BACKTRACK_RECORD<T>(\n    grammarRule: (...args: any[]) => T,\n    args?: any[],\n  ): () => boolean {\n    return () => true;\n  }\n\n  // LA is part of the official API and may be used for custom lookahead logic\n  // by end users who may forget to wrap it in ACTION or inside a GATE\n  LA_RECORD(howMuch: number): IToken {\n    // We cannot use the RECORD_PHASE_TOKEN here because someone may depend\n    // On LA return EOF at the end of the input so an infinite loop may occur.\n    return END_OF_FILE;\n  }\n\n  topLevelRuleRecord(name: string, def: Function): Rule {\n    try {\n      const newTopLevelRule = new Rule({ definition: [], name: name });\n      newTopLevelRule.name = name;\n      this.recordingProdStack.push(newTopLevelRule);\n      def.call(this);\n      this.recordingProdStack.pop();\n      return newTopLevelRule;\n    } catch (originalError) {\n      if (originalError.KNOWN_RECORDER_ERROR !== true) {\n        try {\n          originalError.message =\n            originalError.message +\n            '\\n\\t This error was thrown during the \"grammar recording phase\" For more info see:\\n\\t' +\n            \"https://chevrotain.io/docs/guide/internals.html#grammar-recording\";\n        } catch (mutabilityError) {\n          // We may not be able to modify the original error object\n          throw originalError;\n        }\n      }\n      throw originalError;\n    }\n  }\n\n  // Implementation of parsing DSL\n  optionInternalRecord<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    occurrence: number,\n  ): OUT {\n    return recordProd.call(this, Option, actionORMethodDef, occurrence);\n  }\n\n  atLeastOneInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    recordProd.call(this, RepetitionMandatory, actionORMethodDef, occurrence);\n  }\n\n  atLeastOneSepFirstInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    recordProd.call(\n      this,\n      RepetitionMandatoryWithSeparator,\n      options,\n      occurrence,\n      HANDLE_SEPARATOR,\n    );\n  }\n\n  manyInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    recordProd.call(this, Repetition, actionORMethodDef, occurrence);\n  }\n\n  manySepFirstInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    options: ManySepMethodOpts<OUT>,\n  ): void {\n    recordProd.call(\n      this,\n      RepetitionWithSeparator,\n      options,\n      occurrence,\n      HANDLE_SEPARATOR,\n    );\n  }\n\n  orInternalRecord<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n    occurrence: number,\n  ): T {\n    return recordOrProd.call(this, altsOrOpts, occurrence);\n  }\n\n  subruleInternalRecord<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    occurrence: number,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R | CstNode {\n    assertMethodIdxIsValid(occurrence);\n    if (!ruleToCall || has(ruleToCall, \"ruleName\") === false) {\n      const error: any = new Error(\n        `<SUBRULE${getIdxSuffix(occurrence)}> argument is invalid` +\n          ` expecting a Parser method reference but got: <${JSON.stringify(\n            ruleToCall,\n          )}>` +\n          `\\n inside top level rule: <${\n            (<Rule>this.recordingProdStack[0]).name\n          }>`,\n      );\n      error.KNOWN_RECORDER_ERROR = true;\n      throw error;\n    }\n\n    const prevProd: any = peek(this.recordingProdStack);\n    const ruleName = ruleToCall.ruleName;\n    const newNoneTerminal = new NonTerminal({\n      idx: occurrence,\n      nonTerminalName: ruleName,\n      label: options?.LABEL,\n      // The resolving of the `referencedRule` property will be done once all the Rule's GASTs have been created\n      referencedRule: undefined,\n    });\n    prevProd.definition.push(newNoneTerminal);\n\n    return this.outputCst\n      ? RECORDING_PHASE_CSTNODE\n      : <any>RECORDING_NULL_OBJECT;\n  }\n\n  consumeInternalRecord(\n    this: MixedInParser,\n    tokType: TokenType,\n    occurrence: number,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    assertMethodIdxIsValid(occurrence);\n    if (!hasShortKeyProperty(tokType)) {\n      const error: any = new Error(\n        `<CONSUME${getIdxSuffix(occurrence)}> argument is invalid` +\n          ` expecting a TokenType reference but got: <${JSON.stringify(\n            tokType,\n          )}>` +\n          `\\n inside top level rule: <${\n            (<Rule>this.recordingProdStack[0]).name\n          }>`,\n      );\n      error.KNOWN_RECORDER_ERROR = true;\n      throw error;\n    }\n    const prevProd: any = peek(this.recordingProdStack);\n    const newNoneTerminal = new Terminal({\n      idx: occurrence,\n      terminalType: tokType,\n      label: options?.LABEL,\n    });\n    prevProd.definition.push(newNoneTerminal);\n\n    return RECORDING_PHASE_TOKEN;\n  }\n}\n\nfunction recordProd(\n  prodConstructor: any,\n  mainProdArg: any,\n  occurrence: number,\n  handleSep: boolean = false,\n): any {\n  assertMethodIdxIsValid(occurrence);\n  const prevProd: any = peek(this.recordingProdStack);\n  const grammarAction = isFunction(mainProdArg) ? mainProdArg : mainProdArg.DEF;\n\n  const newProd = new prodConstructor({ definition: [], idx: occurrence });\n  if (handleSep) {\n    newProd.separator = mainProdArg.SEP;\n  }\n  if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n    newProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n  }\n\n  this.recordingProdStack.push(newProd);\n  grammarAction.call(this);\n  prevProd.definition.push(newProd);\n  this.recordingProdStack.pop();\n\n  return RECORDING_NULL_OBJECT;\n}\n\nfunction recordOrProd(mainProdArg: any, occurrence: number): any {\n  assertMethodIdxIsValid(occurrence);\n  const prevProd: any = peek(this.recordingProdStack);\n  // Only an array of alternatives\n  const hasOptions = isArray(mainProdArg) === false;\n  const alts: IOrAlt<unknown>[] =\n    hasOptions === false ? mainProdArg : mainProdArg.DEF;\n\n  const newOrProd = new Alternation({\n    definition: [],\n    idx: occurrence,\n    ignoreAmbiguities: hasOptions && mainProdArg.IGNORE_AMBIGUITIES === true,\n  });\n  if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n    newOrProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n  }\n\n  const hasPredicates = some(alts, (currAlt: any) => isFunction(currAlt.GATE));\n  newOrProd.hasPredicates = hasPredicates;\n\n  prevProd.definition.push(newOrProd);\n\n  forEach(alts, (currAlt) => {\n    const currAltFlat = new Alternative({ definition: [] });\n    newOrProd.definition.push(currAltFlat);\n    if (has(currAlt, \"IGNORE_AMBIGUITIES\")) {\n      currAltFlat.ignoreAmbiguities = currAlt.IGNORE_AMBIGUITIES as boolean; // assumes end user provides the correct config value/type\n    }\n    // **implicit** ignoreAmbiguities due to usage of gate\n    else if (has(currAlt, \"GATE\")) {\n      currAltFlat.ignoreAmbiguities = true;\n    }\n    this.recordingProdStack.push(currAltFlat);\n    currAlt.ALT.call(this);\n    this.recordingProdStack.pop();\n  });\n  return RECORDING_NULL_OBJECT;\n}\n\nfunction getIdxSuffix(idx: number): string {\n  return idx === 0 ? \"\" : `${idx}`;\n}\n\nfunction assertMethodIdxIsValid(idx: number): void {\n  if (idx < 0 || idx > MAX_METHOD_IDX) {\n    const error: any = new Error(\n      // The stack trace will contain all the needed details\n      `Invalid DSL Method idx value: <${idx}>\\n\\t` +\n        `Idx value must be a none negative value smaller than ${\n          MAX_METHOD_IDX + 1\n        }`,\n    );\n    error.KNOWN_RECORDER_ERROR = true;\n    throw error;\n  }\n}\n","import { IParserConfig } from \"@chevrotain/types\";\nimport { has } from \"lodash-es\";\nimport { timer } from \"@chevrotain/utils\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\n/**\n * Trait responsible for runtime parsing errors.\n */\nexport class PerformanceTracer {\n  traceInitPerf: boolean | number;\n  traceInitMaxIdent: number;\n  traceInitIndent: number;\n\n  initPerformanceTracer(config: IParserConfig) {\n    if (has(config, \"traceInitPerf\")) {\n      const userTraceInitPerf = config.traceInitPerf;\n      const traceIsNumber = typeof userTraceInitPerf === \"number\";\n      this.traceInitMaxIdent = traceIsNumber\n        ? <number>userTraceInitPerf\n        : Infinity;\n      this.traceInitPerf = traceIsNumber\n        ? userTraceInitPerf > 0\n        : (userTraceInitPerf as boolean); // assumes end user provides the correct config value/type\n    } else {\n      this.traceInitMaxIdent = 0;\n      this.traceInitPerf = DEFAULT_PARSER_CONFIG.traceInitPerf;\n    }\n\n    this.traceInitIndent = -1;\n  }\n\n  TRACE_INIT<T>(this: MixedInParser, phaseDesc: string, phaseImpl: () => T): T {\n    // No need to optimize this using NOOP pattern because\n    // It is not called in a hot spot...\n    if (this.traceInitPerf === true) {\n      this.traceInitIndent++;\n      const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        console.log(`${indent}--> <${phaseDesc}>`);\n      }\n      const { time, value } = timer(phaseImpl);\n      /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n      const traceMethod = time > 10 ? console.warn : console.log;\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n      }\n      this.traceInitIndent--;\n      return value;\n    } else {\n      return phaseImpl();\n    }\n  }\n}\n","export function applyMixins(derivedCtor: any, baseCtors: any[]) {\n  baseCtors.forEach((baseCtor) => {\n    const baseProto = baseCtor.prototype;\n    Object.getOwnPropertyNames(baseProto).forEach((propName) => {\n      if (propName === \"constructor\") {\n        return;\n      }\n\n      const basePropDescriptor = Object.getOwnPropertyDescriptor(\n        baseProto,\n        propName,\n      );\n      // Handle Accessors\n      if (\n        basePropDescriptor &&\n        (basePropDescriptor.get || basePropDescriptor.set)\n      ) {\n        Object.defineProperty(\n          derivedCtor.prototype,\n          propName,\n          basePropDescriptor,\n        );\n      } else {\n        derivedCtor.prototype[propName] = baseCtor.prototype[propName];\n      }\n    });\n  });\n}\n","/* istanbul ignore file - tricky to import some things from this module during testing */\n\n// semantic version\nexport { VERSION } from \"./version.js\";\n\nexport {\n  CstParser,\n  EmbeddedActionsParser,\n  ParserDefinitionErrorType,\n  EMPTY_ALT,\n} from \"./parse/parser/parser.js\";\n\nexport { Lexer, LexerDefinitionErrorType } from \"./scan/lexer_public.js\";\n\n// Tokens utilities\nexport {\n  createToken,\n  createTokenInstance,\n  EOF,\n  tokenLabel,\n  tokenMatcher,\n  tokenName,\n} from \"./scan/tokens_public.js\";\n\n// Lookahead\n\nexport { getLookaheadPaths } from \"./parse/grammar/lookahead.js\";\n\nexport { LLkLookaheadStrategy } from \"./parse/grammar/llk_lookahead.js\";\n\n// Other Utilities\n\nexport { defaultParserErrorProvider } from \"./parse/errors_public.js\";\n\nexport {\n  EarlyExitException,\n  isRecognitionException,\n  MismatchedTokenException,\n  NotAllInputParsedException,\n  NoViableAltException,\n} from \"./parse/exceptions_public.js\";\n\nexport { defaultLexerErrorProvider } from \"./scan/lexer_errors_public.js\";\n\n// grammar reflection API\nexport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\n\n// GAST Utilities\n\nexport {\n  serializeGrammar,\n  serializeProduction,\n  GAstVisitor,\n} from \"@chevrotain/gast\";\n\nexport { generateCstDts } from \"@chevrotain/cst-dts-gen\";\n\n/* istanbul ignore next */\nexport function clearCache() {\n  console.warn(\n    \"The clearCache function was 'soft' removed from the Chevrotain API.\" +\n      \"\\n\\t It performs no action other than printing this message.\" +\n      \"\\n\\t Please avoid using it as it will be completely removed in the future\",\n  );\n}\n\nexport { createSyntaxDiagramsCode } from \"./diagrams/render_public.js\";\n\nexport class Parser {\n  constructor() {\n    throw new Error(\n      \"The Parser class has been deprecated, use CstParser or EmbeddedActionsParser instead.\\t\\n\" +\n        \"See: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_7-0-0\",\n    );\n  }\n}\n","import { createToken } from \"chevrotain\"\n\nfunction getTokens(v2Compatible) {\n\n  let Symbols = {\n    OR: '|',\n    ELSE: '||',\n    DYNAMIC: '$',\n    STATIC: '#',\n    ENTITY: '&',\n    OPEN_GATE: '@',\n    CLOSE_GATE: '@',\n    PENDING_GATE: '@@',\n    OPEN_SILENT: '{',\n    CLOSE_SILENT: '}',\n  };\n\n  let v2Symbols = {\n    OPEN_CHOICE: '(',\n    CLOSE_CHOICE: ')',\n    OPEN_WEIGHT: '[',\n    CLOSE_WEIGHT: ']',\n    CONTINUATION: '\\\\',\n  };\n\n  let v3Symbols = {\n    OPEN_CHOICE: '[',\n    CLOSE_CHOICE: ']',\n    OPEN_WEIGHT: '^', // also allows (int), eg. (3)\n    CLOSE_WEIGHT: '^',\n    CONTINUATION: '~',\n  };\n\n  Object.assign(Symbols, v2Compatible ? v2Symbols : v3Symbols);\n\n  const Escaped = {};\n  Object.entries(Symbols).forEach(([k, v]) => { Escaped[k] = escapeRegex(v) });\n\n  const PENDING_GATE_PATTERN = new RegExp(`${Escaped.PENDING_GATE}([0-9]{9,11})`)\n\n  Escaped.SPECIAL = Object.values(Escaped).join('').replace(/[<>]/g, ''); // allow <>& for html \n  Symbols.PENDING_GATE_RE = new RegExp(PENDING_GATE_PATTERN.source, 'g'); // for unresolved gates\n\n  const ExitGate = createToken({\n    name: \"ExitGate\",\n    pattern: new RegExp(`\\\\s*${Escaped.CLOSE_GATE}`),\n    pop_mode: true\n  });\n\n  const Gate = createToken({\n    name: \"Gate\",\n    pattern: new RegExp(`[^${Escaped.CLOSE_GATE}]+`)\n  });\n\n  const PendingGate = createToken({\n    name: \"PendingGate\",\n    pattern: PENDING_GATE_PATTERN\n  });\n\n  const EnterGate = createToken({\n    name: \"EnterGate\",\n    pattern: new RegExp(`${Escaped.OPEN_GATE}\\\\s*`),\n    push_mode: \"gate_mode\"\n  });\n\n  \n  const OC = createToken({ name: \"OC\", pattern: new RegExp(Escaped.OPEN_CHOICE + '\\\\s*') });\n  const CC = createToken({ name: \"CC\", pattern: new RegExp(`\\\\s*${Escaped.CLOSE_CHOICE}`) });\n  const OR = createToken({ name: \"OR\", pattern: /\\s*\\|\\s*/ });\n  const ELSE = createToken({ name: \"ELSE\", pattern: /\\s*\\|\\|\\s*/ });\n  const EQ = createToken({ name: \"EQ\", pattern: /\\s*=\\s*/ });\n  const TF = createToken({ name: \"TF\", pattern: /\\.[A-Za-z_0-9][A-Za-z_0-9]*(\\(\\))?/ });\n  const OS = createToken({ name: \"OS\", pattern: new RegExp(`${Escaped.OPEN_SILENT}\\\\s*`) });\n  const CS = createToken({ name: \"CS\", pattern: new RegExp(`\\\\s*${Escaped.CLOSE_SILENT}`) });\n  const SYM = createToken({ name: \"SYM\", pattern: new RegExp(`[${Escaped.DYNAMIC}${Escaped.STATIC}][A-Za-z_0-9]*`) });\n\n  const Entity = createToken({ name: \"Entity\", pattern: /&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-fA-F]{1,6});/i });\n  const Weight = createToken({ name: \"Weight\", pattern: new RegExp(`\\\\s*${Escaped.OPEN_WEIGHT}.+${Escaped.CLOSE_WEIGHT}\\\\s*`) });\n  const Raw = createToken({ name: \"Raw\", pattern: new RegExp(`[^${Escaped.SPECIAL}]+`) });\n\n  const normalMode = [Entity, Weight, ELSE, OC, CC, OR, EQ, SYM, TF, OS, CS, PendingGate, Raw, EnterGate];\n  const gateMode = [Gate, ExitGate];\n\n  const multiMode = {\n    modes: {\n      normal: normalMode,\n      gate_mode: gateMode\n    },\n    defaultMode: 'normal'\n  };\n\n  return { tokens: multiMode, Constants: { Symbols, Escaped } };\n}\n\nfunction escapeRegex(s) {\n  return s.replace(/[-\\/\\\\^$*+?.()|[\\]{}]/g, '\\\\$&');\n}\n\n// console.log(getTokens().tokens.modes.normal.map(t => t.name));\n\nexport { getTokens };","\nimport { CstParser } from \"chevrotain\"\n\nclass RiScriptParser extends CstParser {\n\n  constructor(allTokens) {\n    super(allTokens, { nodeLocationTracking: \"full\" });\n    this.atomTypes = ['silent', 'assign', 'symbol', 'choice', 'pgate', 'text', 'entity'];\n    this.buildRules();\n  }\n\n  parse(opts) {\n    this.input = opts.tokens; // superclass member (do not change)\n    \n    let cst = this.script();\n    if (this.errors.length > 0) throw Error\n      (\"[PARSING]\\n\" + this.errors[0].message);\n    return cst;\n  }\n\n  buildRules() {\n\n    const $ = this, Tokens = this.tokensMap;\n\n    $.RULE(\"script\", () => {\n      $.MANY(() => $.SUBRULE($.expr));\n    });\n\n    $.RULE(\"pgate\", () => {\n      $.CONSUME(Tokens.PendingGate);\n      $.MANY(() => $.CONSUME(Tokens.TF));\n    });\n\n    $.RULE(\"entity\", () => {\n      $.CONSUME(Tokens.Entity);\n    });\n\n    $.RULE(\"gate\", () => {\n      $.CONSUME(Tokens.EnterGate);\n      $.MANY(() => $.CONSUME(Tokens.Gate));\n      $.CONSUME(Tokens.ExitGate);\n    });\n\n    $.RULE(\"silent\", () => {\n      $.CONSUME(Tokens.OS);\n      $.OPTION1(() => $.SUBRULE($.gate));\n      $.CONSUME(Tokens.SYM);\n      $.OPTION2(() => {\n        $.CONSUME(Tokens.EQ);\n        $.SUBRULE($.expr);\n      });\n      $.CONSUME(Tokens.CS);\n    });\n\n    $.RULE(\"assign\", () => {\n      $.CONSUME(Tokens.SYM);\n      $.CONSUME(Tokens.EQ);\n      $.SUBRULE($.expr);\n    });\n\n    $.RULE(\"symbol\", () => {\n      $.CONSUME(Tokens.SYM);\n      $.MANY(() => $.CONSUME(Tokens.TF));\n    });\n\n    $.RULE(\"accept\", () => {\n      $.SUBRULE($.or_expr);\n    });\n\n    $.RULE(\"reject\", () => {\n      $.SUBRULE($.or_expr);\n    });\n\n    $.RULE(\"or_expr\", () => {\n      $.MANY_SEP({\n        SEP: Tokens.OR,\n        DEF: () => $.SUBRULE($.wexpr)\n      });\n    });\n\n    // choice: (LP (wexpr OR)* wexpr RP) transform*;\n    $.RULE(\"choice\", () => {\n      $.CONSUME(Tokens.OC)\n      $.OPTION1(() => $.SUBRULE($.gate));\n      $.SUBRULE($.accept)\n      // $.MANY_SEP({\n      //   SEP: Tokens.OR,\n      //   DEF: () => $.SUBRULE($.wexpr)\n      // });\n      $.OPTION2(() => {\n        $.CONSUME(Tokens.ELSE);\n        $.SUBRULE($.reject)\n      });\n      $.CONSUME(Tokens.CC);\n      $.MANY(() => $.CONSUME(Tokens.TF));\n    });\n\n    $.RULE(\"wexpr\", () => {\n      $.MANY(() => {\n        $.OR([\n          { ALT: () => $.SUBRULE($.expr) },\n          { ALT: () => $.CONSUME(Tokens.Weight) },\n        ])\n      });\n    });\n\n    $.RULE(\"expr\", () => {\n      $.AT_LEAST_ONE(() => $.SUBRULE($.atom));\n    });\n\n    $.RULE(\"atom\", () => {\n      $.OR(this.atomTypes.map(t => ({ ALT: () => $.SUBRULE($[t]) })));\n    });\n\n    $.RULE(\"text\", () => {\n      $.CONSUME(Tokens.Raw);\n    });\n\n    this.performSelfAnalysis(); // keep\n  }\n}\n\nexport { RiScriptParser };","\nclass BaseVisitor {\n  constructor(riScript) {\n    this.input = 0;\n\n    this.path = '';\n    this.tracePath = true;\n    this.scripting = riScript;\n    this.warnOnInvalidGates = false;\n    this.RiScript = this.scripting.constructor; // class hack\n  }\n\n  isCstNode(o) {\n    return (typeof o === 'object' &&\n      ('accept' in o || ('name' in o && 'location' in o && 'children' in o)));\n  }\n\n  visit(cstNode, param) {\n    if (Array.isArray(cstNode)) {\n      cstNode = cstNode[0];\n    }\n    if (typeof cstNode === 'undefined') {\n      return undefined;\n    }\n    if (!this.isCstNode(cstNode)) {\n      throw Error('Non-cstNode passed to visit: ' + JSON.stringify(cstNode));\n    }\n\n    const { name, location } = cstNode;\n\n    this.nodeText = this.input.substring(\n      location.startOffset,\n      location.endOffset + 1\n    );\n\n    if (typeof this[name] !== 'function') {\n      throw Error('BaseVisitor.visit: expecting function for this[' +\n        `${name}], found ${typeof this[name]}: ${JSON.stringify(this[name])}`);\n    }\n\n    if (this.tracePath && !/(expr|atom|silent)/.test(name)) {\n      this.path += name + '.';\n    }\n    return this[name](cstNode.children, param);\n  }\n\n  validateVisitor() {\n    /* no-op */\n  }\n}\n\nclass RiScriptVisitor extends BaseVisitor {\n  constructor(riScript, context = {}) {\n    super(riScript); // stored as global RiScript (TODO)\n    this.context = context;\n\n    this.trace = 0;\n    this.choices = {};\n    this.isNoRepeat = false;\n    this.symbols = this.scripting.Symbols;\n    this.escaped = this.scripting.Escaped;\n\n    // lookups\n    this.statics = {};\n    this.dynamics = {};\n    this.pendingGates = {};\n    this.pendingSymbols = new Set();\n\n    this.validateVisitor(); // keep\n  }\n\n  start(opts = {}) {\n    this.input = opts.input;\n    this.trace = opts.trace;\n    this.traceTx = opts.traceTx;\n    if (!opts.cst) throw Error('no cst');\n    return super.visit(opts.cst);\n  }\n\n  script(ctx) {\n    this.order = 0;\n    const count = ctx.expr ? ctx.expr.length : 0;\n    this.print('script', \"'\" + this.RiScript._escapeText(this.input)\n      + \"' :: \" + count + ' expression(s)');\n    if (!count) return '';\n    if (Object.keys(ctx).length !== 1) throw Error('script: invalid expr');\n    return this.visit(ctx.expr);\n  }\n\n  expr(ctx) {\n    // this.print('expr', ctx);\n    const types = Object.keys(ctx);\n    if (types.length !== 1) throw Error('invalid expr: ' + types.length);\n    const exprs = ctx.atom.map((c) => this.visit(c));\n    // handle special cases of the form: \"not [quite|] far enough\"\n    for (let i = 1; i < exprs.length - 1; i++) {\n      if (\n        exprs[i].length === 0 &&\n        exprs[i - 1].endsWith(' ') &&\n        exprs[i + 1].startsWith(' ')\n      ) {\n        exprs[i + 1] = exprs[i + 1].substring(1);\n      }\n    }\n    return exprs.join('');\n  }\n\n  wexpr(ctx) {\n    this.print('wexpr');\n  }\n\n  gate(ctx) {\n    // returns { decision: [accept | reject] } or { decision: 'defer', operands: [] }\n\n    if (ctx.Gate.length !== 1) throw Error('Invalid gate: ' + ctx.Gate);\n\n    let mingoQuery;\n    const raw = ctx.Gate[0].image;\n    try {\n      mingoQuery = this.scripting._query(raw);\n    } catch (e) {\n      if (!this.warnOnInvalidGates) {\n        throw Error(`Invalid gate[2]: \"@${raw}@\"\\n\\nRootCause -> ${e}`);\n      }\n      if (!this.scripting.RiTa.SILENT && !this.scripting.silent) {\n        console.warn(`[WARN] Ignoring invalid gate: @${raw}@\\n`, e);\n      }\n      return { decision: 'accept' };\n    }\n\n    const resolvedOps = {};\n    const unresolvedOps = [];\n    const operands = mingoQuery.operands();\n    operands.forEach((sym) => {\n      let { result, resolved, isStatic, isUser } = this.checkContext(sym);\n\n      if (typeof result === 'function') {\n        // while {} ?\n        result = result.call(); // call it\n        resolved = !this.scripting.isParseable(result);\n      }\n      if (typeof result === 'undefined' || !resolved) {\n        unresolvedOps.push(sym);\n      } else {\n        // add to appropriate context\n        if (isStatic) {\n          this.statics[sym] = result;\n        } else if (isUser) {\n          this.context[sym] = result;\n        } else {\n          this.dynamics[sym] = result;\n        }\n        // store resolved result\n        resolvedOps[sym] = result;\n      }\n    });\n\n    if (\n      Object.keys(resolvedOps).length + unresolvedOps.length !==\n      operands.length\n    ) { throw Error('invalid operands'); }\n\n    // if we have unresolved operands, return them (and defer)\n    if (unresolvedOps.length) { return { decision: 'defer', operands: unresolvedOps }; }\n\n    let result = mingoQuery.test(resolvedOps); // do test\n    if (!result && this.castValues(resolvedOps)) {\n      result = mingoQuery.test(resolvedOps); // redo test after casting\n    }\n\n    return { decision: result ? 'accept' : 'reject' };\n  }\n\n  assign(ctx, opts) {\n    const sym = ctx.SYM[0].image;\n    let value;\n    let info;\n    const ident = sym.replace(this.scripting.AnySymbolRE, '');\n    const isStatic = sym.startsWith(this.symbols.STATIC);\n\n    if (isStatic) {\n      value = this.visit(ctx.expr);\n      if (this.scripting.isParseable(value)) {\n        this.statics[ident] = value; // store in lookup table ??\n        value = this.inlineAssignment(ident, ctx.TF, value);\n      } else {\n        this.statics[ident] = value; // store in lookup table\n        this.pendingSymbols.delete(ident); // no longer pending\n        this.trace &&\n          console.log('  [pending.delete]', sym,\n            this.pendingSymbols.length\n              ? JSON.stringify(this.pendingSymbols)\n              : ''\n          );\n      }\n      info = `${sym} = ${this.RiScript._escapeText(value)}` +\n        ` [#static] ${opts?.silent ? '{silent}' : ''}`;\n    } else {\n      const $ = this;\n\n      // dynamic: store as func to be resolved later, perhaps many times\n      value = () => $.visit(ctx.expr);\n      info = `${sym} = <f*:pending>` + (opts?.silent ? '{silent}' : '');\n\n      // NOTE: this function may contain a choice, which needs to be handled\n      // when called from a symbol with a norepeat transform (??) TODO: test\n\n      this.dynamics[ident] = value; // store in lookup table\n    }\n    this.print('assign', info);\n\n    return value;\n  }\n\n  silent(ctx) {\n    if (ctx.EQ) {\n      this.assign(ctx, { silent: true });\n    } else {\n      this.symbol(ctx, { silent: true });\n    }\n    return '';\n  }\n\n  atom(ctx) {\n    let result;\n    const types = Object.keys(ctx);\n    if (types.length !== 1) throw Error('invalid atom: ' + types);\n    this.scripting.parser.atomTypes.forEach((type) => {\n      const context = ctx[type];\n      if (context) {\n        if (context.length !== 1) {\n          throw Error(type + ': bad length -> ' + ctx[type].length);\n        }\n        // console.log(type + ':', context[0]);\n        result = this.visit(context[0]);\n      }\n    });\n\n    // pending function, call it\n    if (typeof result === 'function') {\n      result = result.call();\n    }\n    return result;\n  }\n\n  text(ctx) {\n    if (ctx.Raw.length !== 1) throw Error('[1] invalid text');\n    if (Object.keys(ctx).length !== 1) throw Error('[2] invalid text');\n    const image = ctx.Raw[0].image;\n    this.print('text', this.RiScript._escapeText(\"'\" + image + \"'\"));\n    return image;\n  }\n\n  entity(ctx) {\n    return this.nodeText;\n  }\n\n  symbol(ctx, opts) {\n    if (ctx.SYM.length !== 1) throw Error('[1] invalid symbol');\n\n    const original = this.nodeText;\n    const symbol = ctx.SYM[0].image;\n    const ident = symbol.replace(this.scripting.AnySymbolRE, '');\n\n    this.isNoRepeat = this.hasNoRepeat(ctx.TF);\n\n    if (this.pendingSymbols.has(ident)) {\n      this.print('symbol', `${symbol} [is-pending]`);\n      return original;\n    }\n\n    // lookup: result is either a value, a function, or undef\n    let { result, isStatic, isUser, resolved } = this.checkContext(ident);\n\n    if (!isStatic && symbol.startsWith(this.symbols.STATIC)) {\n      if (!this.scripting.EntityRE.test(symbol)) {\n        throw Error(`Attempt to refer to dynamic symbol '${ident}' as` +\n          ` ${this.symbols.STATIC}${ident}, did you mean $${ident}?`);\n      }\n    }\n\n    if (typeof result === 'function') {\n      // while {} ?\n      result = result.call(); // call it\n      resolved = !this.scripting.isParseable(result);\n    }\n\n    if (this.isNoRepeat && (isStatic || isUser)) {\n      this.isNoRepeat = false;\n      const msg = 'Attempt to call norepeat() on ' + (isStatic\n        ? \"static symbol '\" + symbol + \"'. Did you mean to use '\" +\n        this.symbols.DYNAMIC + ident + \"' ?\"\n        : \"non-dynamic symbol '\" + ident + \"'. Did you mean to define '\" +\n        this.symbols.DYNAMIC + ident + \"' in riscript?\");\n      throw Error(msg);\n    }\n\n    if (typeof result === 'undefined') {\n      // nothing found, defer\n      this.print('symbol', symbol + \" -> '\" + original + \"' ctx=\" +\n        this.lookupsToString(), '[deferred]', opts?.silent ? '{silent}' : '');\n      return original;\n    }\n\n    let info = original + \" -> '\" + result + \"'\" + (opts?.silent ? ' {silent}' : '');\n\n    // defer if we still have unresolved riscript\n    if (typeof result === 'string' && !resolved) {\n      if (isStatic) {\n        this.pendingSymbols.add(ident);\n        result = this.inlineAssignment(ident, ctx.TF, result);\n        this.print('symbol*', `${original} -> ${result} :: pending.add(${ident})`);\n      } else {\n        if (ctx.TF) result = this.restoreTransforms(result, ctx.TF);\n        this.print('symbol', info);\n      }\n      return result;\n    }\n\n    if (isStatic) {\n      // store !untransformed! result in static context\n      this.statics[ident] = result; // ADDED 8/18/23 - FIXED 10/8/23\n    }\n\n    if (ctx.TF) {\n      result = this.applyTransforms(result, ctx.TF);\n      info += \" -> '\" + result + \"'\";\n      // info += \" -> \" + ctx.TF.map(tf => ` ${tf.image} -> `) + '\\'' + result + \"'\";\n      // console.log(\"INFO: \" + info);\n      if (this.isNoRepeat) info += ' (norepeat)';\n    }\n\n    this.print('symbol', info);\n\n    // resolved, so remove from pending\n    if (this.pendingSymbols.has(ident)) {\n      this.trace && console.log('  [$pending.delete]', (isStatic ? '#' : '$') + ident,\n        this.pendingSymbols.length ? JSON.stringify(this.pendingSymbols) : '');\n      this.pendingSymbols.delete(ident);\n    }\n    this.isNoRepeat = false; // reset\n\n    return result;\n  }\n\n  pgate(ctx) {\n    this.print('pgate', this.nodeText);\n    // new RegExp(`^${this.symbols.PENDING_GATE}`\n    const original = this.nodeText;\n    const ident = original.replace(this.symbols.PENDING_GATE, '');\n    const lookup = this.pendingGates[ident];\n\n    if (!lookup) {\n      throw Error('no pending gate=\"' + original + '\" pgates=' +\n        JSON.stringify(Object.keys(this.pendingGates)));\n    }\n\n    const stillUnresolved = lookup.operands.some((o) => {\n      let { result, resolved } = this.checkContext(o);\n      if (typeof result === 'function') {\n        // while {} ?\n        result = result.call(); // call it\n        resolved = !this.scripting.isParseable(result);\n      }\n      return typeof result === 'undefined' || !resolved;\n    });\n\n    if (stillUnresolved) return original; // still deferred\n\n    const result = this.choice(lookup.deferredContext); // execute the gate\n    return result;\n  }\n\n  else(ctx) {\n    // this.print('else', this.nodeText);\n    return this.visit(ctx.expr).trim();\n  }\n\n  choice(ctx, opts) {\n    const $ = this.symbols;\n    let rawGate, gateResult;\n    const original = this.nodeText;\n    let info = original;\n    const choiceKey = this.RiScript._stringHash(original + ' #' + this.choiceId(ctx));\n\n    if (!this.isNoRepeat && this.hasNoRepeat(ctx.TF)) {\n      throw Error('noRepeat() not allowed on choice (use a $variable instead): ' + original);\n    }\n\n    let decision = 'accept';\n    if (opts?.forceReject) {\n      decision = 'reject';\n    } else {\n      if (ctx.gate) {\n        // do we have a gate\n        rawGate = ctx.gate[0].children.Gate[0].image;\n        gateResult = this.visit(ctx.gate);\n        decision = gateResult.decision;\n        info += `\\n  [gate] ${rawGate} -> ${decision !== 'defer'\n          ? decision.toUpperCase()\n          : `DEFER ${$.PENDING_GATE}${choiceKey}`\n          }  ${this.lookupsToString()}`;\n      }\n\n      if (gateResult) {\n        if (gateResult.decision === 'defer') {\n          this.pendingGates[choiceKey] = {\n            deferredContext: ctx,\n            operands: gateResult.operands\n          };\n          return `${$.PENDING_GATE}${choiceKey}`; // gate defers\n        }\n      }\n    }\n\n    if (decision === 'reject' && !('reject' in ctx)) {\n      return ''; // rejected without reject expr, return ''\n    }\n\n    const orExpr = ctx[decision]?.[0]?.children?.or_expr?.[0]; // yuck\n    const options = this.parseOptions(orExpr); // get options\n    if (!options) throw Error('No options in choice: ' + original);\n\n    let value = null;\n    const excluded = [];\n    let restored = false;\n    while (value === null) {\n      value = this.choose(options, excluded).value;\n\n      // if we still have script, defer until its resolved\n      if (this.scripting.isParseable(value)) {\n        if (ctx.TF) value = this.restoreTransforms(value, ctx.TF);\n        restored = true;\n        break;\n      }\n\n      // apply any remaining transforms\n      if (ctx.TF) value = this.applyTransforms(value, ctx.TF);\n\n      // we have 'norepeat' but value was already used, try again\n      if (this.isNoRepeat && value === this.choices[choiceKey]) {\n        this.print('choice.reject', value + ' [norepeat]');\n        excluded.push(value);\n        value = null;\n        continue;\n      }\n    }\n\n    if (!restored) this.choices[choiceKey] = value; // put in choice cache\n\n    return value;\n  }\n\n  // Helpers ================================================\n\n  hasNoRepeat(tfs) {\n    const transforms = this.RiScript._transformNames(tfs);\n    if (transforms.length) {\n      return transforms.includes('nr') || transforms.includes('norepeat');\n    }\n    return false;\n  }\n\n  checkContext(ident) {\n    let isStatic = false;\n    let isUser = false;\n    let result;\n\n    if (ident.length === 0) {\n      return { result: '', resolved: true, isStatic, isUser };\n    }\n\n    // check for dynamic symbol: $var\n    result = this.dynamics[ident];\n    if (typeof result === 'undefined') {\n      // no dynamic\n\n      // check for static symbol: #var\n      result = this.statics[ident];\n      if (typeof result !== 'undefined') {\n        isStatic = true; // found static\n      }\n    }\n\n    if (typeof result === 'undefined') {\n      // no static\n      // check for user-defined symbol: context[var]\n      result = this.context[ident];\n      if (typeof result !== 'undefined') {\n        isUser = true; // found user symbol\n      } else {\n        // check for user-defined dynamic? context[$var]\n        result = this.context[this.symbols.DYNAMIC + ident];\n        if (typeof result !== 'undefined') {\n          // no static\n          // note: treat as normal dynamic, isUser = false\n        }\n      }\n    }\n\n    // do we have more script to deal with ?\n    const resolved = !this.scripting.isParseable(result);\n\n    return { result, isStatic, isUser, resolved }; // TODO: replace with 'type'\n  }\n\n  inlineAssignment(ident, tfs, result) {\n    const $ = this.symbols;\n    const lhs = $.STATIC + ident;\n    const rhs = this.restoreTransforms(result, tfs);\n    result = $.OPEN_CHOICE + (lhs + '=' + rhs) + $.CLOSE_CHOICE;\n    return result;\n  }\n\n  choiceId(ctx) {\n    if (!ctx.OC || !ctx.OC.length) throw Error('invalid choice');\n    return ctx.OC[0].startOffset + '.' + ctx.OC[0].endOffset;\n  }\n\n  parseOptions(ctx) {\n    const options = [];\n    if (ctx && ctx?.children?.wexpr) {\n      const wexprs = ctx.children.wexpr;\n      for (let i = 0; i < wexprs.length; i++) {\n        const wexpr = wexprs[i];\n        const expr = wexpr.children.expr;\n        if (expr && expr.length != 1) { throw Error('invalid choice-expr: ' + expr.length); }\n\n        const weight = wexpr.children.Weight;\n        if (weight) {\n          if (weight.length != 1) { throw Error('invalid weight: ' + weight.length); }\n          let mult = 1;\n          try {\n            mult = parseInt(\n              this.symbols.CLOSE_WEIGHT.length\n                ? weight[0].image.trim().slice(1, -1)\n                : weight[0].image.trim().slice(1)\n            );\n          } catch (e) {\n            console.log('EX: ' + mult);\n          }\n          Array.from({ length: mult }, () => options.push(expr));\n        } else {\n          options.push(expr || '');\n        }\n      }\n    }\n    return options;\n  }\n\n  chooseUnique(options, choiceKey) {\n    // not used\n\n    const isUnique = false;\n    while (options.length && !isUnique) {\n      const { index, value } = this.choose(options);\n      if (value !== this.choices[choiceKey]) return value;\n      // console.log(`Skipping ${index}: '${value}'`);\n      options.splice(index, 1);\n    }\n    throw Error('No remaining options');\n  }\n\n  choose(options, excludes = []) {\n    if (!options || !options.length) {\n      throw Error('Invalid choice: no options');\n    }\n\n    const valid = options.filter((x) => !excludes.includes(x));\n    if (!valid.length) {\n      throw Error('Invalid choice: no valid options');\n    }\n\n    const index = this.scripting.RiTa.randi(valid.length);\n\n    let value = ''; const selected = valid[index];\n\n    if (typeof selected === 'string') {\n      this.print('choice.text', \"''\");\n    } else {\n      // if (typeof selected === 'object') {\n      this.path = 'choice.' + this.path;\n      value = this.visit(selected); // cstNode\n    }\n\n    if (typeof value === 'string') value = value.trim();\n\n    return { index, value };\n  }\n\n  applyTransforms(value, txs) {\n    if (this.traceTx) { console.log('applyTransforms', this.formatTxs(...arguments)); }\n    for (let i = 0; i < txs.length; i++) {\n      value = this.applyTransform(value, txs[i]);\n    }\n    return value;\n  }\n\n  // value is not yet resolved, so store with transform for later\n  restoreTransforms(value, txs) {\n    if (typeof value === 'string') {\n      const patt = new RegExp(\n        '^' + this.escaped.OPEN_CHOICE + '.*' + this.escaped.CLOSE_CHOICE + '$'\n      );\n      if (!patt.test(value)) {\n        // wrap in choice to preserve\n        value = this.symbols.OPEN_CHOICE + value + this.symbols.CLOSE_CHOICE;\n      }\n      if (txs) {\n        txs.forEach((tx) => (value += tx.image)); // append transform strings\n      }\n      if (this.traceTx) console.log('restoreTransforms:', value);\n    }\n    return value;\n  }\n\n  castValues(obj) {\n    let madeCast = false;\n    Object.entries(obj).forEach(([k, v]) => {\n      const num = parseFloat(v);\n      if (!isNaN(num)) {\n        madeCast = true;\n        obj[k] = num; // update object with casted value\n      }\n    });\n    return madeCast;\n  }\n\n  contextIsResolved(table) {\n    let allResolved = true;\n    Object.entries(table).forEach(([key, val]) => {\n      if (!this.scripting.isParseable(val)) {\n        allResolved = false;\n      }\n    });\n    return allResolved;\n  }\n\n  applyTransform(target, transform) {\n    const image = transform.image;\n    let result;\n    const raw = target + image;\n    const tx = image.substring(1).replace(/\\(\\)$/, '');\n\n    // function in dynamics\n    if (typeof this.dynamics[tx] === 'function') {\n      result = this.dynamics[tx](target);\n    }\n    // function in statics\n    else if (typeof this.statics[tx] === 'function') {\n      result = this.statics[tx](target);\n    }\n    // function in context\n    else if (typeof this.context[tx] === 'function') {\n      result = this.context[tx](target);\n    }\n\n    // function in transforms\n    else if (typeof this.RiScript.transforms[tx] === 'function') {\n      result = this.RiScript.transforms[tx](target);\n    }\n    // member functions (usually on String)\n    else if (typeof target[tx] === 'function') {\n      result = target[tx]();\n    } else {\n      // check for property\n      if (target.hasOwnProperty(tx)) {\n        result = target[tx];\n      } else {\n        if (!this.scripting.RiTa.SILENT && !this.scripting.silent) {\n          console.warn('[WARN] Unresolved transform: ' + raw);\n        }\n\n        /* Replace transform parens so as not to trigger\n           RiScript.isParseable (for example, in v2) 0 */\n        result = raw.replace(/\\(\\)$/, '&lpar;&rpar;');\n      }\n    }\n\n    if (this.trace) { console.log(`${this.tindent()}[transform] ${raw} -> '${result}'`); }\n\n    return result;\n  }\n\n  lookupsToString() {\n    const dyns = {};\n    const stats = {};\n    Object.entries(this.dynamics || {}).forEach(\n      ([k, v]) => (dyns[`$${k} `] = v)\n    );\n    Object.entries(this.statics || {}).forEach(\n      ([k, v]) => (stats[`#${k} `] = v)\n    );\n    return JSON.stringify({ ...this.context, ...stats, ...dyns }, (k, v) =>\n      typeof v === 'function' ? '<f*:pending>' : v\n    ).replace(/\"/g, '');\n  }\n\n  formatTxs(value, txs) {\n    return value + txs.map((tx) => tx.image.replace(/()/, '') + '()').join('');\n  }\n\n  print(s, ...args) {\n    if (this.trace) {\n      if (this.path && s !== 'script') {\n        s = this.path.replace(/\\.$/, '');\n      }\n      console.log(++this.order, `[${s}]`, ...args);\n      this.path = '';\n    }\n  }\n\n  tindent() {\n    return ' '.repeat((this.order + '').length + 1);\n  }\n}\n\nexport { RiScriptVisitor };\n\n// console.log('&#33; -> '+decode('&#33;'));\n// console.log('&amp; -> '+decode('&amp;'));\n","import { RiScript } from './riscript.js'\n\nclass RiGrammar {\n\n  constructor(rules = {}, context = {}) {\n    if (typeof rules !== 'object') {\n      throw Error('RiGrammar: expecting object, found ' + typeof rules);\n    }\n\n    this.scripting = new RiScript();\n    this.context = context;\n    this.setRules(rules);\n  }\n\n  static expand(rules, context, opts) {\n    return new RiGrammar(rules, context).expand(opts);\n  }\n\n  addTransform() {\n    return RiScript.addTransform(...arguments);\n  }\n  removeTransform() {\n    return RiScript.removeTransform(...arguments);\n  }\n  getTransforms() {\n    return RiScript.transforms;\n  }\n\n  equals(rg) {\n    return rg.toJSON() === this.toJSON();\n  }\n\n  expand(opts = {}) {\n    if ('context' in opts) {\n      throw Error('pass context to RiScript.grammar() or new RiGrammar() instead');\n    }\n\n    // TODO: clone opts here ?\n    opts.visitor = opts.visitor || new RiScript.Visitor(this.scripting);\n    opts.visitor.context = this.context || {};\n    opts.input = this._toScript(opts);\n    // opts.noAddedSilence = true;\n\n    return this.scripting._evaluate(opts);\n  }\n\n  addRule(name, def) {\n    this._validateRule(name, def);\n    this.rules[name] = def;\n  }\n\n  setRules(rules) {\n    if (typeof rules === 'undefined') throw Error('undefined rules');\n    this.rules = {};\n    let incoming = typeof rules === 'string' ? parseJSON(rules) : rules;\n    let self = this;\n    Object.entries(incoming).forEach((e) => self.addRule(...e));\n  }\n\n  removeRule(name) {\n    if (name in this.rules) {\n      delete this.rules[name];\n    }\n  }\n\n  toJSON() {\n    return JSON.stringify(this.rules, ...arguments);\n  }\n\n  toString(opts = {}) {\n    let replacer = opts.replacer || 0;\n    let space = opts.space || 2;\n    let lb = opts?.linebreak;\n    let res = this.toJSON(replacer, space);\n    if (lb) res = res.replace(/\\n/g, lb);\n    return res;\n  }\n\n  static fromJSON(str, opts) {\n    return new RiGrammar(JSON.parse(str), opts);\n  }\n\n  /* \n    Convert grammar to inline rules;\n    rules are dynamic, unless otherwise specified with leading #\n  */\n  _toScript(opts) {\n    let script = '',\n      start = opts.start || 'start';\n    let { Symbols } = this.scripting;\n\n    if (start.startsWith(Symbols.DYNAMIC)) {\n      start = start.substring(Symbols.DYNAMIC.length);\n    }\n\n    if (start.startsWith(Symbols.STATIC)) {\n      start = start.substring(Symbols.STATIC.length);\n    }\n\n    if (!(start in this.rules || Symbols.STATIC + start in this.rules)) {\n      throw Error('Rule: \"' + start + '\" not found in grammar');\n    }\n\n    Object.entries(this.rules).forEach(([name, rule], i) => {\n      while (name.startsWith(Symbols.DYNAMIC)) {\n        name = name.substring(1);\n      }\n      if (!name.startsWith(Symbols.STATIC)) {\n        name = Symbols.DYNAMIC + name;\n      }\n      // console.log(i,name);\n      if (!this.scripting.ChoiceWrapRE.test(rule)) {\n        // let orig = rule;\n        rule = Symbols.OPEN_CHOICE + rule + Symbols.CLOSE_CHOICE;\n        // console.log('WRAPPING: ' + orig + '->' + rule);\n      }\n      script += `${name}=${rule}\\n`;\n    });\n\n    if (opts.trace) console.log('Grammar:\\n' + script.replace(/^\\$/gm, '  $'));\n\n    script += `${Symbols.DYNAMIC}${start}`;\n    return script;\n  }\n\n  _validateRule(name, def) {\n    if (typeof name !== 'string' || name.length === 0) {\n      throw Error('expected [string] name');\n    }\n\n    if (typeof def === 'undefined') {\n      throw Error('undefined rule def: ' + name);\n    }\n    let { Symbols } = this.scripting;\n\n    if (name.startsWith(Symbols.DYNAMIC)) {\n      name = name.substring(Symbols.DYNAMIC.length);\n      throw Error(\n        'Grammar rules are dynamic by default;' +\n          \" if you need a static rule, use '\" +\n          Symbols.STATIC +\n          name +\n          \"', otherwise just use '\" +\n          name +\n          \"'.\"\n      );\n    }\n  }\n}\n\nfunction parseJSON(json) {\n  if (typeof json === 'string') {\n    try {\n      return JSON.parse(json);\n    } catch (e) {\n      throw Error(\n        'RiGrammar appears to be invalid JSON,' +\n          ' please check it at http://jsonlint.com/\\n' +\n          json\n      );\n    }\n  }\n}\n\nexport { RiGrammar };\n","import { RiScript } from './riscript.js';\nimport { RiGrammar } from './grammar.js';\nimport { RiScriptVisitor } from './visitor.js';\n\nRiScript.Grammar = RiGrammar;\nRiScript.Visitor = RiScriptVisitor;\n\nexport default RiScript\n"],"mappings":"6KAAA,OAAOA,OAAQ,KACf,OAAS,SAAAC,OAAa,QCDtB,OAAS,SAAAC,GAAO,WAAAC,GAAS,OAAAC,GAAK,WAAAC,GAAS,OAAAC,GAAK,UAAAC,OAAc,YAC1D,OAAS,oBAAAC,OAAwB,oBCDjC,OAAS,QAAAC,GAAM,WAAAC,OAAe,YAC9B,OACE,eAAAC,GACA,eAAAC,GACA,eAAAC,GACA,UAAAC,GACA,cAAAC,GACA,uBAAAC,GACA,oCAAAC,GACA,2BAAAC,GACA,YAAAC,OACK,mBAMD,IAAgBC,EAAhB,KAA0B,CAC9B,KAAKC,EAAqCC,EAAkB,CAAA,EAAE,CAC5DZ,GAAQW,EAAK,WAAY,CAACE,EAAsBC,IAAS,CACvD,IAAMC,EAAWhB,GAAKY,EAAK,WAAYG,EAAQ,CAAC,EAEhD,GAAID,aAAmBV,GACrB,KAAK,YAAYU,EAASE,EAAUH,CAAQ,UACnCC,aAAmBJ,GAC5B,KAAK,aAAaI,EAASE,EAAUH,CAAQ,UACpCC,aAAmBX,GAC5B,KAAK,SAASW,EAASE,EAAUH,CAAQ,UAChCC,aAAmBT,GAC5B,KAAK,WAAWS,EAASE,EAAUH,CAAQ,UAClCC,aAAmBP,GAC5B,KAAK,eAAeO,EAASE,EAAUH,CAAQ,UACtCC,aAAmBN,GAC5B,KAAK,kBAAkBM,EAASE,EAAUH,CAAQ,UACzCC,aAAmBL,GAC5B,KAAK,YAAYK,EAASE,EAAUH,CAAQ,UACnCC,aAAmBR,GAC5B,KAAK,SAASQ,EAASE,EAAUH,CAAQ,UAChCC,aAAmBZ,GAC5B,KAAK,OAAOY,EAASE,EAAUH,CAAQ,MAEvC,OAAM,MAAM,sBAAsB,CAEtC,CAAC,CACH,CAEA,aACEI,EACAD,EACAH,EAAuB,CAChB,CAET,YACEK,EACAF,EACAH,EAAuB,CAChB,CAET,SACEM,EACAH,EACAH,EAAuB,CAGvB,IAAMO,EAAaJ,EAAS,OAAOH,CAAQ,EAC3C,KAAK,KAAKM,EAAeC,CAAU,CACrC,CAEA,WACEC,EACAL,EACAH,EAAuB,CAGvB,IAAMO,EAAaJ,EAAS,OAAOH,CAAQ,EAC3C,KAAK,KAAKQ,EAAiBD,CAAU,CACvC,CAEA,eACEE,EACAN,EACAH,EAAuB,CAGvB,IAAMU,EAAoC,CACxC,IAAIlB,GAAO,CAAE,WAAYiB,EAAe,UAAU,CAAE,GACpD,OAAYN,EAAeH,CAAQ,EACrC,KAAK,KAAKS,EAAgBC,CAAkB,CAC9C,CAEA,kBACEC,EACAR,EACAH,EAAuB,CAGvB,IAAMY,EAAwBC,GAC5BF,EACAR,EACAH,CAAQ,EAEV,KAAK,KAAKW,EAAmBC,CAAqB,CACpD,CAEA,SACEE,EACAX,EACAH,EAAuB,CAGvB,IAAMe,EAA8B,CAClC,IAAIvB,GAAO,CAAE,WAAYsB,EAAS,UAAU,CAAE,GAC9C,OAAYX,EAAeH,CAAQ,EACrC,KAAK,KAAKc,EAAUC,CAAY,CAClC,CAEA,YACEC,EACAb,EACAH,EAAuB,CAGvB,IAAMiB,EAAkBJ,GACtBG,EACAb,EACAH,CAAQ,EAEV,KAAK,KAAKgB,EAAaC,CAAe,CACxC,CAEA,OACEC,EACAf,EACAH,EAAuB,CAGvB,IAAMO,EAAaJ,EAAS,OAAOH,CAAQ,EAE3CZ,GAAQ8B,EAAO,WAAaC,GAAO,CAIjC,IAAMC,EAAc,IAAI9B,GAAY,CAAE,WAAY,CAAC6B,CAAG,CAAC,CAAE,EACzD,KAAK,KAAKC,EAAkBb,CAAU,CACxC,CAAC,CACH,GAGF,SAASM,GACPQ,EACAlB,EACAH,EAAuB,CAUvB,MARmB,CACjB,IAAIR,GAAO,CACT,WAAY,CACV,IAAIK,GAAS,CAAE,aAAcwB,EAAW,SAAS,CAAE,GACnD,OAAOA,EAAW,UAAU,EAC/B,GAE8C,OAAOlB,EAAUH,CAAQ,CAE5E,CClKA,OAAS,WAAAsB,GAAS,OAAAC,GAAK,QAAAC,OAAY,YACnC,OACE,mBAAAC,GACA,kBAAAC,GACA,kBAAAC,GACA,eAAAC,GACA,YAAAC,OACK,mBAGD,SAAUC,GAAMC,EAAiB,CAErC,GAAIA,aAAgBH,GASlB,OAAOE,GAAoBC,EAAM,cAAc,EAC1C,GAAIA,aAAgBF,GACzB,OAAOG,GAA2BD,CAAI,EACjC,GAAIJ,GAAeI,CAAI,EAC5B,OAAOE,GAAiBF,CAAI,EACvB,GAAIN,GAAgBM,CAAI,EAC7B,OAAOG,GAAkBH,CAAI,EAE7B,MAAM,MAAM,sBAAsB,CAEtC,CAEM,SAAUE,GAAiBF,EAEhC,CACC,IAAII,EAAwB,CAAA,EACtBC,EAAML,EAAK,WACbM,EAAiB,EACjBC,EAAyBF,EAAI,OAASC,EACtCE,EAEAC,EAA0B,GAE9B,KAAOF,GAA0BE,GAC/BD,EAAcH,EAAIC,CAAc,EAChCG,EAA0Bd,GAAea,CAAW,EACpDJ,EAAWA,EAAS,OAAOL,GAAMS,CAAW,CAAC,EAC7CF,EAAiBA,EAAiB,EAClCC,EAAyBF,EAAI,OAASC,EAGxC,OAAOb,GAAKW,CAAQ,CACtB,CAEM,SAAUD,GAAkBH,EAEjC,CACC,IAAMU,EAAuClB,GAC3CQ,EAAK,WACJW,GACQZ,GAAMY,CAAS,CACvB,EAEH,OAAOlB,GAAKF,GAAmBmB,CAAqB,CAAC,CACvD,CAEM,SAAUT,GAAiBW,EAAkB,CACjD,MAAO,CAACA,EAAS,YAAY,CAC/B,CCnEA,OAAS,UAAAC,GAAQ,WAAAC,OAAe,YCDzB,IAAMC,GAAK,SDGlB,OAAS,eAAAC,OAAgD,mBAKnD,IAAOC,GAAP,cAAmCC,CAAU,CAGjD,YAAoBC,EAAa,CAC/B,MAAK,EADa,KAAA,QAAAA,EAFb,KAAA,QAAuC,CAAA,CAI9C,CAEA,cAAY,CACV,YAAK,KAAK,KAAK,OAAO,EACf,KAAK,OACd,CAEA,aACEC,EACAC,EACAC,EAAuB,CAGzB,CAEA,YACEC,EACAF,EACAC,EAAuB,CAEvB,IAAME,EACJC,GAA8BF,EAAQ,eAAgBA,EAAQ,GAAG,EACjE,KAAK,QAAQ,KACTG,EAA0BL,EAAS,OAAOC,CAAQ,EAClDK,EAAW,IAAIX,GAAY,CAAE,WAAYU,CAAQ,CAAE,EACnDE,EAAuBC,GAAMF,CAAQ,EAC3C,KAAK,QAAQH,CAAU,EAAII,CAC7B,GAGI,SAAUE,GACdC,EAAsB,CAEtB,IAAMC,EAAgB,CAAA,EAEtB,OAAAC,GAAQF,EAAiBZ,GAAW,CAClC,IAAMe,EAAiB,IAAIjB,GAAoBE,CAAO,EAAE,aAAY,EACpEgB,GAAOH,EAAeE,CAAc,CACtC,CAAC,EACMF,CACT,CAEM,SAAUP,GACdW,EACAC,EAAyB,CAEzB,OAAOD,EAAM,KAAOC,EAAoBC,EAC1C,CE7DA,OAAS,OAAAC,GAAK,YAAAC,GAAU,eAAAC,OAAmB,YCA3C,OAAS,qBAAAC,OAAyB,4BAMlC,OACE,WAAAC,GACA,YAAAC,GACA,cAAAC,GACA,UAAAC,EACA,QAAAC,GACA,SAAAC,GACA,WAAAC,GACA,WAAAC,EACA,OAAAC,EACA,YAAAC,GACA,WAAAC,GACA,WAAAC,GACA,WAAAC,GACA,cAAAC,GACA,YAAAC,GACA,YAAAC,EACA,eAAAC,GACA,QAAAC,GACA,OAAAC,EACA,UAAAC,GACA,UAAAC,GACA,UAAAC,OACK,YACP,OAAS,eAAAC,OAAmB,oBC9B5B,OAGE,qBAAAC,OAKK,4BACP,OAAS,SAAAC,GAAO,QAAAC,GAAM,WAAAC,GAAS,YAAAC,GAAU,WAAAC,GAAS,UAAAC,OAAc,YAChE,OAAS,eAAAC,GAAa,iBAAAC,OAAqB,oBCV3C,OAKE,gBAAAC,OAEK,4BAEP,IAAIC,GAAqD,CAAA,EACnDC,GAAe,IAAIF,GAUnB,SAAUG,GAAaC,EAAc,CACzC,IAAMC,EAAYD,EAAO,SAAQ,EACjC,GAAIH,GAAe,eAAeI,CAAS,EACzC,OAAOJ,GAAeI,CAAS,EAC1B,CACL,IAAMC,EAAYJ,GAAa,QAAQG,CAAS,EAChD,OAAAJ,GAAeI,CAAS,EAAIC,EACrBA,EAEX,CAEM,SAAUC,IAAsB,CACpCN,GAAiB,CAAA,CACnB,CDnBA,IAAMO,GACJ,gEACWC,GACX;EAEI,SAAUC,GACdC,EACAC,EAAsB,GAAK,CAE3B,GAAI,CACF,IAAMC,EAAMC,GAAaH,CAAM,EAM/B,OALmBI,GACjBF,EAAI,MACJ,CAAA,EACAA,EAAI,MAAM,UAAU,QAGfG,EAAP,CAIA,GAAIA,EAAE,UAAYR,GACZI,GACFK,GACE,GAAGR,4BAC0BE,EAAO,SAAQ;;;2FAGmD,MAG9F,CACL,IAAIO,EAAY,GACZN,IACFM,EACE;;iGAGJC,GACE,GAAGV;qBACsBE,EAAO,SAAQ;;2EAGtCO,CAAS,GAKjB,MAAO,CAAA,CACT,CAEM,SAAUH,GACdF,EACAO,EACAC,EAAmB,CAEnB,OAAQR,EAAI,KAAM,CAChB,IAAK,cACH,QAAS,EAAI,EAAG,EAAIA,EAAI,MAAM,OAAQ,IACpCE,GAA0BF,EAAI,MAAM,CAAC,EAAGO,EAAQC,CAAU,EAE5D,MACF,IAAK,cACH,IAAMC,EAAQT,EAAI,MAClB,QAAS,EAAI,EAAG,EAAIS,EAAM,OAAQ,IAAK,CACrC,IAAMC,EAAOD,EAAM,CAAC,EAGpB,OAAQC,EAAK,KAAM,CACjB,IAAK,YAIL,IAAK,qBAEL,IAAK,YACL,IAAK,oBACL,IAAK,cACL,IAAK,eACL,IAAK,kBACH,SAGJ,IAAMC,EAAOD,EACb,OAAQC,EAAK,KAAM,CACjB,IAAK,YACHC,GAAwBD,EAAK,MAAOJ,EAAQC,CAAU,EACtD,MACF,IAAK,MACH,GAAIG,EAAK,aAAe,GACtB,MAAM,MAAMhB,EAAsB,EAEpCkB,GAAQF,EAAK,MAAQG,GAAQ,CAC3B,GAAI,OAAOA,GAAS,SAClBF,GAAwBE,EAAMP,EAAQC,CAAU,MAC3C,CAEL,IAAMO,EAAQD,EAEd,GAAIN,IAAe,GACjB,QACMQ,EAAYD,EAAM,KACtBC,GAAaD,EAAM,GACnBC,IAEAJ,GAAwBI,EAAWT,EAAQC,CAAU,MAIpD,CAEH,QACMQ,EAAYD,EAAM,KACtBC,GAAaD,EAAM,IAAMC,EAAYC,GACrCD,IAEAJ,GAAwBI,EAAWT,EAAQC,CAAU,EAIvD,GAAIO,EAAM,IAAME,GAAoB,CAClC,IAAMC,EACJH,EAAM,MAAQE,GACVF,EAAM,KACNE,GACAE,EAAcJ,EAAM,GACpBK,EAAYC,EAAyBH,CAAW,EAChDI,EAAYD,EAAyBF,CAAW,EAEtD,QACMI,EAAaH,EACjBG,GAAcD,EACdC,IAEAhB,EAAOgB,CAAU,EAAIA,IAK/B,CAAC,EACD,MACF,IAAK,QACHrB,GAA0BS,EAAK,MAAOJ,EAAQC,CAAU,EACxD,MAEF,QACE,MAAM,MAAM,sBAAsB,EAItC,IAAMgB,EACJb,EAAK,aAAe,QAAaA,EAAK,WAAW,UAAY,EAC/D,GAGGA,EAAK,OAAS,SAAWc,GAAgBd,CAAI,IAAM,IAEnDA,EAAK,OAAS,SAAWa,IAAyB,GAEnD,MAGJ,MAEF,QACE,MAAM,MAAM,uBAAuB,EAIvC,OAAOE,GAAOnB,CAAM,CACtB,CAEA,SAASK,GACPE,EACAP,EACAC,EAAmB,CAEnB,IAAMmB,EAAmBN,EAAyBP,CAAI,EACtDP,EAAOoB,CAAgB,EAAIA,EAEvBnB,IAAe,IACjBoB,GAAiBd,EAAMP,CAAM,CAEjC,CAEA,SAASqB,GACPd,EACAP,EAAsC,CAEtC,IAAMsB,EAAO,OAAO,aAAaf,CAAI,EAC/BgB,EAAYD,EAAK,YAAW,EAElC,GAAIC,IAAcD,EAAM,CACtB,IAAMF,EAAmBN,EAAyBS,EAAU,WAAW,CAAC,CAAC,EACzEvB,EAAOoB,CAAgB,EAAIA,MACtB,CACL,IAAMI,EAAYF,EAAK,YAAW,EAClC,GAAIE,IAAcF,EAAM,CACtB,IAAMF,EAAmBN,EACvBU,EAAU,WAAW,CAAC,CAAC,EAEzBxB,EAAOoB,CAAgB,EAAIA,GAGjC,CAEA,SAASK,GAASC,EAAcC,EAAyB,CACvD,OAAOC,GAAKF,EAAQ,MAAQG,GAAe,CACzC,GAAI,OAAOA,GAAgB,SACzB,OAAOC,GAASH,EAAiBE,CAAW,EACvC,CAEL,IAAMrB,EAAaqB,EACnB,OACED,GACED,EACCI,GAAevB,EAAM,MAAQuB,GAAcA,GAAcvB,EAAM,EAAE,IAC9D,OAGZ,CAAC,CACH,CAEA,SAASU,GAAgBzB,EAAQ,CAC/B,IAAMuC,EAAcvC,EAAa,WACjC,OAAIuC,GAAcA,EAAW,UAAY,EAChC,GAGJvC,EAAI,MAIFwC,GAAQxC,EAAI,KAAK,EACpByC,GAAMzC,EAAI,MAAOyB,EAAe,EAChCA,GAAgBzB,EAAI,KAAK,EALpB,EAMX,CAEA,IAAM0C,GAAN,cAA6BC,EAAiB,CAG5C,YAAoBT,EAAyB,CAC3C,MAAK,EADa,KAAA,gBAAAA,EAFpB,KAAA,MAAiB,EAIjB,CAEA,cAAcU,EAAa,CAEzB,GAAI,KAAK,QAAU,GAMnB,QAAQA,EAAK,KAAM,CACjB,IAAK,YACH,KAAK,eAAeA,CAAI,EACxB,OACF,IAAK,oBACH,KAAK,uBAAuBA,CAAI,EAChC,OAGJ,MAAM,cAAcA,CAAI,EAC1B,CAEA,eAAeA,EAAe,CACxBP,GAAS,KAAK,gBAAiBO,EAAK,KAAK,IAC3C,KAAK,MAAQ,GAEjB,CAEA,SAASA,EAAS,CACZA,EAAK,WACHZ,GAASY,EAAM,KAAK,eAAe,IAAM,SAC3C,KAAK,MAAQ,IAGXZ,GAASY,EAAM,KAAK,eAAe,IAAM,SAC3C,KAAK,MAAQ,GAGnB,GAGI,SAAUC,GACdC,EACAC,EAAwB,CAExB,GAAIA,aAAmB,OAAQ,CAC7B,IAAM/C,EAAMC,GAAa8C,CAAO,EAC1BC,EAAiB,IAAIN,GAAeI,CAAS,EACnD,OAAAE,EAAe,MAAMhD,CAAG,EACjBgD,EAAe,UAEtB,QACEb,GAAUY,EAAUlB,GACXQ,GAASS,EAAoBjB,EAAM,WAAW,CAAC,CAAC,CACxD,IAAM,MAGb,CD7QA,IAAMoB,GAAU,UACHC,GAAe,cACfC,GAAQ,QAuBVC,GACT,OAAa,IAAI,OAAO,MAAM,EAAG,QAAW,UAUxC,SAAUC,GACdC,EACAC,EAQC,CAEDA,EAAUC,GAASD,EAAS,CAC1B,UAAWE,GACX,MAAO,GACP,SAAU,GACV,iBAAkB,OAClB,yBAA0B,CAAC,KAAM;CAAI,EACrC,OAAQ,CAACC,EAAaC,IAAqBA,EAAM,EAClD,EAED,IAAMC,EAASL,EAAQ,OAEvBK,EAAO,kCAAmC,IAAK,CAC7CC,GAA+B,CACjC,CAAC,EAED,IAAIC,EACJF,EAAO,kBAAmB,IAAK,CAC7BE,EAAoBC,GAAOT,EAAaU,GAC/BA,EAASC,EAAO,IAAMC,EAAM,EACpC,CACH,CAAC,EAED,IAAIC,EAAY,GACZC,EACJR,EAAO,qBAAsB,IAAK,CAChCO,EAAY,GACZC,EAAyBC,EACvBP,EACCE,GAAkC,CACjC,IAAMM,EAAcN,EAASC,EAAO,EAGpC,GAAIM,GAASD,CAAW,EAAG,CACzB,IAAME,EAAeF,EAAY,OACjC,OACEE,EAAa,SAAW,GAExBA,IAAiB,KACjBA,IAAiB,KACjBA,IAAiB,KACjB,CAACF,EAAY,WAENE,EAEPA,EAAa,SAAW,GACxBA,EAAa,CAAC,IAAM,MAEpB,CAACC,GACC,CACE,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,KAEFD,EAAa,CAAC,CAAC,EAMVA,EAAa,CAAC,EAEdjB,EAAQ,UACXmB,GAAcJ,CAAW,EACzBK,GAAgBL,CAAW,MAE5B,IAAIM,GAAWN,CAAW,EAC/B,OAAAH,EAAY,GAEL,CAAE,KAAMG,CAAW,EACrB,GAAI,OAAOA,GAAgB,SAChC,OAAAH,EAAY,GAELG,EACF,GAAI,OAAOA,GAAgB,SAAU,CAC1C,GAAIA,EAAY,SAAW,EACzB,OAAOA,EACF,CACL,IAAMO,EAAsBP,EAAY,QACtC,sBACA,MAAM,EAEFQ,EAAgB,IAAI,OAAOD,CAAmB,EACpD,OAAOtB,EAAQ,UACXmB,GAAcI,CAAa,EAC3BH,GAAgBG,CAAa,OAGnC,OAAM,MAAM,sBAAsB,EAEtC,CAAC,CAEL,CAAC,EAED,IAAIC,EACAC,EACAC,EACAC,EACAC,EACJvB,EAAO,eAAgB,IAAK,CAC1BmB,EAAmBV,EACjBP,EACCE,GAAaA,EAAS,YAAa,EAGtCgB,EAAoBX,EAAIP,EAAoBsB,GAAc,CACxD,IAAMC,EAAYD,EAAM,MAExB,GAAIC,IAAcnB,EAAM,QAEjB,IAAIoB,EAASD,CAAS,EAC3B,OAAOA,EACF,GAAIE,GAAYF,CAAS,EAC9B,MAAO,GAEP,MAAM,MAAM,sBAAsB,EAEtC,CAAC,EAEDJ,EAA8BZ,EAAIP,EAAoBsB,GAAc,CAClE,IAAMI,EAAgBJ,EAAM,WAE5B,GAAII,EAIF,OAHwBC,GAAQD,CAAa,EACzCnB,EAAImB,EAAgBE,GAAcC,GAAQ7B,EAAmB4B,CAAI,CAAC,EAClE,CAACC,GAAQ7B,EAAmB0B,CAAa,CAAC,CAGlD,CAAC,EAEDN,EAAuBb,EACrBP,EACCsB,GAAeA,EAAM,SAAS,EAGjCD,EAAsBd,EAAIP,EAAoBsB,GAC5CQ,EAAIR,EAAO,UAAU,CAAC,CAE1B,CAAC,EAED,IAAIS,EACJjC,EAAO,2BAA4B,IAAK,CACtC,IAAMkC,EAA0BC,GAC9BxC,EAAQ,wBAAyB,EAEnCsC,EAAgCxB,EAAIP,EAAoBkC,GAAY,EAAK,EACrEzC,EAAQ,mBAAqB,eAC/BsC,EAAgCxB,EAAIP,EAAoBkC,GAClDJ,EAAII,EAAS,aAAa,EACrB,CAAC,CAACA,EAAQ,YAGfC,GAAsBD,EAASF,CAAuB,IAAM,IAC5DI,GACEJ,EACAE,EAAQ,OAA0B,CAIzC,EAEL,CAAC,EAED,IAAIG,EACAC,EACAC,EACAC,EACJ1C,EAAO,kBAAmB,IAAK,CAC7BuC,EAAuB9B,EAAIP,EAAmByC,EAAe,EAC7DH,EAAoB/B,EAAID,EAAwBoC,EAAc,EAE9DH,EAAcI,GACZ3C,EACA,CAAC4C,EAAKtB,IAAc,CAClB,IAAMC,EAAYD,EAAM,MACxB,OAAIE,EAASD,CAAS,GAAOA,IAAcnB,EAAM,UAC/CwC,EAAIrB,CAAS,EAAI,CAAA,GAEZqB,CACT,EACA,CAAA,CAAuC,EAGzCJ,EAAqBjC,EACnBD,EACA,CAACuC,EAAGC,KACK,CACL,QAASxC,EAAuBwC,CAAG,EACnC,UAAW3B,EAA4B2B,CAAG,EAC1C,kBAAmBf,EAA8Be,CAAG,EACpD,SAAUT,EAAqBS,CAAG,EAClC,MAAOR,EAAkBQ,CAAG,EAC5B,MAAO5B,EAAkB4B,CAAG,EAC5B,KAAM1B,EAAqB0B,CAAG,EAC9B,IAAKzB,EAAoByB,CAAG,EAC5B,aAAc7B,EAAiB6B,CAAG,EAClC,UAAW9C,EAAkB8C,CAAG,GAEnC,CAEL,CAAC,EAED,IAAIC,EAAiB,GACjBC,EACF,CAAA,EAEF,OAAKvD,EAAQ,UACXK,EAAO,0BAA2B,IAAK,CACrCkD,EAA+BL,GAC7B3C,EACA,CAACiD,EAAQC,EAAaJ,IAAO,CAC3B,GAAI,OAAOI,EAAY,SAAY,SAAU,CAC3C,IAAMC,EAAWD,EAAY,QAAQ,WAAW,CAAC,EAC3CE,EAAeC,EAAyBF,CAAQ,EACtDG,GAAiBL,EAAQG,EAAcZ,EAAmBM,CAAG,CAAC,UACrDnB,GAAQuB,EAAY,gBAAgB,EAAG,CAChD,IAAIK,EACJC,EAAQN,EAAY,iBAAmBO,GAAa,CAClD,IAAMN,GACJ,OAAOM,GAAc,SACjBA,EAAU,WAAW,CAAC,EACtBA,EACAC,EAAmBL,EAAyBF,EAAQ,EAKtDI,IAAqBG,IACvBH,EAAmBG,EACnBJ,GACEL,EACAS,EACAlB,EAAmBM,CAAG,CAAC,EAG7B,CAAC,UACQrC,GAASyC,EAAY,OAAO,EACrC,GAAIA,EAAY,QAAQ,QACtBH,EAAiB,GACbtD,EAAQ,qBACVkE,GACE,GAAGC,0BACwBV,EAAY,QAAQ,SAAQ;;;gGAG6C,MAGnG,CACL,IAAMW,EAAiBC,GACrBZ,EAAY,QACZzD,EAAQ,mBAAmB,EAKzBsE,GAAQF,CAAc,IAIxBd,EAAiB,IAEnBS,EAAQK,EAAiBG,GAAQ,CAC/BV,GAAiBL,EAAQe,EAAMxB,EAAmBM,CAAG,CAAC,CACxD,CAAC,OAGCrD,EAAQ,qBACVkE,GACE,GAAGC,kBACgBV,EAAY;;+FAEoE,EAGvGH,EAAiB,GAGnB,OAAOE,CACT,EACA,CAAA,CAA8C,CAElD,CAAC,EAGI,CACL,YAAaV,EACb,mBAAoBC,EACpB,6BAA8BQ,EAC9B,UAAW3C,EACX,eAAgB0C,EAEpB,CAEM,SAAUkB,GACdzE,EACA0E,EAAyB,CAEzB,IAAIC,EAAkC,CAAA,EAEhCC,EAAgBC,GAAoB7E,CAAU,EACpD2E,EAASA,EAAO,OAAOC,EAAc,MAAM,EAE3C,IAAME,EAAgBC,GAAoBH,EAAc,KAAK,EACvDI,EAAkBF,EAAc,MACtC,OAAAH,EAASA,EAAO,OAAOG,EAAc,MAAM,EAE3CH,EAASA,EAAO,OAAOM,GAAsBD,CAAe,CAAC,EAE7DL,EAASA,EAAO,OAAOO,GAAqBF,CAAe,CAAC,EAE5DL,EAASA,EAAO,OACdQ,GAAwBH,EAAiBN,CAAe,CAAC,EAG3DC,EAASA,EAAO,OAAOS,GAAwBJ,CAAe,CAAC,EAExDL,CACT,CAEA,SAASM,GACPjF,EAAuB,CAEvB,IAAI2E,EAAkC,CAAA,EAChCU,EAAqBC,EAAOtF,EAAa0D,GAC7CzC,GAASyC,EAAY/C,EAAO,CAAC,CAAC,EAGhC,OAAAgE,EAASA,EAAO,OAAOY,GAAqBF,CAAkB,CAAC,EAE/DV,EAASA,EAAO,OAAOa,GAAuBH,CAAkB,CAAC,EAEjEV,EAASA,EAAO,OAAOc,GAAqBJ,CAAkB,CAAC,EAE/DV,EAASA,EAAO,OAAOe,GAAsBL,CAAkB,CAAC,EAEhEV,EAASA,EAAO,OAAOgB,GAAsBN,CAAkB,CAAC,EAEzDV,CACT,CAOM,SAAUE,GACd7E,EAAuB,CAEvB,IAAM4F,EAA+BN,EAAOtF,EAAaU,GAChD,CAAC4B,EAAI5B,EAAUC,EAAO,CAC9B,EAEKgE,EAAS5D,EAAI6E,EAA+BlF,IACzC,CACL,QACE,iBACAA,EAAS,KACT,uCACF,KAAMmF,EAAyB,gBAC/B,WAAY,CAACnF,CAAQ,GAExB,EAEKoF,EAAQC,GAAW/F,EAAY4F,CAA4B,EACjE,MAAO,CAAE,OAAAjB,EAAQ,MAAAmB,CAAK,CACxB,CAEM,SAAUf,GACd/E,EAAuB,CAEvB,IAAMgG,EAA+BV,EAAOtF,EAAaU,GAAY,CACnE,IAAMuF,EAAUvF,EAASC,EAAO,EAChC,MACE,CAACM,GAASgF,CAAO,GACjB,CAAC3E,GAAW2E,CAAO,GACnB,CAAC3D,EAAI2D,EAAS,MAAM,GACpB,CAACjE,EAASiE,CAAO,CAErB,CAAC,EAEKtB,EAAS5D,EAAIiF,EAA+BtF,IACzC,CACL,QACE,iBACAA,EAAS,KACT,0JAEF,KAAMmF,EAAyB,gBAC/B,WAAY,CAACnF,CAAQ,GAExB,EAEKoF,EAAQC,GAAW/F,EAAYgG,CAA4B,EACjE,MAAO,CAAE,OAAArB,EAAQ,MAAAmB,CAAK,CACxB,CAEA,IAAMI,GAAe,WAEf,SAAUX,GACdvF,EAAuB,CAEvB,MAAMmG,UAAwBC,EAAiB,CAA/C,aAAA,qBACE,KAAA,MAAQ,EAKV,CAHE,eAAeC,EAAa,CAC1B,KAAK,MAAQ,EACf,EAGF,IAAMC,EAAehB,EAAOtF,EAAaU,GAAY,CACnD,IAAMuF,EAAUvF,EAAS,QAEzB,GAAI,CACF,IAAM6F,EAAYC,GAAaP,CAAiB,EAC1CQ,EAAmB,IAAIN,EAC7B,OAAAM,EAAiB,MAAMF,CAAS,EAEzBE,EAAiB,WACxB,CAGA,OAAOP,GAAa,KAAMD,EAAmB,MAAM,EAEvD,CAAC,EAgBD,OAdelF,EAAIuF,EAAe5F,IACzB,CACL,QACE;iBAEAA,EAAS,KACT;gFAGF,KAAMmF,EAAyB,iBAC/B,WAAY,CAACnF,CAAQ,GAExB,CAGH,CAEM,SAAUiF,GACd3F,EAAuB,CAEvB,IAAM0G,EAAqBpB,EAAOtF,EAAaU,GAC7BA,EAAS,QACV,KAAK,EAAE,CACvB,EAaD,OAXeK,EAAI2F,EAAqBhG,IAC/B,CACL,QACE,iBACAA,EAAS,KACT,qDACF,KAAMmF,EAAyB,oBAC/B,WAAY,CAACnF,CAAQ,GAExB,CAGH,CAEA,IAAMiG,GAAiB,iBAEjB,SAAUnB,GACdxF,EAAuB,CAEvB,MAAM4G,UAA0BR,EAAiB,CAAjD,aAAA,qBACE,KAAA,MAAQ,EAKV,CAHE,iBAAiBC,EAAa,CAC5B,KAAK,MAAQ,EACf,EAGF,IAAMC,EAAehB,EAAOtF,EAAaU,GAAY,CACnD,IAAMuF,EAAUvF,EAAS,QACzB,GAAI,CACF,IAAM6F,EAAYC,GAAaP,CAAO,EAChCY,EAAqB,IAAID,EAC/B,OAAAC,EAAmB,MAAMN,CAAS,EAE3BM,EAAmB,WAC1B,CAGA,OAAOF,GAAe,KAAKV,EAAQ,MAAM,EAE7C,CAAC,EAgBD,OAdelF,EAAIuF,EAAe5F,IACzB,CACL,QACE;iBAEAA,EAAS,KACT;wFAGF,KAAMmF,EAAyB,iBAC/B,WAAY,CAACnF,CAAQ,GAExB,CAGH,CAEM,SAAU+E,GACdzF,EAAuB,CAEvB,IAAM8G,EAAexB,EAAOtF,EAAaU,GAAY,CACnD,IAAMuF,EAAUvF,EAASC,EAAO,EAChC,OAAOsF,aAAmB,SAAWA,EAAQ,WAAaA,EAAQ,OACpE,CAAC,EAaD,OAXelF,EAAI+F,EAAepG,IACzB,CACL,QACE,iBACAA,EAAS,KACT,oEACF,KAAMmF,EAAyB,wBAC/B,WAAY,CAACnF,CAAQ,GAExB,CAGH,CAGM,SAAUgF,GACd1F,EAAuB,CAEvB,IAAM+G,EAAqB,CAAA,EACvBC,EAAoBjG,EAAIf,EAAaiH,GAChC9D,GACLnD,EACA,CAACyD,EAAQyD,KAELD,EAAU,QAAQ,SAAYC,EAAU,QAAmB,QAC3D,CAAC/F,GAAS4F,EAAOG,CAAS,GAC1BA,EAAU,UAAYtG,EAAM,KAI5BmG,EAAM,KAAKG,CAAS,EACpBzD,EAAO,KAAKyD,CAAS,GACdzD,GAIX,CAAA,CAAiB,CAEpB,EAEDuD,EAAoBG,GAAQH,CAAiB,EAE7C,IAAMI,EAAoB9B,EAAO0B,EAAoBK,GAC5CA,EAAiB,OAAS,CAClC,EAmBD,OAjBetG,EAAIqG,EAAoBE,GAAuB,CAC5D,IAAMC,EAAiBxG,EAAIuG,EAAiB5G,GACnCA,EAAS,IACjB,EAGD,MAAO,CACL,QACE,6BAHwB8G,GAAMF,CAAc,EAAG,+DAIOC,EAAe,KACnE,IAAI,OAER,KAAM1B,EAAyB,yBAC/B,WAAYyB,EAEhB,CAAC,CAGH,CAEM,SAAUpC,GACdlF,EAAuB,CAEvB,IAAMyH,EAAenC,EAAOtF,EAAa8B,GAAc,CACrD,GAAI,CAACQ,EAAIR,EAAO,OAAO,EACrB,MAAO,GAET,IAAM4F,EAAQ5F,EAAM,MAEpB,OAAO4F,IAAU9G,EAAM,SAAW8G,IAAU9G,EAAM,IAAM,CAACoB,EAAS0F,CAAK,CACzE,CAAC,EAaD,OAXe3G,EAAI0G,EAAe/G,IACzB,CACL,QACE,iBACAA,EAAS,KACT,gEACF,KAAMmF,EAAyB,yBAC/B,WAAY,CAACnF,CAAQ,GAExB,CAGH,CAEM,SAAUyE,GACdnF,EACA2H,EAAoB,CAEpB,IAAMC,EAAetC,EAAOtF,EAAa8B,GAErCA,EAAM,YAAc,QAAa,CAACX,GAASwG,EAAY7F,EAAM,SAAS,CAEzE,EAaD,OAXef,EAAI6G,EAAelF,IAIzB,CACL,QAHA,iBAAiBA,EAAQ,kEAAkEA,EAAQ,kCAInG,KAAMmD,EAAyB,yBAC/B,WAAY,CAACnD,CAAO,GAEvB,CAGH,CAEM,SAAU0C,GACdpF,EAAuB,CAEvB,IAAM2E,EAAkC,CAAA,EAElCkD,EAAc1E,GAClBnD,EACA,CAACyD,EAAQf,EAASY,IAAO,CACvB,IAAM2C,EAAUvD,EAAQ,QAExB,OAAIuD,IAAYrF,EAAM,KAMlBoB,EAASiE,CAAO,EAClBxC,EAAO,KAAK,CAAE,IAAKwC,EAAS,IAAA3C,EAAK,UAAWZ,CAAO,CAAE,EAC5CzB,GAASgF,CAAO,GAAK6B,GAAW7B,CAAO,GAChDxC,EAAO,KAAK,CAAE,IAAKwC,EAAQ,OAAQ,IAAA3C,EAAK,UAAWZ,CAAO,CAAE,GAEvDe,CACT,EACA,CAAA,CAA0D,EAG5D,OAAAO,EAAQhE,EAAY,CAAC0C,EAASqF,IAAW,CACvC/D,EAAQ6D,EAAa,CAAC,CAAE,IAAAG,EAAK,IAAA1E,EAAK,UAAA2E,CAAS,IAAM,CAC/C,GAAIF,EAAUzE,GAAO4E,GAAcF,EAAKtF,EAAQ,OAAO,EAAG,CACxD,IAAMtC,EACJ,YAAY6H,EAAU;4CACuBvF,EAAQ;8EAGvDiC,EAAO,KAAK,CACV,QAASvE,EACT,KAAMyF,EAAyB,oBAC/B,WAAY,CAACnD,EAASuF,CAAS,EAChC,EAEL,CAAC,CACH,CAAC,EAEMtD,CACT,CAEA,SAASuD,GAAcF,EAAa/B,EAAY,CAE9C,GAAIhF,GAASgF,CAAO,EAAG,CACrB,IAAMkC,EAAclC,EAAQ,KAAK+B,CAAG,EACpC,OAAOG,IAAgB,MAAQA,EAAY,QAAU,MAChD,IAAI7G,GAAW2E,CAAO,EAE3B,OAAOA,EAAQ+B,EAAK,EAAG,CAAA,EAAI,CAAA,CAAE,EACxB,GAAI1F,EAAI2D,EAAS,MAAM,EAE5B,OAAOA,EAAQ,KAAK+B,EAAK,EAAG,CAAA,EAAI,CAAA,CAAE,EAC7B,GAAI,OAAO/B,GAAY,SAC5B,OAAOA,IAAY+B,EAEnB,MAAM,MAAM,sBAAsB,EAEtC,CAEA,SAASF,GAAWM,EAAc,CAiBhC,OACEC,GAhBgB,CAChB,IACA,KACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,KAGiBC,GAASF,EAAO,OAAO,QAAQE,CAAI,IAAM,EAAE,IAAM,MAEtE,CAEM,SAAUjH,GAAgB4E,EAAe,CAC7C,IAAMsC,EAAQtC,EAAQ,WAAa,IAAM,GAGzC,OAAO,IAAI,OAAO,OAAOA,EAAQ,UAAWsC,CAAK,CACnD,CAEM,SAAUnH,GAAc6E,EAAe,CAC3C,IAAMsC,EAAQtC,EAAQ,WAAa,KAAO,IAG1C,OAAO,IAAI,OAAO,GAAGA,EAAQ,SAAUsC,CAAK,CAC9C,CAEM,SAAUC,GACdC,EACAC,EACAC,EAA6C,CAE7C,IAAMhE,EAAkC,CAAA,EAGxC,OAAKrC,EAAImG,EAAiBG,EAAY,GACpCjE,EAAO,KAAK,CACV,QACE,sDACAiE,GACA;EACF,KAAM/C,EAAyB,sCAChC,EAEEvD,EAAImG,EAAiBI,EAAK,GAC7BlE,EAAO,KAAK,CACV,QACE,sDACAkE,GACA;EACF,KAAMhD,EAAyB,wCAChC,EAIDvD,EAAImG,EAAiBI,EAAK,GAC1BvG,EAAImG,EAAiBG,EAAY,GACjC,CAACtG,EAAImG,EAAgB,MAAOA,EAAgB,WAAW,GAEvD9D,EAAO,KAAK,CACV,QACE,kDAAkDiE,QAAkBH,EAAgB;EAEtF,KAAM5C,EAAyB,mDAChC,EAGCvD,EAAImG,EAAiBI,EAAK,GAC5B7E,EAAQyE,EAAgB,MAAO,CAACK,EAAeC,IAAgB,CAC7D/E,EAAQ8E,EAAe,CAACpF,EAAasF,IAAW,CAC9C,GAAI/G,GAAYyB,CAAW,EACzBiB,EAAO,KAAK,CACV,QACE,sEACIoE,iBAA4BC;EAClC,KAAMnD,EAAyB,0CAChC,UACQvD,EAAIoB,EAAa,YAAY,EAAG,CACzC,IAAMuF,EAAY9G,GAAQuB,EAAY,UAAU,EAC5CA,EAAY,WACZ,CAACA,EAAY,UAAU,EAC3BM,EAAQiF,EAAYC,GAAiB,CAEjC,CAACjH,GAAYiH,CAAa,GAC1B,CAAC/H,GAAS2H,EAAeI,CAAa,GAEtCvE,EAAO,KAAK,CACV,QAAS,8DAA8DuE,EAAc,mBAAmBxF,EAAY,0BAA0BqF;EAC9I,KAAMlD,EAAyB,gDAChC,CAEL,CAAC,EAEL,CAAC,CACH,CAAC,EAGIlB,CACT,CAEM,SAAUwE,GACdV,EACAC,EACAC,EAA6C,CAE7C,IAAMS,EAAW,CAAA,EACbC,EAAkB,GAChBC,EAAgBnC,GAAQoC,GAAQC,GAAOf,EAAgB,KAAK,CAAC,CAAC,EAE9DgB,EAAqBhJ,GACzB6I,EACC5I,GAAaA,EAASC,EAAO,IAAMC,EAAM,EAAE,EAExC8I,EAAsBjH,GAAakG,CAAwB,EACjE,OAAID,GACF1E,EAAQyF,EAAqB/G,GAAW,CACtC,IAAMiH,EAAYhH,GAAsBD,EAASgH,CAAmB,EACpE,GAAIC,IAAc,GAAO,CAEvB,IAAMC,EAAoB,CACxB,QAFcC,GAA2BnH,EAASiH,CAAS,EAG3D,KAAMA,EAAU,MAChB,UAAWjH,GAEb0G,EAAS,KAAKQ,CAAiB,OAG3BtH,EAAII,EAAS,aAAa,EACxBA,EAAQ,cAAgB,KAC1B2G,EAAkB,IAIlBzG,GAAiB8G,EAAqBhH,EAAQ,OAAiB,IAE/D2G,EAAkB,GAI1B,CAAC,EAGCX,GAAc,CAACW,GACjBD,EAAS,KAAK,CACZ,QACE;;;;eAKF,KAAMvD,EAAyB,qBAChC,EAEIuD,CACT,CAEM,SAAUU,GAAiB/G,EAEhC,CACC,IAAMgH,EAAoB,CAAA,EACpBC,EAAYC,GAAKlH,CAAW,EAElC,OAAAiB,EAAQgG,EAAYE,GAAW,CAC7B,IAAMC,EAAiBpH,EAAYmH,CAAO,EAG1C,GAAI/H,GAAQgI,CAAc,EACxBJ,EAAaG,CAAO,EAAI,CAAA,MAExB,OAAM,MAAM,sBAAsB,CAEtC,CAAC,EAEMH,CACT,CAGM,SAAU9G,GAAgBgF,EAAoB,CAClD,IAAMhC,EAAUgC,EAAU,QAE1B,GAAIhH,GAASgF,CAAO,EAClB,MAAO,GACF,GAAI3E,GAAW2E,CAAO,EAE3B,MAAO,GACF,GAAI3D,EAAI2D,EAAS,MAAM,EAE5B,MAAO,GACF,GAAIjE,EAASiE,CAAO,EACzB,MAAO,GAEP,MAAM,MAAM,sBAAsB,CAEtC,CAEM,SAAU/C,GAAe+C,EAAY,CACzC,OAAIjE,EAASiE,CAAO,GAAKA,EAAQ,SAAW,EACnCA,EAAQ,WAAW,CAAC,EAEpB,EAEX,CAKO,IAAMmE,GAAwD,CAEnE,KAAM,SAAUC,EAAI,CAClB,IAAMC,EAAMD,EAAK,OACjB,QAASE,EAAI,KAAK,UAAWA,EAAID,EAAKC,IAAK,CACzC,IAAMC,EAAIH,EAAK,WAAWE,CAAC,EAC3B,GAAIC,IAAM,GACR,YAAK,UAAYD,EAAI,EACd,GACF,GAAIC,IAAM,GACf,OAAIH,EAAK,WAAWE,EAAI,CAAC,IAAM,GAC7B,KAAK,UAAYA,EAAI,EAErB,KAAK,UAAYA,EAAI,EAEhB,GAGX,MAAO,EACT,EAEA,UAAW,GAGb,SAAS5H,GACPD,EACAF,EAAiC,CASjC,GAAIF,EAAII,EAAS,aAAa,EAG5B,MAAO,GAGP,GAAIzB,GAASyB,EAAQ,OAAO,EAAG,CAC7B,GAAI,CAEFE,GAAiBJ,EAAyBE,EAAQ,OAAiB,QAC5D+H,EAAP,CAEA,MAAO,CACL,MAAO5E,EAAyB,oBAChC,OAAS4E,EAAY,SAGzB,MAAO,OACF,IAAIzI,EAASU,EAAQ,OAAO,EAEjC,MAAO,GACF,GAAIO,GAAgBP,CAAO,EAEhC,MAAO,CAAE,MAAOmD,EAAyB,iBAAiB,EAE1D,MAAM,MAAM,sBAAsB,EAGxC,CAEM,SAAUgE,GACdnH,EACAgI,EAKC,CAGD,GAAIA,EAAQ,QAAU7E,EAAyB,oBAC7C,MACE;0BAC4BnD,EAAQ;gBAClBgI,EAAQ;oGAGvB,GAAIA,EAAQ,QAAU7E,EAAyB,kBACpD,MACE;0BAC4BnD,EAAQ;kGAItC,MAAM,MAAM,sBAAsB,CAEtC,CAEA,SAASD,GAAakI,EAAiC,CASrD,OARkB5J,EAAI4J,EAAeC,GAC/B5I,EAAS4I,CAAW,EACfA,EAAY,WAAW,CAAC,EAExBA,CAEV,CAGH,CAEA,SAAS9G,GACP/C,EACA8J,EACAC,EAAQ,CAEJ/J,EAAI8J,CAAG,IAAM,OACf9J,EAAI8J,CAAG,EAAI,CAACC,CAAK,EAEjB/J,EAAI8J,CAAG,EAAE,KAAKC,CAAK,CAEvB,CAEO,IAAMC,GAAqB,IAiB9BC,GAAsC,CAAA,EACpC,SAAUnH,EAAyBF,EAAgB,CACvD,OAAOA,EAAWoH,GACdpH,EACAqH,GAA0BrH,CAAQ,CACxC,CAUA,SAASpD,IAA+B,CACtC,GAAIgE,GAAQyG,EAAyB,EAAG,CACtCA,GAA4B,IAAI,MAAM,KAAK,EAC3C,QAAST,EAAI,EAAGA,EAAI,MAAOA,IACzBS,GAA0BT,CAAC,EAAIA,EAAI,IAAM,IAAM,CAAC,EAAEA,EAAI,KAAOA,EAGnE,CGzoCA,OACE,UAAAU,GACA,SAAAC,GACA,WAAAC,GACA,YAAAC,GACA,WAAAC,GACA,WAAAC,GACA,eAAAC,GACA,QAAAC,GACA,QAAAC,GACA,OAAAC,GACA,QAAAC,GACA,UAAAC,GACA,UAAAC,OACK,YACP,OAAS,iBAAAC,GAAe,SAAAC,GAAO,oBAAAC,OAAwB,oBC5BvD,OACE,SAAAC,GACA,WAAAC,GACA,cAAAC,GACA,WAAAC,GACA,WAAAC,GACA,OAAAC,GACA,YAAAC,GACA,WAAAC,GACA,WAAAC,GACA,OAAAC,OACK,YAGD,SAAUC,EACdC,EACAC,EAAyB,CAEzB,IAAMC,EAAeF,EAAY,aACjC,OAAIE,IAAiBD,EAAe,aAC3B,GAGLA,EAAe,WAAa,IAC5BA,EAAe,mBAAoBC,CAAY,IAAM,EAG3D,CAIM,SAAUC,GACdC,EACAC,EAAkB,CAElB,OAAOD,EAAM,eAAiBC,EAAQ,YACxC,CAEO,IAAIC,GAAoB,EAClBC,GAAqD,CAAA,EAE5D,SAAUC,EAAkBC,EAAuB,CAEvD,IAAMC,EAAuBC,GAAiBF,CAAU,EAGxDG,GAAwBF,CAAoB,EAG5CG,GAAwBH,CAAoB,EAC5CI,GAA2BJ,CAAoB,EAE/CjB,GAAQiB,EAAuBL,GAAW,CACxCA,EAAQ,SAAWA,EAAQ,gBAAiB,OAAS,CACvD,CAAC,CACH,CAEM,SAAUM,GAAiBF,EAAuB,CACtD,IAAIM,EAAS1B,GAAMoB,CAAU,EAEzBO,EAAaP,EACbQ,EAAY,GAChB,KAAOA,GAAW,CAChBD,EAAa1B,GACXE,GAAQM,GAAIkB,EAAaE,GAAgBA,EAAY,UAAU,CAAC,CAAC,EAGnE,IAAMC,EAAgB5B,GAAWyB,EAAYD,CAAM,EAEnDA,EAASA,EAAO,OAAOI,CAAa,EAEhCtB,GAAQsB,CAAa,EACvBF,EAAY,GAEZD,EAAaG,EAGjB,OAAOJ,CACT,CAEM,SAAUH,GAAwBH,EAAuB,CAC7DhB,GAAQgB,EAAaS,GAAe,CAC7BE,GAAoBF,CAAW,IAClCX,GAAgBD,EAAiB,EAAIY,EAC/BA,EAAa,aAAeZ,MAKlCe,GAAsBH,CAAW,GACjC,CAACtB,GAAQsB,EAAY,UAAU,IAI/BA,EAAY,WAAa,CAACA,EAAY,UAAkC,GAGrEG,GAAsBH,CAAW,IACpCA,EAAY,WAAa,CAAA,GAGtBI,GAAgCJ,CAAW,IAC9CA,EAAY,gBAAkB,CAAA,GAG3BK,GAAmCL,CAAW,IACjDA,EAAY,mBAAqB,CAAA,EAErC,CAAC,CACH,CAEM,SAAUJ,GAA2BL,EAAuB,CAChEhB,GAAQgB,EAAaS,GAAe,CAElCA,EAAY,gBAAkB,CAAA,EAC9BzB,GAAQyB,EAAY,mBAAqB,CAACM,EAAKC,IAAO,CACpDP,EAAY,gBAAiB,KAC3BX,GAAgBkB,CAAwB,EAAE,YAAa,CAE3D,CAAC,CACH,CAAC,CACH,CAEM,SAAUZ,GAAwBJ,EAAuB,CAC7DhB,GAAQgB,EAAaS,GAAe,CAClCQ,GAA8B,CAAA,EAAIR,CAAW,CAC/C,CAAC,CACH,CAEM,SAAUQ,GACdC,EACAC,EAAmB,CAEnBnC,GAAQkC,EAAOE,GAAY,CACzBD,EAAS,mBAAoBC,EAAS,YAAa,EAAI,EACzD,CAAC,EAEDpC,GAAQmC,EAAS,WAAaE,GAAgB,CAC5C,IAAMC,EAAUJ,EAAK,OAAOC,CAAQ,EAE/BjC,GAASoC,EAASD,CAAY,GACjCJ,GAA8BK,EAASD,CAAY,CAEvD,CAAC,CACH,CAEM,SAAUV,GAAoBf,EAAkB,CACpD,OAAOX,GAAIW,EAAS,cAAc,CACpC,CAEM,SAAUgB,GAAsBhB,EAAkB,CACtD,OAAOX,GAAIW,EAAS,YAAY,CAClC,CAEM,SAAUiB,GAAgCjB,EAAkB,CAChE,OAAOX,GAAIW,EAAS,iBAAiB,CACvC,CAEM,SAAUkB,GACdlB,EAAkB,CAElB,OAAOX,GAAIW,EAAS,oBAAoB,CAC1C,CAEM,SAAU2B,GAAY3B,EAAkB,CAC5C,OAAOX,GAAIW,EAAS,cAAc,CACpC,CCpKO,IAAM4B,GAAwD,CACnE,iCAAiCC,EAAa,CAC5C,MAAO,uDAAuDA,EAAM,iCACtE,EAEA,iCACEC,EACAC,EACAC,EACAC,EACAC,EAAe,CAEf,MACE,2BAA2BJ,EAAS,OAClCC,CAAW,kBACKA,cAA6BC,eAEnD,GF8BF,IAAYG,GAAZ,SAAYA,EAAwB,CAClCA,EAAAA,EAAA,gBAAA,CAAA,EAAA,kBACAA,EAAAA,EAAA,gBAAA,CAAA,EAAA,kBACAA,EAAAA,EAAA,iBAAA,CAAA,EAAA,mBACAA,EAAAA,EAAA,wBAAA,CAAA,EAAA,0BACAA,EAAAA,EAAA,yBAAA,CAAA,EAAA,2BACAA,EAAAA,EAAA,yBAAA,CAAA,EAAA,2BACAA,EAAAA,EAAA,yBAAA,CAAA,EAAA,2BACAA,EAAAA,EAAA,sCAAA,CAAA,EAAA,wCACAA,EAAAA,EAAA,wCAAA,CAAA,EAAA,0CACAA,EAAAA,EAAA,mDAAA,CAAA,EAAA,qDACAA,EAAAA,EAAA,0CAAA,EAAA,EAAA,4CACAA,EAAAA,EAAA,iBAAA,EAAA,EAAA,mBACAA,EAAAA,EAAA,oBAAA,EAAA,EAAA,sBACAA,EAAAA,EAAA,qBAAA,EAAA,EAAA,uBACAA,EAAAA,EAAA,oBAAA,EAAA,EAAA,sBACAA,EAAAA,EAAA,oBAAA,EAAA,EAAA,sBACAA,EAAAA,EAAA,kBAAA,EAAA,EAAA,oBACAA,EAAAA,EAAA,gDAAA,EAAA,EAAA,iDACF,GAnBYA,IAAAA,EAAwB,CAAA,EAAA,EAyBpC,IAAMC,GAA+C,CACnD,8BAA+B,GAC/B,iBAAkB,OAClB,uBAAwB,YACxB,yBAA0B,CAAC;EAAM,IAAI,EACrC,oBAAqB,GACrB,SAAU,GACV,qBAAsBC,GACtB,cAAe,GACf,gBAAiB,GACjB,gBAAiB,IAGnB,OAAO,OAAOD,EAAoB,EAE5B,IAAOE,EAAP,KAAY,CA4BhB,YACYC,EACVC,EAAuBJ,GAAoB,CAE3C,GAHU,KAAA,gBAAAG,EAvBL,KAAA,sBAAiD,CAAA,EACjD,KAAA,uBAAkD,CAAA,EAE/C,KAAA,mBAAuD,CAAA,EACvD,KAAA,6BAEN,CAAA,EAEM,KAAA,MAAkB,CAAA,EAElB,KAAA,YAA+C,CAAA,EAGjD,KAAA,gBAA2B,GAC3B,KAAA,cAAyB,GACzB,KAAA,UAAqB,GACrB,KAAA,mBAA8C,CAAA,EAu0BtD,KAAA,WAAa,CAAIE,EAAmBC,IAAyB,CAG3D,GAAI,KAAK,gBAAkB,GAAM,CAC/B,KAAK,kBACL,IAAMC,EAAS,IAAI,MAAM,KAAK,gBAAkB,CAAC,EAAE,KAAK,GAAI,EACxD,KAAK,gBAAkB,KAAK,mBAC9B,QAAQ,IAAI,GAAGA,SAAcF,IAAY,EAE3C,GAAM,CAAE,KAAAG,EAAM,MAAAC,CAAK,EAAKC,GAAMJ,CAAS,EAEjCK,EAAcH,EAAO,GAAK,QAAQ,KAAO,QAAQ,IACvD,OAAI,KAAK,gBAAkB,KAAK,mBAC9BG,EAAY,GAAGJ,SAAcF,YAAoBG,KAAQ,EAE3D,KAAK,kBACEC,MAEP,QAAOH,EAAS,CAEpB,EAj1BM,OAAOF,GAAW,UACpB,MAAM,MACJ;8CACiD,EAKrD,KAAK,OAASQ,GAAO,CAAA,EAAIZ,GAAsBI,CAAM,EAErD,IAAMS,EAAe,KAAK,OAAO,cAC7BA,IAAiB,IACnB,KAAK,kBAAoB,IACzB,KAAK,cAAgB,IACZ,OAAOA,GAAiB,WACjC,KAAK,kBAAoBA,EACzB,KAAK,cAAgB,IAEvB,KAAK,gBAAkB,GAEvB,KAAK,WAAW,oBAAqB,IAAK,CACxC,IAAIC,EACAC,EAAoB,GACxB,KAAK,WAAW,wBAAyB,IAAK,CAC5C,GACE,KAAK,OAAO,yBACZf,GAAqB,uBAGrB,KAAK,OAAO,uBAAyBgB,WAGnC,KAAK,OAAO,2BACZhB,GAAqB,yBAErB,MAAM,MACJ;uGAC2G,EAKjH,GAAII,EAAO,UAAYA,EAAO,oBAC5B,MAAM,MACJ,oEAAoE,EAIxE,KAAK,gBAAkB,kBAAkB,KACvC,KAAK,OAAO,gBAAgB,EAE9B,KAAK,cAAgB,QAAQ,KAAK,KAAK,OAAO,gBAAgB,EAG1Da,GAAQd,CAAe,EACzBW,EAAmB,CACjB,MAAO,CAAE,YAAaI,GAAMf,CAAe,CAAC,EAC5C,YAAagB,KAIfJ,EAAoB,GACpBD,EAAmBI,GAAiCf,CAAe,EAEvE,CAAC,EAEG,KAAK,OAAO,kBAAoB,KAClC,KAAK,WAAW,uBAAwB,IAAK,CAC3C,KAAK,sBAAwB,KAAK,sBAAsB,OACtDiB,GACEN,EACA,KAAK,gBACL,KAAK,OAAO,wBAAwB,CACrC,CAEL,CAAC,EAED,KAAK,WAAW,8BAA+B,IAAK,CAClD,KAAK,uBAAyB,KAAK,uBAAuB,OACxDO,GACEP,EACA,KAAK,gBACL,KAAK,OAAO,wBAAwB,CACrC,CAEL,CAAC,GAIHA,EAAiB,MAAQA,EAAiB,MACtCA,EAAiB,MACjB,CAAA,EAIJQ,GAAQR,EAAiB,MAAO,CAACS,EAAeC,IAAgB,CAC9DV,EAAiB,MAAMU,CAAY,EAAIC,GACrCF,EACCG,GAAgBC,GAAYD,CAAW,CAAC,CAE7C,CAAC,EAED,IAAME,EAAeC,GAAKf,EAAiB,KAAK,EAyDhD,GAvDAQ,GACER,EAAiB,MACjB,CAACgB,EAAyBC,IAAe,CACvC,KAAK,WAAW,UAAUA,gBAA2B,IAAK,CAcxD,GAbA,KAAK,MAAM,KAAKA,CAAW,EAEvB,KAAK,OAAO,kBAAoB,IAClC,KAAK,WAAW,mBAAoB,IAAK,CACvC,KAAK,sBAAwB,KAAK,sBAAsB,OACtDC,GAAiBF,EAAYF,CAAY,CAAC,CAE9C,CAAC,EAMCK,GAAQ,KAAK,qBAAqB,EAAG,CACvCC,EAAkBJ,CAAU,EAE5B,IAAIK,EACJ,KAAK,WAAW,oBAAqB,IAAK,CACxCA,EAAoBC,GAAkBN,EAAY,CAChD,yBACE,KAAK,OAAO,yBACd,iBAAkB1B,EAAO,iBACzB,oBAAqBA,EAAO,oBAC5B,SAAUA,EAAO,SACjB,OAAQ,KAAK,WACd,CACH,CAAC,EAED,KAAK,mBAAmB2B,CAAW,EACjCI,EAAkB,mBAEpB,KAAK,6BAA6BJ,CAAW,EAC3CI,EAAkB,6BAEpB,KAAK,YAAcvB,GACjB,CAAA,EACA,KAAK,YACLuB,EAAkB,WAAW,EAG/B,KAAK,UAAYA,EAAkB,WAAa,KAAK,UAErD,KAAK,mBAAmBJ,CAAW,EACjCI,EAAkB,eAExB,CAAC,CACH,CAAC,EAGH,KAAK,YAAcrB,EAAiB,YAGlC,CAACmB,GAAQ,KAAK,qBAAqB,GACnC,CAAC,KAAK,OAAO,8BACb,CAIA,IAAMI,EAHiBC,GAAI,KAAK,sBAAwBC,GAC/CA,EAAM,OACd,EAC2C,KAC1C;CAA2B,EAE7B,MAAM,IAAI,MACR;EAA8CF,CAAoB,EAKtEf,GAAQ,KAAK,uBAAyBkB,GAAqB,CACzDC,GAAcD,EAAkB,OAAO,CACzC,CAAC,EAED,KAAK,WAAW,uCAAwC,IAAK,CAwB3D,GApBIE,IACF,KAAK,UAAiBC,GACtB,KAAK,MAAQ,KAAK,gBAElB,KAAK,gBAAkBC,GACvB,KAAK,MAAQ,KAAK,eAGhB7B,IACF,KAAK,YAAc6B,IAGjB,KAAK,kBAAoB,KAC3B,KAAK,iBAAmBD,IAGtB,KAAK,gBAAkB,KACzB,KAAK,iCAAmCC,IAGtC,QAAQ,KAAK,KAAK,OAAO,gBAAgB,EAC3C,KAAK,oBAAsB,KAAK,wBACvB,aAAa,KAAK,KAAK,OAAO,gBAAgB,EACvD,KAAK,oBAAsB,KAAK,6BACvB,cAAc,KAAK,KAAK,OAAO,gBAAgB,EACxD,KAAK,oBAAsB,KAAK,0BAEhC,OAAM,MACJ,8CAA8C,KAAK,OAAO,mBAAmB,EAI7E,KAAK,WACP,KAAK,SAAW,KAAK,kBACrB,KAAK,cAAgB,KAAK,0BAE1B,KAAK,SAAW,KAAK,0BACrB,KAAK,cAAgB,KAAK,sBAE9B,CAAC,EAED,KAAK,WAAW,+BAAgC,IAAK,CACnD,IAAMC,EAAmBC,GACvB,KAAK,mBACL,CAACC,EAAmBC,EAAgBC,KAC9BD,IAAmB,IACrBD,EAAkB,KAAKE,CAAQ,EAE1BF,GAET,CAAA,CAAc,EAGhB,GAAI3C,EAAO,qBAAuB,CAAC6B,GAAQY,CAAgB,EACzD,MAAM,MACJ,kBAAkBA,EAAiB,KACjC,IAAI;;yEAGuE,CAGnF,CAAC,EAED,KAAK,WAAW,yBAA0B,IAAK,CAC7CK,GAAsB,CACxB,CAAC,EAED,KAAK,WAAW,mBAAoB,IAAK,CACvCC,GAAiB,IAAI,CACvB,CAAC,CACH,CAAC,CACH,CAEO,SACLC,EACAC,EAAsB,KAAK,YAAW,CAEtC,GAAI,CAACpB,GAAQ,KAAK,qBAAqB,EAAG,CAIxC,IAAMI,EAHiBC,GAAI,KAAK,sBAAwBC,GAC/CA,EAAM,OACd,EAC2C,KAC1C;CAA2B,EAE7B,MAAM,IAAI,MACR;EACEF,CAAoB,EAI1B,OAAO,KAAK,iBAAiBe,EAAMC,CAAW,CAChD,CAMQ,iBAAiBD,EAAcC,EAAmB,CACxD,IAAIC,EACFC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACIC,EAAUlB,EACVmB,EAAYD,EAAQ,OACtBE,EAAS,EACTC,EAAqB,EAKnBC,GAAwB,KAAK,UAC/B,EACA,KAAK,MAAMtB,EAAK,OAAS,EAAE,EACzBuB,EAAgB,IAAI,MAAMD,EAAqB,EAC/CE,GAAyB,CAAA,EAC3BC,GAAO,KAAK,gBAAkB,EAAI,OAClCC,GAAS,KAAK,gBAAkB,EAAI,OAClCC,GAAcC,GAAiB,KAAK,WAAW,EAC/CC,GAAa,KAAK,gBAClBC,GAAwB,KAAK,OAAO,uBAEtCC,GAAyB,EACzBC,GAAuC,CAAA,EACvCC,GAEA,CAAA,EAEEC,GAAsB,CAAA,EAEtBC,GAA+B,CAAA,EACrC,OAAO,OAAOA,EAAU,EACxB,IAAIC,GAEJ,SAASC,IAAuB,CAC9B,OAAOL,EACT,CAEA,SAASM,GAA6BC,EAAgB,CACpD,IAAMC,EAAmBC,EAAyBF,CAAQ,EACpDG,GACJT,GAAiCO,CAAgB,EACnD,OAAIE,KAAqB,OAChBP,GAEAO,EAEX,CAEA,IAAMC,GAAYC,GAAoB,CAEpC,GACEV,GAAU,SAAW,GAGrBU,EAAS,UAAU,YAAc,OACjC,CAGA,IAAM5B,EACJ,KAAK,OAAO,qBAAqB,iCAC/B4B,CAAQ,EAGZpB,GAAO,KAAK,CACV,OAAQoB,EAAS,YACjB,KAAMA,EAAS,UACf,OAAQA,EAAS,YACjB,OAAQA,EAAS,MAAM,OACvB,QAAS5B,EACV,MACI,CACLkB,GAAU,IAAG,EACb,IAAMW,EAAUC,GAAKZ,EAAS,EAC9BF,GAAqB,KAAK,mBAAmBa,CAAO,EACpDZ,GACE,KAAK,6BAA6BY,CAAO,EAC3Cd,GAAyBC,GAAmB,OAC5C,IAAMe,GACJ,KAAK,mBAAmBF,CAAO,GAAK,KAAK,OAAO,WAAa,GAE3DZ,IAAoCc,GACtCX,GAAsBE,GAEtBF,GAAsBC,GAG5B,EAEA,SAASW,GAAuBH,EAAe,CAC7CX,GAAU,KAAKW,CAAO,EACtBZ,GACE,KAAK,6BAA6BY,CAAO,EAE3Cb,GAAqB,KAAK,mBAAmBa,CAAO,EACpDd,GAAyBC,GAAmB,OAE5CD,GAAyBC,GAAmB,OAC5C,IAAMe,EACJ,KAAK,mBAAmBF,CAAO,GAAK,KAAK,OAAO,WAAa,GAE3DZ,IAAoCc,EACtCX,GAAsBE,GAEtBF,GAAsBC,EAE1B,CAIAW,GAAU,KAAK,KAAM/C,CAAW,EAEhC,IAAIgD,EAEEC,GAAkB,KAAK,OAAO,gBAEpC,KAAO9B,EAASD,GAAW,CACzBZ,EAAe,KAEf,IAAM4C,EAAejC,EAAQ,WAAWE,CAAM,EACxCgC,EAA2BhB,GAAoBe,CAAY,EAC3DE,GAAuBD,EAAyB,OAEtD,IAAKlD,EAAI,EAAGA,EAAImD,GAAsBnD,IAAK,CACzC+C,EAAaG,EAAyBlD,CAAC,EACvC,IAAMoD,EAAcL,EAAW,QAC/BzC,EAAU,KAGV,IAAM+C,EAAiBN,EAAW,MA0BlC,GAzBIM,IAAmB,GACjBJ,IAAiBI,IAEnBhD,EAAe+C,GAERL,EAAW,WAAa,IACjChC,EAASqC,EAA4B,KACnCpC,EACAE,EACAG,EACAI,EAAM,EAEJV,IAAU,MACZV,EAAeU,EAAM,CAAC,EACjBA,EAAqC,UAAY,SACpDT,EAAWS,EAAqC,UAGlDV,EAAe,OAGjB,KAAK,gBAAgB+C,EAAuBlC,CAAM,EAClDb,EAAe,KAAK,MAAM+C,EAAuBtD,EAAMoB,CAAM,GAG3Db,IAAiB,KAAM,CAIzB,GADAD,EAAY2C,EAAW,UACnB3C,IAAc,OAAW,CAG3B,IAAMkD,GAAkBlD,EAAU,OAClC,IAAKF,EAAI,EAAGA,EAAIoD,GAAiBpD,IAAK,CACpC,IAAMqD,EAAkBzB,GAAmB1B,EAAUF,CAAC,CAAC,EACjDsD,GAAmBD,EAAgB,QA+BzC,GA9BAhD,EAAa,KAITgD,EAAgB,WAAa,IAC/BxC,EAASyC,GAAiC,KACxCxC,EACAE,EACAG,EACAI,EAAM,EAEJV,IAAU,MACZZ,EAAgBY,EAAM,CAAC,EAEpBA,EAAqC,UAAY,SAElDR,EAAcQ,EAAqC,UAGrDZ,EAAgB,OAGlB,KAAK,gBAAgBqD,GAA4BtC,CAAM,EACvDf,EAAgB,KAAK,MACnBqD,GACA1D,EACAoB,CAAM,GAINf,GAAiBA,EAAc,OAASE,EAAa,OAAQ,CAC/DA,EAAeF,EACfG,EAAUC,EACVwC,EAAaQ,EAGb,QAIN,OAKJ,GAAIlD,IAAiB,KAAM,CAoCzB,GAnCAG,EAAcH,EAAa,OAC3BI,EAAQsC,EAAW,MACftC,IAAU,SACZC,EAAUqC,EAAW,aAGrBpC,EAAW,KAAK,oBACdN,EACAa,EACAR,EACAqC,EAAW,UACXxB,GACAC,GACAhB,CAAW,EAGb,KAAK,cAAcG,EAAUL,CAAO,EAGhCG,IAAU,GACZU,EAAqB,KAAK,SACxBE,EACAF,EACAR,CAAQ,EAGVc,GAAOhB,CAAK,EAAE,KAAKE,CAAQ,GAG/Bb,EAAO,KAAK,UAAUA,EAAMU,CAAW,EACvCU,EAASA,EAASV,EAGlBgB,GAAS,KAAK,iBAAiBA,GAAShB,CAAW,EAE/CmB,KAAe,IAAQoB,EAAW,oBAAsB,GAAM,CAChE,IAAIU,EAAkB,EAClBC,EACAC,GACJ/B,GAAsB,UAAY,EAClC,GACE8B,EAAkB9B,GAAsB,KAAKvB,CAAY,EACrDqD,IAAoB,KACtBC,GAAkB/B,GAAsB,UAAY,EACpD6B,WAEKC,IAAoB,IAEzBD,IAAoB,IACtBlC,GAAOA,GAAQkC,EACfjC,GAAShB,EAAcmD,GACvB,KAAK,iCACHhD,EACAF,EACAkD,GACAF,EACAlC,GACAC,GACAhB,CAAW,GAKjB,KAAK,YAAYuC,EAAYN,GAAUK,GAAWnC,CAAS,MACtD,CAEL,IAAMiD,EAAmB1C,EACnB2C,EAAYtC,GACZuC,GAActC,GAChBuC,EAAmBf,KAAoB,GAE3C,KAAOe,IAAqB,IAAS7C,EAASD,GAI5C,IAFAnB,EAAO,KAAK,UAAUA,EAAM,CAAC,EAC7BoB,IACKjB,EAAI,EAAGA,EAAI4B,GAAwB5B,IAAK,CAC3C,IAAM8C,GAAajB,GAAmB7B,CAAC,EACjCmD,GAAcL,GAAW,QAGzBM,GAAiBN,GAAW,MAmBlC,GAlBIM,KAAmB,GACjBrC,EAAQ,WAAWE,CAAM,IAAMmC,KAEjCU,EAAmB,IAEZhB,GAAW,WAAa,GACjCgB,EACGX,GAA4B,KAC3BpC,EACAE,EACAG,EACAI,EAAM,IACF,MAER,KAAK,gBAAgB2B,GAAuBlC,CAAM,EAClD6C,EAAoBX,GAAuB,KAAKtD,CAAI,IAAM,MAGxDiE,IAAqB,GACvB,MAuBN,GAlBAnD,EAAYM,EAAS0C,EACrBpC,GAAS,KAAK,iBAAiBA,GAASZ,CAAS,EAEjDE,EAAM,KAAK,OAAO,qBAAqB,iCACrCE,EACA4C,EACAhD,EACAiD,EACAC,EAAW,EAEbxC,GAAO,KAAK,CACV,OAAQsC,EACR,KAAMC,EACN,OAAQC,GACR,OAAQlD,EACR,QAASE,EACV,EAEGkC,KAAoB,GACtB,OAON,OAAK,KAAK,YAER3B,EAAc,OAASF,GAGlB,CACL,OAAQE,EACR,OAAQI,GACR,OAAQH,GAEZ,CAEQ,YACNxE,EACA2F,EACAK,EACAnC,EAAgB,CAEhB,GAAI7D,EAAO,MAAQ,GAAM,CAGvB,IAAMkH,EAAWlH,EAAO,KACxB2F,EAAS9B,CAAQ,EACbqD,IAAa,QACflB,EAAU,KAAK,KAAMkB,CAAQ,OAEtBlH,EAAO,OAAS,QACzBgG,EAAU,KAAK,KAAMhG,EAAO,IAAI,CAEpC,CAEQ,UAAUgD,EAAcmE,EAAc,CAC5C,OAAOnE,EAAK,UAAUmE,CAAM,CAC9B,CAEQ,gBAAgBC,EAAgBC,EAAoB,CAC1DD,EAAO,UAAYC,CACrB,CAGQ,iCACNxD,EACAF,EACA2D,EACAX,EACAlC,EACAC,EACAhB,EAAmB,CAEnB,IAAI6D,EAAcC,EACd7D,IAAU,SAEZ4D,EAAeD,IAAc5D,EAAc,EAC3C8D,EAAmBD,EAAe,GAAK,EACjCZ,IAAoB,GAAKY,IAAiB,KAE9C1D,EAAS,QAAUY,EAAO+C,EAG1B3D,EAAS,UAAYa,EAAS,EAAI,CAAC8C,GAIzC,CAEQ,iBAAiBC,EAAmB/D,EAAmB,CAC7D,OAAO+D,EAAY/D,CACrB,CAMQ,sBACNgE,EACAC,EACAC,EACAC,EAAoB,CAEpB,MAAO,CACL,MAAAH,EACA,YAAAC,EACA,aAAAC,EACA,UAAAC,EAEJ,CAEQ,qBACNH,EACAC,EACAC,EACAC,EACAC,EACAC,EAAmB,CAEnB,MAAO,CACL,MAAAL,EACA,YAAAC,EACA,UAAAG,EACA,YAAAC,EACA,aAAAH,EACA,UAAAC,EAEJ,CAEQ,gBACNH,EACAC,EACAC,EACAC,EACAC,EACAC,EACArE,EAAmB,CAEnB,MAAO,CACL,MAAAgE,EACA,YAAAC,EACA,UAAWA,EAAcjE,EAAc,EACvC,UAAAoE,EACA,QAASA,EACT,YAAAC,EACA,UAAWA,EAAcrE,EAAc,EACvC,aAAAkE,EACA,UAAAC,EAEJ,CAUQ,kBACNG,EACAC,EACAC,EAAkB,CAElB,OAAAF,EAAY,KAAKE,CAAU,EACpBD,CACT,CAEQ,0BACND,EACAC,EACAC,EAAkB,CAElB,OAAAF,EAAYC,CAAK,EAAIC,EACrBD,IACOA,CACT,CAKQ,sBAAsBE,EAAe3E,EAAY,CAAS,CAE1D,wBAAwB2E,EAAe3E,EAAY,CACrDA,IAAY,OACd2E,EAAM,QAAU3E,EAEpB,CASQ,cACN4E,EACApF,EACAoB,EAAc,CAGd,OADcgE,EAAQ,KAAKpF,CAAI,IACjB,GACLA,EAAK,UAAUoB,EAAQgE,EAAQ,SAAS,EAE1C,IACT,CAEQ,cAAcA,EAAiBpF,EAAY,CACjD,IAAMqF,EAAcD,EAAQ,KAAKpF,CAAI,EACrC,OAAOqF,IAAgB,KAAOA,EAAY,CAAC,EAAI,IACjD,GAx1BcvI,EAAA,QACZ,6LAGYA,EAAA,GAAK,iBJzFf,SAAUwI,GAAWC,EAAkB,CAC3C,OAAIC,GAAcD,CAAO,EAChBA,EAAQ,MAERA,EAAQ,IAEnB,CAMM,SAAUE,GACdC,EAAc,CAEd,OAAOC,GAASD,EAAI,KAAK,GAAKA,EAAI,QAAU,EAC9C,CAEA,IAAME,GAAS,SACTC,GAAa,aACbC,GAAQ,QACRC,GAAQ,QACRC,GAAY,YACZC,GAAW,WACXC,GAAa,aACbC,GAAc,cACdC,GAAmB,mBAEnB,SAAUC,EAAYC,EAAoB,CAC9C,OAAOC,GAAoBD,CAAM,CACnC,CAEA,SAASC,GAAoBD,EAAoB,CAC/C,IAAME,EAAUF,EAAO,QAEjBG,EAA4B,CAAA,EAOlC,GANAA,EAAU,KAAOH,EAAO,KAEnBI,GAAYF,CAAO,IACtBC,EAAU,QAAUD,GAGlBG,GAAIL,EAAQV,EAAM,EACpB,KACE;8FAKJ,OAAIe,GAAIL,EAAQT,EAAU,IAExBY,EAAU,WAAkBH,EAAOT,EAAU,GAG/Ce,EAAkB,CAACH,CAAS,CAAC,EAEzBE,GAAIL,EAAQR,EAAK,IACnBW,EAAU,MAAQH,EAAOR,EAAK,GAG5Ba,GAAIL,EAAQP,EAAK,IACnBU,EAAU,MAAQH,EAAOP,EAAK,GAG5BY,GAAIL,EAAQL,EAAQ,IACtBQ,EAAU,SAAWH,EAAOL,EAAQ,GAGlCU,GAAIL,EAAQN,EAAS,IACvBS,EAAU,UAAYH,EAAON,EAAS,GAGpCW,GAAIL,EAAQJ,EAAU,IACxBO,EAAU,WAAaH,EAAOJ,EAAU,GAGtCS,GAAIL,EAAQH,EAAW,IACzBM,EAAU,YAAcH,EAAOH,EAAW,GAGxCQ,GAAIL,EAAQF,EAAgB,IAC9BK,EAAU,iBAAmBH,EAAOF,EAAgB,GAG/CK,CACT,CAEO,IAAMI,EAAMR,EAAY,CAAE,KAAM,MAAO,QAASS,EAAM,EAAE,CAAE,EACjEF,EAAkB,CAACC,CAAG,CAAC,EAEjB,SAAUE,GACdC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EAAiB,CAEjB,MAAO,CACL,MAAAN,EACA,YAAAC,EACA,UAAAC,EACA,UAAAC,EACA,QAAAC,EACA,YAAAC,EACA,UAAAC,EACA,aAAoBP,EAAS,aAC7B,UAAWA,EAEf,CAEM,SAAUQ,GAAaC,EAAeT,EAAkB,CAC5D,OAAOU,EAAuBD,EAAOT,CAAO,CAC9C,COvHA,OAAS,SAAAW,GAAO,OAAAC,GAAK,UAAAC,OAAc,YACnC,OAEE,wBAAAC,GACA,eAAAC,GACA,QAAAC,GACA,YAAAC,OACK,mBAWA,IAAMC,GAA0D,CACrE,0BAA0B,CAAE,SAAAC,EAAU,OAAAC,EAAQ,SAAAC,EAAU,SAAAC,CAAQ,EAAE,CAQhE,MAFY,aALKC,GAAcJ,CAAQ,EAEnC,OAAOK,GAAWL,CAAQ,QAC1B,qBAAqBA,EAAS,6BAEqBC,EAAO,YAGhE,EAEA,8BAA8B,CAAE,eAAAK,EAAgB,SAAAH,CAAQ,EAAE,CACxD,MAAO,6CAA+CG,EAAe,KACvE,EAEA,wBAAwB,CACtB,oBAAAC,EACA,OAAAN,EACA,SAAAC,EACA,sBAAAM,EACA,SAAAL,CAAQ,EACT,CACC,IAAMM,EAAY,cAGZC,EAAY;cADClB,GAAMS,CAAM,EAAG,MACgB,IAElD,GAAIO,EACF,OAAOC,EAAYD,EAAwBE,EACtC,CACL,IAAMC,EAAoBjB,GACxBa,EACA,CAACK,EAAQC,IAAiBD,EAAO,OAAOC,CAAY,EACpD,CAAA,CAAmB,EAEfC,EAA0BrB,GAC9BkB,EACCI,GACC,IAAItB,GAAIsB,EAAWC,GAAkBX,GAAWW,CAAa,CAAC,EAAE,KAC9D,IAAI,IACF,EAMFC,EAAwB;EAJCxB,GAC7BqB,EACA,CAACI,EAASC,IAAQ,KAAKA,EAAM,MAAMD,GAAS,EAEkD,KAC9F;CAAI,IAGN,OAAOT,EAAYQ,EAAwBP,EAE/C,EAEA,sBAAsB,CACpB,uBAAAU,EACA,OAAAnB,EACA,sBAAAO,EACA,SAAAL,CAAQ,EACT,CACC,IAAMM,EAAY,cAGZC,EAAY;cADClB,GAAMS,CAAM,EAAG,MACgB,IAElD,GAAIO,EACF,OAAOC,EAAYD,EAAwBE,EACtC,CAQL,IAAMO,EACJ;KAR8BxB,GAC9B2B,EACCL,GACC,IAAItB,GAAIsB,EAAWC,GAAkBX,GAAWW,CAAa,CAAC,EAAE,KAC9D,GAAG,IACD,EAIsB,KAAK,IAAI,KAEvC,OAAOP,EAAYQ,EAAwBP,EAE/C,GAGF,OAAO,OAAOX,EAA0B,EAEjC,IAAMsB,GACX,CACE,uBACEC,EACAC,EAA0B,CAS1B,MANE,gEACAA,EAAc,gBACd;2BAEAD,EAAa,KACb,IAEJ,GAGSE,EACX,CACE,yBACEF,EACAG,EAA2C,CAE3C,SAASC,EACPC,EAA+B,CAE/B,OAAIA,aAAgB7B,GACX6B,EAAK,aAAa,KAChBA,aAAgB/B,GAClB+B,EAAK,gBAEL,EAEX,CAEA,IAAMC,EAAeN,EAAa,KAC5BO,EAAgBrC,GAAMiC,CAAc,EACpCK,EAAQD,EAAc,IACtBE,EAAUpC,GAAqBkC,CAAa,EAC5CG,EAAgBN,EAA2BG,CAAa,EAExDI,EAAmBH,EAAQ,EAC7BI,EAAM,KAAKH,IAAUE,EAAmBH,EAAQ,QAClDE,EAAgB,oBAAoBA,MAAoB;4CAG5CP,EAAe,0CACmBG;;oBAKhD,OAAAM,EAAMA,EAAI,QAAQ,UAAW,GAAG,EAChCA,EAAMA,EAAI,QAAQ,SAAU;CAAI,EAEzBA,CACT,EAEA,4BAA4BC,EAAU,CAQpC,MANE;0EAC2EA,EAAK;;;uDAMpF,EAEA,qCAAqCC,EAKpC,CACC,IAAMC,EAAU5C,GAAI2C,EAAQ,WAAaE,GACvCjC,GAAWiC,CAAO,CAAC,EACnB,KAAK,IAAI,EACLC,EACJH,EAAQ,YAAY,MAAQ,EAAI,GAAKA,EAAQ,YAAY,IAU3D,MARE,4BAA4BA,EAAQ,iBAAiB,KACnD,IAAI;QAEGG,cAAuBH,EAAQ,aAAa;GACjDC;;qBAKR,EAEA,+BAA+BD,EAK9B,CACC,IAAMC,EAAU5C,GAAI2C,EAAQ,WAAaI,GACvCnC,GAAWmC,CAAO,CAAC,EACnB,KAAK,IAAI,EACLD,EACJH,EAAQ,YAAY,MAAQ,EAAI,GAAKA,EAAQ,YAAY,IACvDK,EACF,qCAAqCL,EAAQ,iBAAiB,KAC5D,IAAI,YACMG,cACAH,EAAQ,aAAa;GAC7BC;EAEN,OAAAI,EACEA,EACA;sBAEKA,CACT,EAEA,0BAA0BL,EAGzB,CACC,IAAIL,EAAUpC,GAAqByC,EAAQ,UAAU,EACrD,OAAIA,EAAQ,WAAW,MAAQ,IAC7BL,GAAWK,EAAQ,WAAW,KAI9B,mBAAmBL,mBAAyBK,EAAQ,aAAa;qCAIrE,EAIA,oBAAoBA,EAGnB,CAEC,MAAO,YACT,EAEA,2BAA2BA,EAI1B,CAMC,MAJE,iCAAiCA,EAAQ,eAAiB,YAChDA,EAAQ,YAAY,gBAAgBA,EAAQ,aAAa;uDAIvE,EAEA,8BAA8BA,EAG7B,CASC,MAPE;KACMA,EAAQ,YAAY,gBACxBA,EAAQ,aAAa;OAErBA,EAAQ,YAAY,WAAW,OAAS,iBAI9C,EAEA,wBAAwBA,EAGvB,CACC,IAAMjC,EAAWiC,EAAQ,aAAa,KAChCM,EAAYjD,GAChB2C,EAAQ,kBACPO,GAAaA,EAAS,IAAI,EAEvBC,EAAoB,GAAGzC,SAAgBuC,EAC1C,OAAO,CAACvC,CAAQ,CAAC,EACjB,KAAK,OAAO,IAQf,MANE;SACUA;;GACgEyC;;6DAK9E,EAIA,0BAA0BR,EAGzB,CAEC,MAAO,YACT,EAEA,4BAA4BA,EAG3B,CACC,IAAIjC,EACJ,OAAIiC,EAAQ,wBAAwBvC,GAClCM,EAAWiC,EAAQ,aAAa,KAEhCjC,EAAWiC,EAAQ,aAGN,iCAAiCjC,4CAAmDiC,EAAQ,eAG7G,GClUJ,OAAS,YAAAS,GAAU,WAAAC,OAAe,YCGlC,OAAS,WAAAC,GAAS,UAAAC,OAAc,YAChC,OAAS,eAAAC,OAAsC,mBAMzC,SAAUC,GACdC,EACAC,EAAoD,CAEpD,IAAMC,EAAc,IAAIC,GAAuBH,EAAWC,CAAc,EACxE,OAAAC,EAAY,YAAW,EAChBA,EAAY,MACrB,CAEM,IAAOC,GAAP,cAAsCL,EAAW,CAIrD,YACUM,EACAH,EAAoD,CAE5D,MAAK,EAHG,KAAA,cAAAG,EACA,KAAA,eAAAH,EALH,KAAA,OAAgD,CAAA,CAQvD,CAEO,aAAW,CAChBL,GAAQC,GAAO,KAAK,aAAa,EAAIQ,GAAQ,CAC3C,KAAK,aAAeA,EACpBA,EAAK,OAAO,IAAI,CAClB,CAAC,CACH,CAEO,iBAAiBC,EAAiB,CACvC,IAAMC,EAAM,KAAK,cAAcD,EAAK,eAAe,EAEnD,GAAKC,EAYHD,EAAK,eAAiBC,MAZd,CACR,IAAMC,EAAM,KAAK,eAAe,uBAC9B,KAAK,aACLF,CAAI,EAEN,KAAK,OAAO,KAAK,CACf,QAASE,EACT,KAAMC,EAA0B,uBAChC,SAAU,KAAK,aAAa,KAC5B,kBAAmBH,EAAK,gBACzB,EAIL,GCvDF,OACE,SAAAI,GACA,WAAAC,GACA,cAAAC,GACA,QAAAC,GACA,aAAAC,GACA,UAAAC,GACA,SAAAC,GACA,WAAAC,GACA,WAAAC,GACA,WAAAC,GACA,WAAAC,GACA,YAAAC,GACA,WAAAC,GACA,OAAAC,GACA,UAAAC,GACA,UAAAC,GACA,UAAAC,GACA,UAAAC,OACK,YAOP,OACE,eAAAC,GACA,eAAeC,GACf,eAAAC,GACA,wBAAAC,GACA,kBAAAC,GACA,eAAAC,GACA,UAAAC,GACA,cAAAC,GACA,uBAAAC,GACA,oCAAAC,GACA,2BAAAC,GACA,YAAAC,OACK,mBCvCP,OAAS,SAAAC,GAAO,WAAAC,GAAS,WAAAC,GAAS,OAAAC,GAAK,WAAAC,GAAS,OAAAC,GAAK,UAAAC,OAAc,YCAnE,OACE,SAAAC,GACA,QAAAC,EACA,aAAAC,GACA,SAASC,GACT,WAAAC,GACA,WAAAC,GACA,QAAAC,OACK,YAIP,OACE,eAAAC,GACA,eAAAC,GACA,eAAAC,GACA,UAAAC,GACA,cAAAC,EACA,uBAAAC,GACA,oCAAAC,GACA,2BAAAC,GACA,QAAAC,GACA,YAAAC,MACK,mBAUD,IAAgBC,GAAhB,cAAyDC,CAAU,CAUvE,YACYC,EACAC,EAAkB,CAE5B,MAAK,EAHK,KAAA,QAAAD,EACA,KAAA,KAAAC,EAXF,KAAA,iBAAgC,CAAA,EAIhC,KAAA,mBAAqB,GACrB,KAAA,yBAA2B,EAC3B,KAAA,MAAQ,GACR,KAAA,cAAgB,EAO1B,CAEA,cAAY,CAGV,GAFA,KAAK,MAAQ,GAET,KAAK,KAAK,UAAU,CAAC,IAAM,KAAK,QAAQ,KAC1C,MAAM,MAAM,qDAAqD,EAInE,YAAK,UAAYC,GAAM,KAAK,KAAK,SAAS,EAAE,QAAO,EACnD,KAAK,gBAAkBA,GAAM,KAAK,KAAK,eAAe,EAAE,QAAO,EAG/D,KAAK,UAAU,IAAG,EAClB,KAAK,gBAAgB,IAAG,EAExB,KAAK,mBAAkB,EACvB,KAAK,KAAK,KAAK,OAAO,EAEf,KAAK,gBACd,CAEA,KACEC,EACAC,EAA0B,CAAA,EAAE,CAGvB,KAAK,OACR,MAAM,KAAKD,EAAMC,CAAQ,CAE7B,CAEA,YACEC,EACAC,EACAF,EAAuB,CAGvB,GACEC,EAAQ,eAAe,OAAS,KAAK,oBACrCA,EAAQ,MAAQ,KAAK,yBACrB,CACA,IAAME,EAAWD,EAAS,OAAOF,CAAQ,EACzC,KAAK,mBAAkB,EACvB,KAAK,KAAKC,EAAQ,eAAqBE,CAAQ,EAEnD,CAEA,oBAAkB,CAEZC,GAAQ,KAAK,SAAS,GAGxB,KAAK,mBAAqB,GAC1B,KAAK,yBAA2B,EAChC,KAAK,cAAgB,KAErB,KAAK,mBAAqB,KAAK,UAAU,IAAG,EAC5C,KAAK,yBAA2B,KAAK,gBAAgB,IAAG,EAE5D,GAGWC,GAAP,cAAoCX,EAAgC,CAIxE,YACEE,EACUC,EAAuB,CAEjC,MAAMD,EAASC,CAAI,EAFT,KAAA,KAAAA,EALJ,KAAA,iBAAmB,GACnB,KAAA,uBAAyB,EAO/B,KAAK,iBAAmB,KAAK,KAAK,QAAQ,KAC1C,KAAK,uBAAyB,KAAK,KAAK,iBAC1C,CAEA,aACES,EACAJ,EACAF,EAAuB,CAEvB,GACE,KAAK,eACLM,EAAS,aAAa,OAAS,KAAK,kBACpCA,EAAS,MAAQ,KAAK,wBACtB,CAAC,KAAK,MACN,CACA,IAAMH,EAAWD,EAAS,OAAOF,CAAQ,EACnCO,EAAW,IAAItB,GAAY,CAAE,WAAYkB,CAAQ,CAAE,EACzD,KAAK,iBAAmBK,GAAMD,CAAQ,EACtC,KAAK,MAAQ,GAEjB,GAeWE,GAAP,cAAyDd,CAAU,CAOvE,YACYe,EACAC,EAAkB,CAE5B,MAAK,EAHK,KAAA,QAAAD,EACA,KAAA,WAAAC,EARF,KAAA,OAAgC,CACxC,MAAO,OACP,WAAY,OACZ,YAAa,OAQf,CAEA,cAAY,CACV,YAAK,KAAK,KAAK,OAAO,EACf,KAAK,MACd,GAGWC,GAAP,cAA2CH,EAAyC,CACxF,SACEI,EACAX,EACAF,EAAuB,CAEvB,GAAIa,EAAS,MAAQ,KAAK,WAAY,CACpC,IAAMC,EAAiBC,GAAOb,EAAS,OAAOF,CAAQ,CAAC,EACvD,KAAK,OAAO,YAAcc,IAAmB,OACzCA,aAA0BrB,IAC5B,KAAK,OAAO,MAAQqB,EAAe,aACnC,KAAK,OAAO,WAAaA,EAAe,UAG1C,MAAM,SAASD,EAAUX,EAAUF,CAAQ,CAE/C,GAGWgB,GAAP,cAA8CP,EAAyC,CAC3F,YACEQ,EACAf,EACAF,EAAuB,CAEvB,GAAIiB,EAAY,MAAQ,KAAK,WAAY,CACvC,IAAMC,EAAoBH,GAAOb,EAAS,OAAOF,CAAQ,CAAC,EAC1D,KAAK,OAAO,YAAckB,IAAsB,OAC5CA,aAA6BzB,IAC/B,KAAK,OAAO,MAAQyB,EAAkB,aACtC,KAAK,OAAO,WAAaA,EAAkB,UAG7C,MAAM,YAAYD,EAAaf,EAAUF,CAAQ,CAErD,GAGWmB,GAAP,cAAiDV,EAAyC,CAC9F,eACEW,EACAlB,EACAF,EAAuB,CAEvB,GAAIoB,EAAe,MAAQ,KAAK,WAAY,CAC1C,IAAMC,EAAuBN,GAAOb,EAAS,OAAOF,CAAQ,CAAC,EAC7D,KAAK,OAAO,YAAcqB,IAAyB,OAC/CA,aAAgC5B,IAClC,KAAK,OAAO,MAAQ4B,EAAqB,aACzC,KAAK,OAAO,WAAaA,EAAqB,UAGhD,MAAM,eAAeD,EAAgBlB,EAAUF,CAAQ,CAE3D,GAIWsB,GAAP,cAAoDb,EAAyC,CACjG,kBACEc,EACArB,EACAF,EAAuB,CAEvB,GAAIuB,EAAkB,MAAQ,KAAK,WAAY,CAC7C,IAAMC,EAAoCT,GACxCb,EAAS,OAAOF,CAAQ,CAAC,EAE3B,KAAK,OAAO,YAAcwB,IAAsC,OAC5DA,aAA6C/B,IAC/C,KAAK,OAAO,MAAQ+B,EAAkC,aACtD,KAAK,OAAO,WAAaA,EAAkC,UAG7D,MAAM,kBAAkBD,EAAmBrB,EAAUF,CAAQ,CAEjE,GAQI,SAAUyB,GACdC,EACAC,EACAC,EAAwB,CAAA,EAAE,CAG1BA,EAAW9B,GAAM8B,CAAQ,EACzB,IAAIC,EAAmC,CAAA,EACnC,EAAI,EAGR,SAASC,EAAkBC,EAAsB,CAC/C,OAAOA,EAAQ,OAAOC,EAAKN,EAAW,EAAI,CAAC,CAAC,CAC9C,CAGA,SAASO,EAAuBC,EAAyB,CACvD,IAAMC,EAAeV,GACnBK,EAAkBI,CAAU,EAC5BP,EACAC,CAAQ,EAEV,OAAOC,EAAO,OAAOM,CAAY,CACnC,CASA,KAAOP,EAAS,OAASD,GAAa,EAAID,EAAU,QAAQ,CAC1D,IAAM3B,EAAO2B,EAAU,CAAC,EAGxB,GAAI3B,aAAgBd,GAClB,OAAOgD,EAAuBlC,EAAK,UAAU,EACxC,GAAIA,aAAgBb,GACzB,OAAO+C,EAAuBlC,EAAK,UAAU,EACxC,GAAIA,aAAgBZ,GACzB0C,EAASI,EAAuBlC,EAAK,UAAU,UACtCA,aAAgBV,GAAqB,CAC9C,IAAM+C,EAASrC,EAAK,WAAW,OAAO,CACpC,IAAIX,EAAW,CACb,WAAYW,EAAK,WAClB,EACF,EACD,OAAOkC,EAAuBG,CAAM,UAC3BrC,aAAgBT,GAAkC,CAC3D,IAAM8C,EAAS,CACb,IAAInD,GAAY,CAAE,WAAYc,EAAK,UAAU,CAAE,EAC/C,IAAIX,EAAW,CACb,WAAY,CAAC,IAAIK,EAAS,CAAE,aAAcM,EAAK,SAAS,CAAE,CAAC,EAAE,OACtDA,EAAK,UAAU,EAEvB,GAEH,OAAOkC,EAAuBG,CAAM,UAC3BrC,aAAgBR,GAAyB,CAClD,IAAM6C,EAASrC,EAAK,WAAW,OAAO,CACpC,IAAIX,EAAW,CACb,WAAY,CAAC,IAAIK,EAAS,CAAE,aAAcM,EAAK,SAAS,CAAE,CAAC,EAAE,OACtDA,EAAK,UAAU,EAEvB,EACF,EACD8B,EAASI,EAAuBG,CAAM,UAC7BrC,aAAgBX,EAAY,CACrC,IAAMgD,EAASrC,EAAK,WAAW,OAAO,CACpC,IAAIX,EAAW,CACb,WAAYW,EAAK,WAClB,EACF,EACD8B,EAASI,EAAuBG,CAAM,MACjC,IAAIrC,aAAgBf,GACzB,OAAAqD,GAAQtC,EAAK,WAAauC,GAAW,CAI/BlC,GAAQkC,EAAQ,UAAU,IAAM,KAClCT,EAASI,EAAuBK,EAAQ,UAAU,EAEtD,CAAC,EACMT,EACF,GAAI9B,aAAgBN,EACzBmC,EAAS,KAAK7B,EAAK,YAAY,MAE/B,OAAM,MAAM,sBAAsB,EAGpC,IAEF,OAAA8B,EAAO,KAAK,CACV,YAAaD,EACb,UAAWI,EAAKN,EAAW,CAAC,EAC7B,EAEMG,CACT,CASM,SAAUU,GACdC,EACAC,EACAC,EACAC,EAAoB,CAEpB,IAAMC,EAAyB,qBAEzBC,EAAwB,CAACD,CAAiB,EAC1CE,EAAwB,mBAC1BC,EAAoB,GAElBC,EAAoBP,EAAY,OAChCQ,EAA2BD,EAAoBL,EAAe,EAE9Dd,EAAwC,CAAA,EAExCqB,EAAkC,CAAA,EAQxC,IAPAA,EAAc,KAAK,CACjB,IAAK,GACL,IAAKV,EACL,UAAW,CAAA,EACX,gBAAiB,CAAA,EAClB,EAEM,CAACpC,GAAQ8C,CAAa,GAAG,CAC9B,IAAMtB,EAAWsB,EAAc,IAAG,EAGlC,GAAItB,IAAakB,EAAkB,CAE/BC,GACAI,GAAKD,CAAa,EAAG,KAAOD,GAG5BC,EAAc,IAAG,EAEnB,SAGF,IAAME,EAAUxB,EAAS,IACnByB,EAAUzB,EAAS,IACnB0B,EAAgB1B,EAAS,UACzB2B,EAAsB3B,EAAS,gBAGrC,GAAIxB,GAAQgD,CAAO,EACjB,SAGF,IAAMrD,EAAOqD,EAAQ,CAAC,EAEtB,GAAIrD,IAAS6C,EAAmB,CAC9B,IAAMY,EAAW,CACf,IAAKH,EACL,IAAKrB,EAAKoB,CAAO,EACjB,UAAWK,GAAUH,CAAa,EAClC,gBAAiBG,GAAUF,CAAmB,GAEhDL,EAAc,KAAKM,CAAQ,UAClBzD,aAAgBN,EAEzB,GAAI4D,EAAUL,EAAoB,EAAG,CACnC,IAAMU,EAAUL,EAAU,EACpBM,EAAclB,EAAYiB,CAAO,EACvC,GAAIhB,EAAYiB,EAAa5D,EAAK,YAAY,EAAG,CAC/C,IAAMyD,EAAW,CACf,IAAKE,EACL,IAAK1B,EAAKoB,CAAO,EACjB,UAAWE,EACX,gBAAiBC,GAEnBL,EAAc,KAAKM,CAAQ,WAGpBH,IAAYL,EAAoB,EAEzCnB,EAAO,KAAK,CACV,cAAe9B,EAAK,aACpB,oBAAqBA,EAAK,IAC1B,UAAWuD,EACX,gBAAiBC,EAClB,EACDR,EAAoB,OAEpB,OAAM,MAAM,sBAAsB,UAE3BhD,aAAgBb,GAAa,CACtC,IAAM0E,EAAe9D,GAAMwD,CAAa,EACxCM,EAAa,KAAK7D,EAAK,eAAe,EAEtC,IAAM8D,EAAqB/D,GAAMyD,CAAmB,EACpDM,EAAmB,KAAK9D,EAAK,GAAG,EAEhC,IAAMyD,EAAW,CACf,IAAKH,EACL,IAAKtD,EAAK,WAAW,OAAO8C,EAAuBb,EAAKoB,CAAO,CAAC,EAChE,UAAWQ,EACX,gBAAiBC,GAEnBX,EAAc,KAAKM,CAAQ,UAClBzD,aAAgBZ,GAAQ,CAEjC,IAAM2E,EAAkB,CACtB,IAAKT,EACL,IAAKrB,EAAKoB,CAAO,EACjB,UAAWE,EACX,gBAAiBC,GAEnBL,EAAc,KAAKY,CAAe,EAElCZ,EAAc,KAAKJ,CAAgB,EAEnC,IAAMiB,EAAe,CACnB,IAAKV,EACL,IAAKtD,EAAK,WAAW,OAAOiC,EAAKoB,CAAO,CAAC,EACzC,UAAWE,EACX,gBAAiBC,GAEnBL,EAAc,KAAKa,CAAY,UACtBhE,aAAgBV,GAAqB,CAE9C,IAAM2E,EAAkB,IAAI5E,EAAW,CACrC,WAAYW,EAAK,WACjB,IAAKA,EAAK,IACX,EACKgC,EAAUhC,EAAK,WAAW,OAAO,CAACiE,CAAe,EAAGhC,EAAKoB,CAAO,CAAC,EACjEI,EAAW,CACf,IAAKH,EACL,IAAKtB,EACL,UAAWuB,EACX,gBAAiBC,GAEnBL,EAAc,KAAKM,CAAQ,UAClBzD,aAAgBT,GAAkC,CAE3D,IAAM2E,EAAgB,IAAIxE,EAAS,CACjC,aAAcM,EAAK,UACpB,EACKiE,EAAkB,IAAI5E,EAAW,CACrC,WAAY,CAAM6E,CAAa,EAAE,OAAOlE,EAAK,UAAU,EACvD,IAAKA,EAAK,IACX,EACKgC,EAAUhC,EAAK,WAAW,OAAO,CAACiE,CAAe,EAAGhC,EAAKoB,CAAO,CAAC,EACjEI,EAAW,CACf,IAAKH,EACL,IAAKtB,EACL,UAAWuB,EACX,gBAAiBC,GAEnBL,EAAc,KAAKM,CAAQ,UAClBzD,aAAgBR,GAAyB,CAElD,IAAMuE,EAAkB,CACtB,IAAKT,EACL,IAAKrB,EAAKoB,CAAO,EACjB,UAAWE,EACX,gBAAiBC,GAEnBL,EAAc,KAAKY,CAAe,EAElCZ,EAAc,KAAKJ,CAAgB,EAEnC,IAAMmB,EAAgB,IAAIxE,EAAS,CACjC,aAAcM,EAAK,UACpB,EACKmE,EAAgB,IAAI9E,EAAW,CACnC,WAAY,CAAM6E,CAAa,EAAE,OAAOlE,EAAK,UAAU,EACvD,IAAKA,EAAK,IACX,EACKgC,EAAUhC,EAAK,WAAW,OAAO,CAACmE,CAAa,EAAGlC,EAAKoB,CAAO,CAAC,EAC/DW,EAAe,CACnB,IAAKV,EACL,IAAKtB,EACL,UAAWuB,EACX,gBAAiBC,GAEnBL,EAAc,KAAKa,CAAY,UACtBhE,aAAgBX,EAAY,CAErC,IAAM0E,EAAkB,CACtB,IAAKT,EACL,IAAKrB,EAAKoB,CAAO,EACjB,UAAWE,EACX,gBAAiBC,GAEnBL,EAAc,KAAKY,CAAe,EAElCZ,EAAc,KAAKJ,CAAgB,EAGnC,IAAMoB,EAAgB,IAAI9E,EAAW,CACnC,WAAYW,EAAK,WACjB,IAAKA,EAAK,IACX,EACKgC,EAAUhC,EAAK,WAAW,OAAO,CAACmE,CAAa,EAAGlC,EAAKoB,CAAO,CAAC,EAC/DW,EAAe,CACnB,IAAKV,EACL,IAAKtB,EACL,UAAWuB,EACX,gBAAiBC,GAEnBL,EAAc,KAAKa,CAAY,UACtBhE,aAAgBf,GAEzB,QAASmF,EAAIpE,EAAK,WAAW,OAAS,EAAGoE,GAAK,EAAGA,IAAK,CACpD,IAAM7B,EAAevC,EAAK,WAAWoE,CAAC,EAChCC,EAAc,CAClB,IAAKf,EACL,IAAKf,EAAQ,WAAW,OAAON,EAAKoB,CAAO,CAAC,EAC5C,UAAWE,EACX,gBAAiBC,GAEnBL,EAAc,KAAKkB,CAAW,EAC9BlB,EAAc,KAAKJ,CAAgB,UAE5B/C,aAAgBd,GACzBiE,EAAc,KAAK,CACjB,IAAKG,EACL,IAAKtD,EAAK,WAAW,OAAOiC,EAAKoB,CAAO,CAAC,EACzC,UAAWE,EACX,gBAAiBC,EAClB,UACQxD,aAAgBP,GAEzB0D,EAAc,KACZmB,GAAmBtE,EAAMsD,EAASC,EAAeC,CAAmB,CAAC,MAGvE,OAAM,MAAM,sBAAsB,EAGtC,OAAO1B,CACT,CAEA,SAASwC,GACP3D,EACA2C,EACAC,EACAC,EAA6B,CAE7B,IAAMK,EAAe9D,GAAMwD,CAAa,EACxCM,EAAa,KAAKlD,EAAQ,IAAI,EAE9B,IAAM4D,EAAyBxE,GAAMyD,CAAmB,EAExD,OAAAe,EAAuB,KAAK,CAAC,EAEtB,CACL,IAAKjB,EACL,IAAK3C,EAAQ,WACb,UAAWkD,EACX,gBAAiBU,EAErB,CDtmBA,OACE,eAAAC,GACA,eAAeC,GACf,eAAAC,GACA,UAAAC,GACA,cAAAC,GACA,uBAAAC,GACA,oCAAAC,GACA,2BAAAC,OACK,mBAYP,IAAYC,GAAZ,SAAYA,EAAS,CACnBA,EAAAA,EAAA,OAAA,CAAA,EAAA,SACAA,EAAAA,EAAA,WAAA,CAAA,EAAA,aACAA,EAAAA,EAAA,qBAAA,CAAA,EAAA,uBACAA,EAAAA,EAAA,oCAAA,CAAA,EAAA,sCACAA,EAAAA,EAAA,0BAAA,CAAA,EAAA,4BACAA,EAAAA,EAAA,YAAA,CAAA,EAAA,aACF,GAPYA,IAAAA,EAAS,CAAA,EAAA,EASf,SAAUC,GACdC,EAA2C,CAG3C,GAAIA,aAAgBP,IAAUO,IAAS,SACrC,OAAOF,EAAU,OACZ,GAAIE,aAAgBN,IAAcM,IAAS,aAChD,OAAOF,EAAU,WACZ,GACLE,aAAgBL,IAChBK,IAAS,sBAET,OAAOF,EAAU,qBACZ,GACLE,aAAgBJ,IAChBI,IAAS,mCAET,OAAOF,EAAU,oCACZ,GACLE,aAAgBH,IAChBG,IAAS,0BAET,OAAOF,EAAU,0BACZ,GAAIE,aAAgBV,IAAeU,IAAS,cACjD,OAAOF,EAAU,YAEjB,MAAM,MAAM,sBAAsB,CAEtC,CAsBM,SAAUG,GACdC,EACAC,EACAC,EACAC,EACAC,EACAC,EAAuB,CAEvB,IAAMC,EAAiBC,GACrBP,EACAC,EACAC,CAAY,EAGRM,EAAeC,GAA0BH,CAAc,EACzDI,GACAC,EAEJ,OAAON,EACLC,EACAH,EACAK,EACAJ,CAAoB,CAExB,CAcM,SAAUQ,GACdZ,EACAC,EACAY,EACAT,EACAU,EACAC,EAIkB,CAElB,IAAMT,EAAiBU,GACrBhB,EACAC,EACAa,EACAD,CAAC,EAGGL,EAAeC,GAA0BH,CAAc,EACzDI,GACAC,EAEJ,OAAOI,EACLT,EAAe,CAAC,EAChBE,EACAJ,CAAoB,CAExB,CAIM,SAAUa,GACdC,EACAf,EACAK,EACAJ,EAA6B,CAE7B,IAAMe,EAAYD,EAAK,OACjBE,EAA0BC,GAAMH,EAAOI,GACpCD,GAAMC,EAAUC,GACdA,EAAS,SAAW,CAC5B,CACF,EAGD,GAAIpB,EAIF,OAAO,SAELqB,EAAqB,CAKrB,IAAMC,EAAwCC,GAC5CF,EACCF,GAAYA,EAAQ,IAAI,EAG3B,QAASK,EAAI,EAAGA,EAAIR,EAAWQ,IAAK,CAClC,IAAML,EAAUJ,EAAKS,CAAC,EAChBC,EAAiBN,EAAQ,OAEzBO,EAAgBJ,EAAWE,CAAC,EAClC,GAAI,EAAAE,IAAkB,QAAaA,EAAc,KAAK,IAAI,IAAM,IAIhEC,EAAU,QAASC,EAAI,EAAGA,EAAIH,EAAgBG,IAAK,CACjD,IAAMR,EAAWD,EAAQS,CAAC,EACpBC,EAAiBT,EAAS,OAChC,QAASU,EAAI,EAAGA,EAAID,EAAgBC,IAAK,CACvC,IAAMC,EAAY,KAAK,GAAGD,EAAI,CAAC,EAC/B,GAAIzB,EAAa0B,EAAWX,EAASU,CAAC,CAAC,IAAM,GAG3C,SAASH,EAKb,OAAOH,GAOb,EACK,GAAIP,GAA2B,CAAChB,EAAsB,CAG3D,IAAM+B,EAAkBT,GAAIR,EAAOI,GAC1Bc,GAAQd,CAAO,CACvB,EAEKe,EAAcC,GAClBH,EACA,CAACI,EAAQjB,EAASkB,KAChBC,GAAQnB,EAAUoB,GAAe,CAC1BC,GAAIJ,EAAQG,EAAY,YAAa,IACxCH,EAAOG,EAAY,YAAa,EAAIF,GAEtCC,GAAQC,EAAY,gBAAmBE,GAAqB,CACrDD,GAAIJ,EAAQK,CAAiB,IAChCL,EAAOK,CAAiB,EAAIJ,EAEhC,CAAC,CACH,CAAC,EACMD,GAET,CAAA,CAA4B,EAM9B,OAAO,UAAA,CACL,IAAML,EAAY,KAAK,GAAG,CAAC,EAC3B,OAAOG,EAAYH,EAAU,YAAY,CAC3C,MAOA,QAAO,UAAA,CACL,QAASP,EAAI,EAAGA,EAAIR,EAAWQ,IAAK,CAClC,IAAML,EAAUJ,EAAKS,CAAC,EAChBC,EAAiBN,EAAQ,OAC/BQ,EAAU,QAASC,EAAI,EAAGA,EAAIH,EAAgBG,IAAK,CACjD,IAAMR,EAAWD,EAAQS,CAAC,EACpBC,EAAiBT,EAAS,OAChC,QAASU,EAAI,EAAGA,EAAID,EAAgBC,IAAK,CACvC,IAAMC,EAAY,KAAK,GAAGD,EAAI,CAAC,EAC/B,GAAIzB,EAAa0B,EAAWX,EAASU,CAAC,CAAC,IAAM,GAG3C,SAASH,EAKb,OAAOH,GAOb,CAEJ,CAEM,SAAUkB,GACdC,EACAtC,EACAJ,EAA6B,CAE7B,IAAMgB,EAA0BC,GAAMyB,EAAMvB,GACnCA,EAAS,SAAW,CAC5B,EAEKwB,EAAaD,EAAI,OAIvB,GAAI1B,GAA2B,CAAChB,EAAsB,CACpD,IAAM4C,EAAoBZ,GAAQU,CAAG,EAErC,GACEE,EAAkB,SAAW,GAC7BC,GAAcD,EAAkB,CAAC,EAAG,eAAe,EACnD,CAEA,IAAME,EADoBF,EAAkB,CAAC,EACW,aAExD,OAAO,UAAA,CACL,OAAO,KAAK,GAAG,CAAC,EAAE,eAAiBE,CACrC,MACK,CACL,IAAMb,EAAcC,GAClBU,EACA,CAACT,EAAQG,EAAaF,KACpBD,EAAOG,EAAY,YAAa,EAAI,GACpCD,GAAQC,EAAY,gBAAmBE,GAAqB,CAC1DL,EAAOK,CAAiB,EAAI,EAC9B,CAAC,EACML,GAET,CAAA,CAAe,EAGjB,OAAO,UAAA,CACL,IAAML,EAAY,KAAK,GAAG,CAAC,EAC3B,OAAOG,EAAYH,EAAU,YAAY,IAAM,EACjD,OAGF,QAAO,UAAA,CACLJ,EAAU,QAASC,EAAI,EAAGA,EAAIgB,EAAYhB,IAAK,CAC7C,IAAMR,EAAWuB,EAAIf,CAAC,EAChBC,EAAiBT,EAAS,OAChC,QAASU,EAAI,EAAGA,EAAID,EAAgBC,IAAK,CACvC,IAAMC,EAAY,KAAK,GAAGD,EAAI,CAAC,EAC/B,GAAIzB,EAAa0B,EAAWX,EAASU,CAAC,CAAC,IAAM,GAG3C,SAASH,EAIb,MAAO,GAIT,MAAO,EACT,CAEJ,CAEA,IAAMqB,GAAN,cAAyCC,CAAU,CAGjD,YACUC,EACAC,EACAC,EAAyB,CAEjC,MAAK,EAJG,KAAA,QAAAF,EACA,KAAA,iBAAAC,EACA,KAAA,eAAAC,CAGV,CAEA,cAAY,CACV,YAAK,KAAK,KAAK,OAAO,EACf,KAAK,OACd,CAEQ,cACNC,EACAC,EACAC,EACAC,EAAuB,CAEvB,OACEH,EAAK,MAAQ,KAAK,kBAClB,KAAK,iBAAmBC,GAExB,KAAK,QAAUC,EAAS,OAAOC,CAAQ,EAChC,IAGF,EACT,CAEA,WACEC,EACAF,EACAC,EAAuB,CAElB,KAAK,cAAcC,EAAYC,EAAU,OAAQH,EAAUC,CAAQ,GACtE,MAAM,WAAWC,EAAYF,EAAUC,CAAQ,CAEnD,CAEA,eACEG,EACAJ,EACAC,EAAuB,CAGpB,KAAK,cACJG,EACAD,EAAU,qBACVH,EACAC,CAAQ,GAGV,MAAM,WAAWG,EAAgBJ,EAAUC,CAAQ,CAEvD,CAEA,kBACEI,EACAL,EACAC,EAAuB,CAGpB,KAAK,cACJI,EACAF,EAAU,oCACVH,EACAC,CAAQ,GAGV,MAAM,WAAWI,EAAmBL,EAAUC,CAAQ,CAE1D,CAEA,SACEK,EACAN,EACAC,EAAuB,CAGpB,KAAK,cAAcK,EAAUH,EAAU,WAAYH,EAAUC,CAAQ,GAEtE,MAAM,WAAWK,EAAUN,EAAUC,CAAQ,CAEjD,CAEA,YACEM,EACAP,EACAC,EAAuB,CAGpB,KAAK,cACJM,EACAJ,EAAU,0BACVH,EACAC,CAAQ,GAGV,MAAM,WAAWM,EAAaP,EAAUC,CAAQ,CAEpD,GAMIO,GAAN,cAA4CC,EAAW,CAGrD,YACUb,EACAC,EACAa,EAAe,CAEvB,MAAK,EAJG,KAAA,iBAAAd,EACA,KAAA,eAAAC,EACA,KAAA,UAAAa,EALH,KAAA,OAAwB,CAAA,CAQ/B,CAEQ,cACNZ,EACAa,EAA2B,CAGzBb,EAAK,MAAQ,KAAK,kBAClB,KAAK,iBAAmBa,IACvB,KAAK,YAAc,QAAab,IAAS,KAAK,aAE/C,KAAK,OAASA,EAAK,WAEvB,CAEO,YAAYA,EAAY,CAC7B,KAAK,cAAcA,EAAMK,EAAU,MAAM,CAC3C,CAEO,gBAAgBL,EAAgB,CACrC,KAAK,cAAcA,EAAMK,EAAU,UAAU,CAC/C,CAEO,yBAAyBL,EAAyB,CACvD,KAAK,cAAcA,EAAMK,EAAU,oBAAoB,CACzD,CAEO,sCACLL,EAAsC,CAEtC,KAAK,cAAcA,EAAMK,EAAU,mCAAmC,CACxE,CAEO,6BAA6BL,EAA6B,CAC/D,KAAK,cAAcA,EAAMK,EAAU,yBAAyB,CAC9D,CAEO,iBAAiBL,EAAiB,CACvC,KAAK,cAAcA,EAAMK,EAAU,WAAW,CAChD,GAGF,SAASS,GAAwBC,EAAY,CAC3C,IAAMhC,EAAS,IAAI,MAAMgC,CAAI,EAC7B,QAAStC,EAAI,EAAGA,EAAIsC,EAAMtC,IACxBM,EAAON,CAAC,EAAI,CAAA,EAEd,OAAOM,CACT,CAOA,SAASiC,GAAeC,EAAiB,CACvC,IAAIC,EAAO,CAAC,EAAE,EACd,QAASzC,EAAI,EAAGA,EAAIwC,EAAK,OAAQxC,IAAK,CACpC,IAAM0C,EAAUF,EAAKxC,CAAC,EAChB2C,EAAa,CAAA,EACnB,QAAS7C,EAAI,EAAGA,EAAI2C,EAAK,OAAQ3C,IAAK,CACpC,IAAM8C,EAAiBH,EAAK3C,CAAC,EAC7B6C,EAAW,KAAKC,EAAiB,IAAMF,EAAQ,YAAY,EAC3D,QAAShD,EAAI,EAAGA,EAAIgD,EAAQ,gBAAiB,OAAQhD,IAAK,CACxD,IAAMmD,EAAsB,IAAMH,EAAQ,gBAAiBhD,CAAC,EAC5DiD,EAAW,KAAKC,EAAiBC,CAAmB,GAGxDJ,EAAOE,EAET,OAAOF,CACT,CAKA,SAASK,GACPC,EACAC,EACAzC,EAAW,CAEX,QACM0C,EAAa,EACjBA,EAAaF,EAAkB,OAC/BE,IACA,CAEA,GAAIA,IAAe1C,EACjB,SAEF,IAAM2C,EAAyBH,EAAkBE,CAAU,EAC3D,QAASE,EAAY,EAAGA,EAAYH,EAAe,OAAQG,IAAa,CACtE,IAAMC,EAAYJ,EAAeG,CAAS,EAC1C,GAAID,EAAuBE,CAAS,IAAM,GACxC,MAAO,IAKb,MAAO,EACT,CAEM,SAAUC,GACdC,EACA1E,EAAS,CAET,IAAM2E,EAAc9D,GAAI6D,EAAWjE,GACjCmE,GAAkB,CAACnE,CAAO,EAAG,CAAC,CAAC,EAE3BoE,EAAcpB,GAAwBkB,EAAY,MAAM,EACxDG,EAAajE,GAAI8D,EAAcI,GAAgB,CACnD,IAAMC,EAAmC,CAAA,EACzC,OAAApD,GAAQmD,EAAeE,GAAQ,CAC7B,IAAMpB,EAAOF,GAAesB,EAAK,WAAW,EAC5CrD,GAAQiC,EAAOqB,GAAW,CACxBF,EAAKE,CAAO,EAAI,EAClB,CAAC,CACH,CAAC,EACMF,CACT,CAAC,EACGG,EAAUR,EAGd,QAASS,EAAa,EAAGA,GAAcpF,EAAGoF,IAAc,CACtD,IAAMC,EAAcF,EACpBA,EAAU1B,GAAwB4B,EAAY,MAAM,EAGpD,QAASC,EAAS,EAAGA,EAASD,EAAY,OAAQC,IAAU,CAC1D,IAAMC,EAA0BF,EAAYC,CAAM,EAElD,QACME,EAAc,EAClBA,EAAcD,EAAwB,OACtCC,IACA,CACA,IAAMC,EAAiBF,EAAwBC,CAAW,EAAE,YACtDE,EAAYH,EAAwBC,CAAW,EAAE,UACjDG,EAAahC,GAAe8B,CAAc,EAGhD,GAFiBvB,GAAmBY,EAAYa,EAAYL,CAAM,GAElDlD,GAAQsD,CAAS,GAAKD,EAAe,SAAWzF,EAAG,CACjE,IAAM4F,EAAgBf,EAAYS,CAAM,EAExC,GAAIO,GAAaD,EAAeH,CAAc,IAAM,GAAO,CACzDG,EAAc,KAAKH,CAAc,EAEjC,QAASvE,EAAI,EAAGA,EAAIyE,EAAW,OAAQzE,IAAK,CAC1C,IAAMgE,EAAUS,EAAWzE,CAAC,EAC5B4D,EAAWQ,CAAM,EAAEJ,CAAO,EAAI,SAK/B,CACH,IAAMY,EAA6BlB,GACjCc,EACAN,EAAa,EACbK,CAAc,EAEhBN,EAAQG,CAAM,EAAIH,EAAQG,CAAM,EAAE,OAAOQ,CAA0B,EAGnElE,GAAQkE,EAA6Bb,GAAQ,CAC3C,IAAMU,EAAahC,GAAesB,EAAK,WAAW,EAClDrD,GAAQ+D,EAAaI,GAAO,CAC1BjB,EAAWQ,CAAM,EAAES,CAAG,EAAI,EAC5B,CAAC,CACH,CAAC,KAMT,OAAOlB,CACT,CAEM,SAAUnF,GACdP,EACAC,EACAY,EACAgG,EAAoB,CAEpB,IAAMC,EAAU,IAAI5C,GAClBlE,EACA6D,EAAU,YACVgD,CAAM,EAER,OAAA5G,EAAY,OAAO6G,CAAO,EACnBxB,GAAkCwB,EAAQ,OAAQjG,CAAC,CAC5D,CAEM,SAAUG,GACdhB,EACAC,EACAa,EACAD,EAAS,CAET,IAAMkG,EAAmB,IAAI7C,GAC3BlE,EACAc,CAAQ,EAEVb,EAAY,OAAO8G,CAAgB,EACnC,IAAMC,EAAYD,EAAiB,OAO7BE,EALiB,IAAI9D,GACzBlD,EACAD,EACAc,CAAQ,EAEsB,aAAY,EAEtCoG,EAAa,IAAIC,GAAgB,CAAE,WAAYH,CAAS,CAAE,EAC1DI,EAAY,IAAID,GAAgB,CAAE,WAAYF,CAAQ,CAAE,EAE9D,OAAO3B,GAAkC,CAAC4B,EAAYE,CAAS,EAAGvG,CAAC,CACrE,CAEM,SAAU6F,GACdW,EACAC,EAAuB,CAEvBC,EAAkB,QAAStF,EAAI,EAAGA,EAAIoF,EAAY,OAAQpF,IAAK,CAC7D,IAAMuF,EAAYH,EAAYpF,CAAC,EAC/B,GAAIuF,EAAU,SAAWF,EAAW,OAGpC,SAASvF,EAAI,EAAGA,EAAIyF,EAAU,OAAQzF,IAAK,CACzC,IAAM0F,EAAYH,EAAWvF,CAAC,EACxB2F,EAAWF,EAAUzF,CAAC,EAK5B,IAFE0F,IAAcC,GACdA,EAAS,mBAAoBD,EAAU,YAAa,IAAM,UACrC,GACrB,SAASF,EAGb,MAAO,IAGT,MAAO,EACT,CAEM,SAAUI,GACdC,EACAC,EAAkB,CAElB,OACED,EAAO,OAASC,EAAM,QACtBxG,GAAMuG,EAAQ,CAACjD,EAASnC,IAAO,CAC7B,IAAMsF,EAAeD,EAAMrF,CAAG,EAC9B,OACEmC,IAAYmD,GACZA,EAAa,mBAAoBnD,EAAQ,YAAa,CAE1D,CAAC,CAEL,CAEM,SAAUlE,GACdH,EAAmC,CAEnC,OAAOe,GAAMf,EAAiByH,GAC5B1G,GAAM0G,EAAiBC,GACrB3G,GAAM2G,EAAaC,GAAUhF,GAAQgF,EAAM,eAAgB,CAAC,CAAC,CAC9D,CAEL,CDpqBM,SAAUC,GAAkBC,EAKjC,CACC,IAAMC,EAAmCD,EAAQ,kBAAkB,SAAS,CAC1E,MAAOA,EAAQ,MACf,WAAYA,EAAQ,WACpB,YAAaA,EAAQ,YACtB,EACD,OAAOE,GAAID,EAAmCE,GAAiB,OAAA,OAAA,CAC7D,KAAMC,EAA0B,2BAA2B,EACxDD,CAAY,CACf,CACJ,CAEM,SAAUE,GACdC,EACAC,EACAC,EACAC,EAAmB,CAEnB,IAAMC,EAA4CC,GAChDL,EACCM,GACCC,GAA6BD,EAAcJ,CAAc,CAAC,EAGxDM,EAA+BC,GACnCT,EACAC,EACAC,CAAc,EAGVQ,EAAoBL,GAAQL,EAAYW,GAC5CC,GAAoBD,EAAST,CAAc,CAAC,EAGxCW,EAAsBR,GAAQL,EAAYW,GAC9CG,GACEH,EACAX,EACAG,EACAD,CAAc,CACf,EAGH,OAAOE,EAAgB,OACrBI,EACAE,EACAG,CAAmB,CAEvB,CAEA,SAASN,GACPQ,EACAb,EAAqD,CAErD,IAAMc,EAAmB,IAAIC,GAC7BF,EAAa,OAAOC,CAAgB,EACpC,IAAME,EAAqBF,EAAiB,eAEtCG,EAAmBC,GACvBF,EACAG,EAA+B,EAG3BC,EAAkBC,GAAOJ,EAAmBK,GACzCA,EAAU,OAAS,CAC3B,EAwBD,OAtBe5B,GAAI6B,GAAOH,CAAU,EAAII,GAAuB,CAC7D,IAAMC,EAAiBC,GAAMF,CAAc,EACrCG,EAAM3B,EAAe,yBACzBa,EACAW,CAAc,EAEVI,EAAUC,GAAqBJ,CAAS,EACxCK,EAA6C,CACjD,QAASH,EACT,KAAM/B,EAA0B,sBAChC,SAAUiB,EAAa,KACvB,QAASe,EACT,WAAYH,EAAU,KAGlBM,EAAQC,GAA2BP,CAAS,EAClD,OAAIM,IACFD,EAAS,UAAYC,GAGhBD,CACT,CAAC,CAEH,CAEM,SAAUX,GACdc,EAA+B,CAE/B,MAAO,GAAGJ,GAAqBI,CAAI,OACjCA,EAAK,SACDD,GAA2BC,CAAI,GACvC,CAEA,SAASD,GAA2BC,EAA+B,CACjE,OAAIA,aAAgBC,GACXD,EAAK,aAAa,KAChBA,aAAgBE,GAClBF,EAAK,gBAEL,EAEX,CAEM,IAAOlB,GAAP,cAA6CqB,EAAW,CAA9D,aAAA,qBACS,KAAA,eAA8C,CAAA,CAmCvD,CAjCS,iBAAiBC,EAAoB,CAC1C,KAAK,eAAe,KAAKA,CAAO,CAClC,CAEO,YAAYC,EAAc,CAC/B,KAAK,eAAe,KAAKA,CAAM,CACjC,CAEO,6BAA6BC,EAAgC,CAClE,KAAK,eAAe,KAAKA,CAAO,CAClC,CAEO,yBAAyBC,EAA+B,CAC7D,KAAK,eAAe,KAAKA,CAAU,CACrC,CAEO,sCACLC,EAA+C,CAE/C,KAAK,eAAe,KAAKA,CAAa,CACxC,CAEO,gBAAgBC,EAAgB,CACrC,KAAK,eAAe,KAAKA,CAAI,CAC/B,CAEO,iBAAiBC,EAAe,CACrC,KAAK,eAAe,KAAKA,CAAE,CAC7B,CAEO,cAAcC,EAAkB,CACrC,KAAK,eAAe,KAAKA,CAAQ,CACnC,GAGI,SAAUhC,GACdiC,EACAC,EACAC,EACA/C,EAAqD,CAErD,IAAMgD,EAAS,CAAA,EAWf,GAVoBC,GAClBH,EACA,CAACI,EAAQzC,IACHA,EAAQ,OAASoC,EAAK,KACjBK,EAAS,EAEXA,EAET,CAAC,EAEe,EAAG,CACnB,IAAMC,EAASnD,EAAe,4BAA4B,CACxD,aAAc6C,EACd,YAAaE,EACd,EACDC,EAAO,KAAK,CACV,QAASG,EACT,KAAMvD,EAA0B,oBAChC,SAAUiD,EAAK,KAChB,EAGH,OAAOG,CACT,CAKM,SAAUI,GACdC,EACAC,EACAP,EAAiB,CAEjB,IAAMC,EAAS,CAAA,EACXG,EAEJ,OAAKI,GAASD,EAAmBD,CAAQ,IACvCF,EACE,kCAAkCE,8CAAqDN,wDAEzFC,EAAO,KAAK,CACV,QAASG,EACT,KAAMvD,EAA0B,sBAChC,SAAUyD,EACX,GAGIL,CACT,CAEM,SAAUQ,GACdC,EACAC,EACA1D,EACA2D,EAAe,CAAA,EAAE,CAEjB,IAAMX,EAAmC,CAAA,EACnCY,EAAmBC,GAAqBH,EAAS,UAAU,EACjE,GAAII,GAAQF,CAAgB,EAC1B,MAAO,CAAA,EACF,CACL,IAAMP,EAAWI,EAAQ,KACEF,GAASK,EAAkBH,CAAO,GAE3DT,EAAO,KAAK,CACV,QAAShD,EAAe,wBAAwB,CAC9C,aAAcyD,EACd,kBAAmBE,EACpB,EACD,KAAM/D,EAA0B,eAChC,SAAUyD,EACX,EAKH,IAAMU,EAAiBC,GAAWJ,EAAkBD,EAAK,OAAO,CAACF,CAAO,CAAC,CAAC,EACpEQ,EAAsB9D,GAAQ4D,EAAiBG,GAAe,CAClE,IAAMC,EAAUC,GAAMT,CAAI,EAC1B,OAAAQ,EAAQ,KAAKD,CAAW,EACjBV,GACLC,EACAS,EACAlE,EACAmE,CAAO,CAEX,CAAC,EAED,OAAOnB,EAAO,OAAOiB,CAAmB,EAE5C,CAEM,SAAUJ,GAAqBQ,EAAyB,CAC5D,IAAInB,EAAiB,CAAA,EACrB,GAAIY,GAAQO,CAAU,EACpB,OAAOnB,EAET,IAAMzB,EAAYC,GAAM2C,CAAU,EAGlC,GAAI5C,aAAqBU,GACvBe,EAAO,KAAKzB,EAAU,cAAc,UAEpCA,aAAqB6C,IACrB7C,aAAqB8C,IACrB9C,aAAqB+C,IACrB/C,aAAqBgD,IACrBhD,aAAqBiD,IACrBjD,aAAqBkD,GAErBzB,EAASA,EAAO,OACdW,GAAoCpC,EAAU,UAAU,CAAC,UAElDA,aAAqBmD,GAE9B1B,EAAS2B,GACPnF,GAAI+B,EAAU,WAAaqD,GACzBjB,GAAuCiB,EAAY,UAAU,CAAC,CAC/D,UAEM,EAAArD,aAAqBS,IAG9B,MAAM,MAAM,sBAAsB,EAGpC,IAAM6C,EAAkBC,GAAevD,CAAS,EAC1CwD,EAAUZ,EAAW,OAAS,EACpC,GAAIU,GAAmBE,EAAS,CAC9B,IAAMC,EAAOC,GAAKd,CAAU,EAC5B,OAAOnB,EAAO,OAAOW,GAAqBqB,CAAI,CAAC,MAE/C,QAAOhC,CAEX,CAEA,IAAMkC,GAAN,cAA0BhD,EAAW,CAArC,aAAA,qBACS,KAAA,aAA8B,CAAA,CAKvC,CAHS,iBAAiBiD,EAAiB,CACvC,KAAK,aAAa,KAAKA,CAAI,CAC7B,GAGI,SAAUC,GACdzE,EACAb,EAAqD,CAErD,IAAMuF,EAAc,IAAIH,GACxBvE,EAAa,OAAO0E,CAAW,EAC/B,IAAMC,EAAMD,EAAY,aAkCxB,OAhCepF,GACbqF,EACCC,GAAU,CACT,IAAMC,EAAaC,GAAUF,EAAO,UAAU,EAC9C,OAAOtF,GAAQuF,EAAY,CAACE,EAAiBC,IAAc,CACzD,IAAMC,EAAqBC,GACzB,CAACH,CAAe,EAChB,CAAA,EACAI,EACA,CAAC,EAEH,OAAIlC,GAAQgC,CAAkB,EACrB,CACL,CACE,QAAS9F,EAAe,2BAA2B,CACjD,aAAca,EACd,YAAa4E,EACb,eAAgBI,EACjB,EACD,KAAMjG,EAA0B,oBAChC,SAAUiB,EAAa,KACvB,WAAY4E,EAAO,IACnB,YAAaI,EAAa,IAIvB,CAAA,CAEX,CAAC,CACH,CAAC,CAIL,CAEM,SAAUI,GACdpF,EACAqF,EACAlG,EAAqD,CAErD,IAAMuF,EAAc,IAAIH,GACxBvE,EAAa,OAAO0E,CAAW,EAC/B,IAAIC,EAAMD,EAAY,aAItB,OAAAC,EAAMW,GAAOX,EAAMC,GAAWA,EAAO,oBAAsB,EAAI,EAEhDtF,GAAQqF,EAAMC,GAAuB,CAClD,IAAMW,EAAiBX,EAAO,IACxBY,EAAqBZ,EAAO,cAAgBS,EAC5CI,EAAeC,GACnBH,EACAvF,EACAwF,EACAZ,CAAM,EAEFe,EAAsBC,GAC1BH,EACAb,EACA5E,EACAb,CAAc,EAEV0G,EAA4BC,GAChCL,EACAb,EACA5E,EACAb,CAAc,EAGhB,OAAOwG,EAAoB,OAAOE,CAAyB,CAC7D,CAAC,CAGH,CAEM,IAAOE,GAAP,cAAmCxE,EAAW,CAApD,aAAA,qBACS,KAAA,eAEA,CAAA,CAmBT,CAjBS,6BAA6BG,EAAgC,CAClE,KAAK,eAAe,KAAKA,CAAO,CAClC,CAEO,yBAAyBC,EAA+B,CAC7D,KAAK,eAAe,KAAKA,CAAU,CACrC,CAEO,sCACLC,EAA+C,CAE/C,KAAK,eAAe,KAAKA,CAAa,CACxC,CAEO,gBAAgBC,EAAgB,CACrC,KAAK,eAAe,KAAKA,CAAI,CAC/B,GAGI,SAAUhC,GACdG,EACAb,EAAqD,CAErD,IAAMuF,EAAc,IAAIH,GACxBvE,EAAa,OAAO0E,CAAW,EAC/B,IAAMC,EAAMD,EAAY,aAoBxB,OAlBepF,GAAQqF,EAAMC,GACvBA,EAAO,WAAW,OAAS,IACtB,CACL,CACE,QAASzF,EAAe,8BAA8B,CACpD,aAAca,EACd,YAAa4E,EACd,EACD,KAAM7F,EAA0B,cAChC,SAAUiB,EAAa,KACvB,WAAY4E,EAAO,MAIhB,CAAA,CAEV,CAGH,CAEM,SAAUoB,GACdC,EACAC,EACA/G,EAAqD,CAErD,IAAMgD,EAAmC,CAAA,EACzC,OAAAgE,GAAQF,EAAgBG,GAAe,CACrC,IAAMnG,EAAmB,IAAI8F,GAC7BK,EAAY,OAAOnG,CAAgB,EACnC,IAAME,EAAqBF,EAAiB,eAC5CkG,GAAQhG,EAAqBkG,GAAY,CACvC,IAAMC,EAAWC,GAAYF,CAAQ,EAC/Bb,EAAqBa,EAAS,cAAgBH,EAC9CX,EAAiBc,EAAS,IAO1BG,EANQC,GACZlB,EACAa,EACAE,EACAd,CAAkB,EAEgB,CAAC,EACrC,GAAIvC,GAAQe,GAAQwC,CAAqB,CAAC,EAAG,CAC3C,IAAMlE,EAASnD,EAAe,0BAA0B,CACtD,aAAciH,EACd,WAAYC,EACb,EACDlE,EAAO,KAAK,CACV,QAASG,EACT,KAAMvD,EAA0B,uBAChC,SAAUqH,EAAY,KACvB,EAEL,CAAC,CACH,CAAC,EAEMjE,CACT,CAOA,SAASyD,GACPH,EACAiB,EACA1E,EACA7C,EAAqD,CAErD,IAAMwH,EAAmC,CAAA,EACnCC,EAAuBxE,GAC3BqD,EACA,CAACpD,EAAQwE,EAAS7B,KAEZ0B,EAAY,WAAW1B,CAAU,EAAE,oBAAsB,IAI7DmB,GAAQU,EAAUC,GAAY,CAC5B,IAAMC,EAAwB,CAAC/B,CAAU,EACzCmB,GAAQV,EAAc,CAACuB,EAAcC,IAAmB,CAEpDjC,IAAeiC,GACfC,GAAaF,EAAcF,CAAQ,GAEnCJ,EAAY,WAAWO,CAAe,EAAE,oBAAsB,IAE9DF,EAAsB,KAAKE,CAAe,CAE9C,CAAC,EAGCF,EAAsB,OAAS,GAC/B,CAACG,GAAaP,EAAqBG,CAAQ,IAE3CH,EAAoB,KAAKG,CAAQ,EACjCzE,EAAO,KAAK,CACV,KAAM0E,EACN,KAAMD,EACP,EAEL,CAAC,EACMzE,GAET,CAAA,CAA6C,EAyB/C,OAtBmBxD,GAAI+H,EAAuBO,GAAqB,CACjE,IAAMC,EAAcvI,GAClBsI,EAAkB,KACjBnC,GAAeA,EAAa,CAAC,EAUhC,MAAO,CACL,QARkB7F,EAAe,+BAA+B,CAChE,aAAc6C,EACd,YAAa0E,EACb,iBAAkBU,EAClB,WAAYD,EAAkB,KAC/B,EAIC,KAAMpI,EAA0B,eAChC,SAAUiD,EAAK,KACf,WAAY0E,EAAY,IACxB,aAAcS,EAAkB,KAEpC,CAAC,CAGH,CAEM,SAAUrB,GACdL,EACAiB,EACA1E,EACA7C,EAAqD,CAGrD,IAAMkI,EAAkBjF,GACtBqD,EACA,CAACpD,EAAQwE,EAASS,IAAO,CACvB,IAAMC,EAAkB1I,GAAIgI,EAAUC,IAC7B,CAAE,IAAKQ,EAAK,KAAMR,CAAQ,EAClC,EACD,OAAOzE,EAAO,OAAOkF,CAAe,CACtC,EACA,CAAA,CAA0C,EAuD5C,OApDeC,GACblI,GAAQ+H,EAAkBI,GAAkB,CAG1C,GAFwBf,EAAY,WAAWe,EAAe,GAAG,EAE7C,oBAAsB,GACxC,MAAO,CAAA,EAET,IAAMC,EAAYD,EAAe,IAC3BE,EAAaF,EAAe,KAE5BG,EAAmCC,GACvCR,EACCS,GAIGpB,EAAY,WAAWoB,EAAiB,GAAG,EAAE,oBAC3C,IACFA,EAAiB,IAAMJ,GAGvBK,GAAqBD,EAAiB,KAAMH,CAAU,CAEzD,EAyBH,OAtB6B9I,GAC3B+I,EACCI,GAAkE,CACjE,IAAMZ,EAAc,CAACY,EAAkB,IAAM,EAAGN,EAAY,CAAC,EACvDO,EAAavB,EAAY,MAAQ,EAAI,GAAKA,EAAY,IAQ5D,MAAO,CACL,QAPcvH,EAAe,qCAAqC,CAClE,aAAc6C,EACd,YAAa0E,EACb,iBAAkBU,EAClB,WAAYY,EAAkB,KAC/B,EAGC,KAAMjJ,EAA0B,sBAChC,SAAUiD,EAAK,KACf,WAAYiG,EACZ,aAAcb,EAElB,CAAC,CAIL,CAAC,CAAC,CAIN,CAEA,SAAS1H,GACPT,EACAC,EACAC,EAAqD,CAErD,IAAMgD,EAAmC,CAAA,EAEnC+F,EAAarJ,GAAIK,EAAaiJ,GAAcA,EAAU,IAAI,EAEhE,OAAAhC,GAAQlH,EAAY4D,GAAY,CAC9B,IAAMuF,EAAevF,EAAS,KAC9B,GAAIH,GAASwF,EAAYE,CAAY,EAAG,CACtC,IAAM9F,EAASnD,EAAe,4BAA4B0D,CAAQ,EAElEV,EAAO,KAAK,CACV,QAASG,EACT,KAAMvD,EAA0B,gCAChC,SAAUqJ,EACX,EAEL,CAAC,EAEMjG,CACT,CFprBM,SAAUkG,GACdC,EAA2B,CAE3B,IAAMC,EAA8CC,GAASF,EAAS,CACpE,eAAgBG,GACjB,EAEKC,EAA8C,CAAA,EACpD,OAAAC,GAAQL,EAAQ,MAAQM,GAAQ,CAC9BF,EAAcE,EAAK,IAAI,EAAIA,CAC7B,CAAC,EACMP,GAAkBK,EAAeH,EAAc,cAAc,CACtE,CAEM,SAAUM,GAAgBP,EAK/B,CACC,OAAAA,EAAUE,GAASF,EAAS,CAC1B,eAAgBQ,EACjB,EAEMD,GACLP,EAAQ,MACRA,EAAQ,WACRA,EAAQ,eACRA,EAAQ,WAAW,CAEvB,CKxCA,OACE,SAAAS,GACA,aAAAC,GACA,QAAAC,GACA,WAAAC,GACA,OAAAC,GACA,YAAAC,GACA,WAAAC,GACA,OAAAC,OACK,YClBP,OAAS,YAAAC,OAAgB,YAOzB,IAAMC,GAA6B,2BAC7BC,GAA0B,uBAC1BC,GAAuB,qBACvBC,GAAiC,6BAEjCC,GAA8B,CAClCJ,GACAC,GACAC,GACAC,IAGF,OAAO,OAAOC,EAA2B,EAGnC,SAAUC,GAAuBC,EAAY,CAEjD,OAAOP,GAASK,GAA6BE,EAAM,IAAI,CACzD,CAEA,IAAeC,GAAf,cACU,KAAK,CAMb,YACEC,EACOC,EAAa,CAEpB,MAAMD,CAAO,EAFN,KAAA,MAAAC,EAJT,KAAA,eAA2B,CAAA,EASzB,OAAO,eAAe,KAAM,WAAW,SAAS,EAG5C,MAAM,mBACR,MAAM,kBAAkB,KAAM,KAAK,WAAW,CAElD,GAGWC,GAAP,cAAwCH,EAAoB,CAChE,YACEC,EACAC,EACOE,EAAqB,CAE5B,MAAMH,EAASC,CAAK,EAFb,KAAA,cAAAE,EAGP,KAAK,KAAOX,EACd,GAGWY,GAAP,cAAoCL,EAAoB,CAC5D,YACEC,EACAC,EACOE,EAAqB,CAE5B,MAAMH,EAASC,CAAK,EAFb,KAAA,cAAAE,EAGP,KAAK,KAAOV,EACd,GAGWY,GAAP,cAA0CN,EAAoB,CAClE,YAAYC,EAAiBC,EAAa,CACxC,MAAMD,EAASC,CAAK,EACpB,KAAK,KAAON,EACd,GAGWW,GAAP,cAAkCP,EAAoB,CAC1D,YACEC,EACAC,EACOE,EAAqB,CAE5B,MAAMH,EAASC,CAAK,EAFb,KAAA,cAAAE,EAGP,KAAK,KAAOT,EACd,GDzDK,IAAMa,GAAsB,CAAA,EAQtBC,GAA6B,0BAE7BC,GAAP,cAAuC,KAAK,CAChD,YAAYC,EAAe,CACzB,MAAMA,CAAO,EACb,KAAK,KAAOF,EACd,GAMWG,GAAP,KAAkB,CAKtB,gBAAgBC,EAAqB,CACnC,KAAK,iBAAmB,CAAA,EACxB,KAAK,cAAgB,CAAA,EAErB,KAAK,gBAAkBC,GAAID,EAAQ,iBAAiB,EAC/CA,EAAO,gBACRE,EAAsB,gBAKtB,KAAK,kBACP,KAAK,4BAA8BC,GAEvC,CAEO,iBAAiBC,EAAkB,CACxC,IAAMC,EAAcC,GAClBF,EACA,GACA,IACA,IACA,IACA,IACA,IACA,GAAG,EAEL,OAAAC,EAAY,qBAAuB,GAC5BA,CACT,CAEO,iCAAiCD,EAAkB,CACxD,MAAO,EACT,CAEO,gCAAgCA,EAAkB,CACvD,MAAO,EACT,CAEA,wBAEEG,EACAC,EACAC,EACAC,EAA0B,CAG1B,IAAMC,EAAgB,KAAK,oBAAmB,EACxCC,EAAkB,KAAK,iBAAgB,EACvCC,EAA2B,CAAA,EAC7BC,EAAoB,GAElBC,EAAyB,KAAK,GAAG,CAAC,EACpCC,EAAY,KAAK,GAAG,CAAC,EAEnBC,EAAuB,IAAK,CAChC,IAAMC,EAAgB,KAAK,GAAG,CAAC,EAGzBC,EAAM,KAAK,qBAAqB,0BAA0B,CAC9D,SAAUT,EACV,OAAQK,EACR,SAAUG,EACV,SAAU,KAAK,oBAAmB,EACnC,EACKE,EAAQ,IAAIC,GAChBF,EACAJ,EACA,KAAK,GAAG,CAAC,CAAC,EAGZK,EAAM,eAAiBE,GAAUT,CAAc,EAC/C,KAAK,WAAWO,CAAK,CACvB,EAEA,KAAO,CAACN,GAEN,GAAI,KAAK,aAAaE,EAAWN,CAAe,EAAG,CACjDO,EAAoB,EACpB,eACSR,EAAc,KAAK,IAAI,EAAG,CAEnCQ,EAAoB,EAEpBV,EAAY,MAAM,KAAMC,CAAe,EACvC,YACS,KAAK,aAAaQ,EAAWL,CAAa,EACnDG,EAAoB,IAEpBE,EAAY,KAAK,WAAU,EAC3B,KAAK,kBAAkBA,EAAWH,CAAc,GAOpD,KAAK,iBAAiBD,CAAe,CACvC,CAEA,kCAEEW,EACAC,EACAC,EAA6B,CAsB7B,MAlBI,EAAAA,IAAa,IAKb,KAAK,aAAa,KAAK,GAAG,CAAC,EAAGF,CAAuB,GAMrD,KAAK,eAAc,GAQrB,KAAK,yBACHA,EACA,KAAK,4BAA4BA,EAAyBC,CAAU,CAAC,EAO3E,CAGA,4BAEEpB,EACAsB,EAAoB,CAEpB,IAAMC,EAAc,KAAK,sBAAsBvB,EAASsB,CAAY,EAEpE,OADgB,KAAK,0BAA0BC,CAAW,CAE5D,CAEA,kBAEEjB,EACAkB,EAAoB,CAEpB,GAAI,KAAK,mCAAmClB,EAAiBkB,CAAO,EAElE,OADoB,KAAK,iBAAiBlB,CAAe,EAI3D,GAAI,KAAK,kCAAkCA,CAAe,EAAG,CAC3D,IAAMmB,EAAU,KAAK,WAAU,EAC/B,YAAK,aAAY,EACVA,EAGT,MAAM,IAAIhC,GAAwB,eAAe,CACnD,CAEA,yBAEEiC,EACAF,EAAoB,CAEpB,OACE,KAAK,mCAAmCE,EAAeF,CAAO,GAC9D,KAAK,kCAAkCE,CAAa,CAExD,CAEA,mCAEEpB,EACAkB,EAAoB,CAOpB,GALI,CAAC,KAAK,iCAAiClB,CAAe,GAKtDqB,GAAQH,CAAO,EACjB,MAAO,GAGT,IAAMI,EAAgB,KAAK,GAAG,CAAC,EAM/B,OAJEC,GAAKL,EAAUM,GACN,KAAK,aAAaF,EAAeE,CAAsB,CAC/D,IAAM,MAGX,CAEA,kCAEExB,EAA0B,CAE1B,OAAK,KAAK,gCAAgCA,CAAe,EAIvB,KAAK,aACrC,KAAK,GAAG,CAAC,EACTA,CAAe,EALR,EAQX,CAEA,yBAEEyB,EAAuB,CAEvB,IAAMC,EAAY,KAAK,iBAAgB,EACjCC,EAAuB,KAAK,0BAA0BD,CAAS,EACrE,OAAOE,GAASD,EAAsBF,CAAY,CACpD,CAEA,qBAAmB,CACjB,IAAMI,EAA4B,KAAK,iBAAgB,EAEnDC,EAAY,KAAK,GAAG,CAAC,EACrBC,EAAI,EACR,OAAa,CACX,IAAMC,EAAaT,GAAKM,EAA4BI,GACjCC,GAAaJ,EAAWG,CAAa,CAEvD,EACD,GAAID,IAAe,OACjB,OAAOA,EAETF,EAAY,KAAK,GAAGC,CAAC,EACrBA,IAEJ,CAEA,kBAAgB,CAEd,GAAI,KAAK,WAAW,SAAW,EAC7B,OAAO9C,GAET,IAAMkD,EAAoB,KAAK,6BAA4B,EACrDC,EAAc,KAAK,mCAAkC,EACrDC,EAAoB,KAAK,iCAAgC,EAE/D,MAAO,CACL,SAAU,KAAK,wBAAwBF,CAAiB,EACxD,iBAAkBC,EAClB,OAAQ,KAAK,wBAAwBC,CAAiB,EAE1D,CAEA,yBAAuB,CACrB,IAAMC,EAAoB,KAAK,WACzBC,EAA0B,KAAK,sBAErC,OAAOC,GAAIF,EAAmB,CAACG,EAAUC,IACnCA,IAAQ,EACHzD,GAEF,CACL,SAAU,KAAK,wBAAwBwD,CAAQ,EAC/C,iBAAkBF,EAAwBG,CAAG,EAC7C,OAAQ,KAAK,wBAAwBJ,EAAkBI,EAAM,CAAC,CAAC,EAElE,CACH,CAEA,kBAAgB,CACd,IAAMC,EAAcH,GAAI,KAAK,wBAAuB,EAAKI,GAChD,KAAK,0BAA0BA,CAAO,CAC9C,EACD,OAAYC,GAAQF,CAAW,CACjC,CAEA,0BAEEjB,EAAqB,CAErB,GAAIA,IAAczC,GAChB,MAAO,CAAC6D,CAAG,EAGb,IAAMC,EACJrB,EAAU,SAAWA,EAAU,iBAAmBsB,GAAKtB,EAAU,OAEnE,OAAO,KAAK,cAAcqB,CAAU,CACtC,CAIA,kBAEEE,EACAC,EAAsB,CAEtB,OAAK,KAAK,aAAaD,EAAOH,CAAG,GAC/BI,EAAa,KAAKD,CAAK,EAElBC,CACT,CAEA,SAA8BxD,EAAkB,CAC9C,IAAMS,EAA2B,CAAA,EAC7BgB,EAAU,KAAK,GAAG,CAAC,EACvB,KAAO,KAAK,aAAaA,EAASzB,CAAO,IAAM,IAC7CyB,EAAU,KAAK,WAAU,EACzB,KAAK,kBAAkBA,EAAShB,CAAc,EAGhD,OAAOS,GAAUT,CAAc,CACjC,CAEA,4BAEEgD,EACAC,EACAC,EACAC,EACAC,EACAC,EACAzC,EAAkB,CAIpB,CAEA,sBAEErB,EACAsB,EAAoB,CAEpB,IAAMyC,EAA0B,KAAK,0BAAyB,EACxDC,EAAgCC,GAAM,KAAK,qBAAqB,EAQtE,MAPyB,CACvB,UAAWF,EACX,gBAAiBC,EACjB,QAAShE,EACT,kBAAmBsB,EAIvB,CACA,2BAAyB,CACvB,OAAOwB,GAAI,KAAK,WAAaoB,GAC3B,KAAK,wBAAwBA,CAAa,CAAC,CAE/C,GAGI,SAAUnE,GAEd0D,EACAC,EACAC,EACAC,EACAC,EACAC,EACAzC,EAAkB,CAElB,IAAM8C,EAAM,KAAK,4BAA4BP,EAAcC,CAAc,EACrEO,EAAoB,KAAK,iBAAiBD,CAAG,EACjD,GAAIC,IAAsB,OAAW,CACnC,IAAMC,EAAe,KAAK,oBAAmB,EACvCC,EAAc,KAAK,mBAAkB,EAAGD,CAAY,EAG1DD,EADE,IAAIN,EAAeQ,EAAaT,CAAc,EACrB,aAAY,EACvC,KAAK,iBAAiBM,CAAG,EAAIC,EAG/B,IAAIjD,EAA0BiD,EAAkB,MAC5ChD,EAAagD,EAAkB,WAC7BG,EAAcH,EAAkB,YAKpC,KAAK,WAAW,SAAW,GAC3BG,GACApD,IAA4B,SAE5BA,EAA0BiC,EAC1BhC,EAAa,GAKX,EAAAD,IAA4B,QAAaC,IAAe,SAK1D,KAAK,kCACHD,EACAC,EACAC,CAAQ,GAMV,KAAK,wBACHoC,EACAC,EACAC,EACAxC,CAAuB,CAG7B,CExdA,OAAS,WAAAqD,GAAS,OAAAC,OAAW,YCwBvB,SAAUC,GACdC,EACAC,EACAC,EAAkB,CAElB,OAAOA,EAAaD,EAAeD,CACrC,CAEA,IAAMG,GAAyB,GAAK,EDfpC,OAEE,eAAAC,GACA,wBAAAC,OAOK,mBEnBP,OAAS,WAAAC,GAAS,WAAAC,OAAe,YAkB3B,IAAOC,GAAP,KAA2B,CAG/B,YAAYC,EAAmC,OAC7C,KAAK,cACHC,EAAAD,GAAS,gBAAY,MAAAC,IAAA,OAAAA,EAAIC,EAAsB,YACnD,CAEA,SAASF,EAIR,CACC,IAAMG,EAAsB,KAAK,wBAAwBH,EAAQ,KAAK,EAEtE,GAAII,GAAQD,CAAmB,EAAG,CAChC,IAAME,EAAiB,KAAK,4BAA4BL,EAAQ,KAAK,EAC/DM,EAAsB,KAAK,yCAC/BN,EAAQ,MACR,KAAK,YAAY,EAEbO,EAAwB,KAAK,kCACjCP,EAAQ,MACR,KAAK,YAAY,EAQnB,MANkB,CAChB,GAAGG,EACH,GAAGE,EACH,GAAGC,EACH,GAAGC,GAIP,OAAOJ,CACT,CAEA,wBAAwBK,EAAa,CACnC,OAAOC,GAAQD,EAAQE,GACrBC,GACED,EACAA,EACAE,CAAoC,CACrC,CAEL,CAEA,4BAA4BJ,EAAa,CACvC,OAAOC,GAAQD,EAAQE,GACrBG,GACEH,EACAE,CAAoC,CACrC,CAEL,CAEA,yCACEJ,EACAM,EAAoB,CAEpB,OAAOL,GAAQD,EAAQE,GACrBK,GACEL,EACAI,EACAF,CAAoC,CACrC,CAEL,CAEA,kCACEJ,EACAM,EAAoB,CAEpB,OAAOE,GACLR,EACAM,EACAF,CAAoC,CAExC,CAEA,6BAA6BZ,EAM5B,CACC,OAAOiB,GACLjB,EAAQ,eACRA,EAAQ,KACRA,EAAQ,aACRA,EAAQ,cACRA,EAAQ,qBACRkB,EAA8B,CAElC,CAEA,0BAA0BlB,EAMzB,CACC,OAAOmB,GACLnB,EAAQ,eACRA,EAAQ,KACRA,EAAQ,aACRA,EAAQ,qBACRoB,GAAYpB,EAAQ,QAAQ,EAC5BqB,EAAuC,CAE3C,GFxGI,IAAOC,GAAP,KAAiB,CAMrB,eAAeC,EAAqB,CAClC,KAAK,qBAAuBC,GAAID,EAAQ,sBAAsB,EACzDA,EAAO,qBACRE,EAAsB,qBAE1B,KAAK,aAAeD,GAAID,EAAQ,cAAc,EACzCA,EAAO,aACRE,EAAsB,aAE1B,KAAK,kBAAoBD,GAAID,EAAQ,mBAAmB,EACnDA,EAAO,kBACR,IAAIG,GAAqB,CAAE,aAAc,KAAK,YAAY,CAAE,EAEhE,KAAK,oBAAsB,IAAI,GACjC,CAEA,6BAAkDC,EAAa,CAC7DC,GAAQD,EAAQE,GAAY,CAC1B,KAAK,WAAW,GAAGA,EAAS,sBAAuB,IAAK,CACtD,GAAM,CACJ,YAAAC,EACA,WAAAC,EACA,OAAAC,EACA,oBAAAC,EACA,iCAAAC,EACA,wBAAAC,CAAuB,EACrBC,GAAeP,CAAQ,EAE3BD,GAAQE,EAAcO,GAAY,CAChC,IAAMC,EAAUD,EAAS,MAAQ,EAAI,GAAKA,EAAS,IACnD,KAAK,WAAW,GAAGE,GAAqBF,CAAQ,IAAIC,IAAW,IAAK,CAClE,IAAME,EAAS,KAAK,kBAAkB,6BAA6B,CACjE,eAAgBH,EAAS,IACzB,KAAMR,EACN,aAAcQ,EAAS,cAAgB,KAAK,aAC5C,cAAeA,EAAS,cACxB,qBAAsB,KAAK,qBAC5B,EAEKI,EAAMC,GACV,KAAK,oBAAoBb,EAAS,IAAI,EACtC,IACAQ,EAAS,GAAG,EAEd,KAAK,eAAeI,EAAKD,CAAM,CACjC,CAAC,CACH,CAAC,EAEDZ,GAAQG,EAAaM,GAAY,CAC/B,KAAK,qBACHR,EACAQ,EAAS,IACT,IACA,aACAA,EAAS,aACTE,GAAqBF,CAAQ,CAAC,CAElC,CAAC,EAEDT,GAAQI,EAASK,GAAY,CAC3B,KAAK,qBACHR,EACAQ,EAAS,IACT,IACA,SACAA,EAAS,aACTE,GAAqBF,CAAQ,CAAC,CAElC,CAAC,EAEDT,GAAQK,EAAsBI,GAAY,CACxC,KAAK,qBACHR,EACAQ,EAAS,IACT,KACA,sBACAA,EAAS,aACTE,GAAqBF,CAAQ,CAAC,CAElC,CAAC,EAEDT,GAAQM,EAAmCG,GAAY,CACrD,KAAK,qBACHR,EACAQ,EAAS,IACT,KACA,mCACAA,EAAS,aACTE,GAAqBF,CAAQ,CAAC,CAElC,CAAC,EAEDT,GAAQO,EAA0BE,GAAY,CAC5C,KAAK,qBACHR,EACAQ,EAAS,IACT,KACA,0BACAA,EAAS,aACTE,GAAqBF,CAAQ,CAAC,CAElC,CAAC,CACH,CAAC,CACH,CAAC,CACH,CAEA,qBAEEM,EACAC,EACAC,EACAC,EACAC,EACAC,EAAqB,CAErB,KAAK,WACH,GAAGA,IAAgBJ,IAAmB,EAAI,GAAKA,IAC/C,IAAK,CACH,IAAMJ,EAAS,KAAK,kBAAkB,0BAA0B,CAC9D,eAAAI,EACA,KAAAD,EACA,aAAcI,GAAoB,KAAK,aACvC,qBAAsB,KAAK,qBAC3B,SAAAD,EACD,EACKL,EAAMC,GACV,KAAK,oBAAoBC,EAAK,IAAI,EAClCE,EACAD,CAAc,EAEhB,KAAK,eAAeH,EAAKD,CAAM,CACjC,CAAC,CAEL,CAGA,4BAEES,EACAC,EAAkB,CAElB,IAAMC,EAAyB,KAAK,6BAA4B,EAChE,OAAOT,GACLS,EACAF,EACAC,CAAU,CAEd,CAEA,mBAAwCT,EAAW,CACjD,OAAO,KAAK,oBAAoB,IAAIA,CAAG,CACzC,CAGA,eAAoCA,EAAaW,EAAe,CAC9D,KAAK,oBAAoB,IAAIX,EAAKW,CAAK,CACzC,GAGIC,GAAN,cAAyCC,EAAW,CAApD,aAAA,qBACS,KAAA,WAOH,CACF,OAAQ,CAAA,EACR,YAAa,CAAA,EACb,WAAY,CAAA,EACZ,wBAAyB,CAAA,EACzB,oBAAqB,CAAA,EACrB,iCAAkC,CAAA,EAuCtC,CApCE,OAAK,CACH,KAAK,WAAa,CAChB,OAAQ,CAAA,EACR,YAAa,CAAA,EACb,WAAY,CAAA,EACZ,wBAAyB,CAAA,EACzB,oBAAqB,CAAA,EACrB,iCAAkC,CAAA,EAEtC,CAEO,YAAYtB,EAAc,CAC/B,KAAK,WAAW,OAAO,KAAKA,CAAM,CACpC,CAEO,6BAA6BuB,EAAgC,CAClE,KAAK,WAAW,wBAAwB,KAAKA,CAAO,CACtD,CAEO,yBAAyBC,EAA+B,CAC7D,KAAK,WAAW,oBAAoB,KAAKA,CAAU,CACrD,CAEO,sCACLC,EAA+C,CAE/C,KAAK,WAAW,iCAAiC,KAAKA,CAAa,CACrE,CAEO,gBAAgBC,EAAgB,CACrC,KAAK,WAAW,WAAW,KAAKA,CAAI,CACtC,CAEO,iBAAiBC,EAAe,CACrC,KAAK,WAAW,YAAY,KAAKA,CAAE,CACrC,GAGIC,GAAmB,IAAIP,GACvB,SAAUjB,GAAeO,EAAU,CAQvCiB,GAAiB,MAAK,EACtBjB,EAAK,OAAOiB,EAAgB,EAC5B,IAAMC,EAAaD,GAAiB,WAEpC,OAAAA,GAAiB,MAAK,EACVC,CACd,CGnQM,SAAUC,GACdC,EACAC,EAAoE,CAGhE,MAAMD,EAAiB,WAAW,IAAM,IAI1CA,EAAiB,YAAcC,EAAgB,YAC/CD,EAAiB,UAAYC,EAAgB,WAMtCD,EAAiB,UAAaC,EAAgB,YACrDD,EAAiB,UAAYC,EAAgB,UAEjD,CASM,SAAUC,GACdF,EACAC,EAAgC,CAG5B,MAAMD,EAAiB,WAAW,IAAM,IAI1CA,EAAiB,YAAcC,EAAgB,YAC/CD,EAAiB,YAAcC,EAAgB,YAC/CD,EAAiB,UAAYC,EAAgB,UAC7CD,EAAiB,UAAYC,EAAgB,UAC7CD,EAAiB,UAAYC,EAAgB,UAC7CD,EAAiB,QAAUC,EAAgB,SAMpCD,EAAiB,UAAaC,EAAgB,YACrDD,EAAiB,UAAYC,EAAgB,UAC7CD,EAAiB,UAAYC,EAAgB,UAC7CD,EAAiB,QAAUC,EAAgB,QAE/C,CAEM,SAAUE,GACdC,EACAC,EACAC,EAAqB,CAEjBF,EAAK,SAASE,CAAa,IAAM,OACnCF,EAAK,SAASE,CAAa,EAAI,CAACD,CAAK,EAErCD,EAAK,SAASE,CAAa,EAAE,KAAKD,CAAK,CAE3C,CAEM,SAAUE,GACdH,EACAI,EACAC,EAAe,CAEXL,EAAK,SAASI,CAAQ,IAAM,OAC9BJ,EAAK,SAASI,CAAQ,EAAI,CAACC,CAAU,EAErCL,EAAK,SAASI,CAAQ,EAAE,KAAKC,CAAU,CAE3C,CChFA,OAAS,OAAAC,GAAK,eAAAC,GAAa,QAAAC,GAAM,QAAAC,MAAY,YCN7C,OACE,WAAAC,GACA,UAAAC,GACA,WAAAC,GACA,WAAAC,GACA,WAAAC,GACA,cAAAC,GACA,eAAAC,GACA,QAAAC,GACA,OAAAC,OACK,YCVP,IAAMC,GAAO,OAEP,SAAUC,GAAeC,EAASC,EAAiB,CACvD,OAAO,eAAeD,EAAKF,GAAM,CAC/B,WAAY,GACZ,aAAc,GACd,SAAU,GACV,MAAOG,EACR,CACH,CDKM,SAAUC,GAAiBC,EAAUC,EAAS,CAClD,IAAMC,EAAgBC,GAAKH,CAAG,EACxBI,EAAsBF,EAAc,OAC1C,QAAS,EAAI,EAAG,EAAIE,EAAqB,IAAK,CAC5C,IAAMC,EAAgBH,EAAc,CAAC,EAC/BI,EAAiBN,EAAIK,CAAa,EAClCE,EAAuBD,EAAe,OAC5C,QAASE,EAAI,EAAGA,EAAID,EAAsBC,IAAK,CAC7C,IAAMC,EAAiBH,EAAeE,CAAC,EAEnCC,EAAU,eAAiB,QAC7B,KAAKA,EAAU,IAAI,EAAEA,EAAU,SAAUR,CAAK,GAKtD,CAEM,SAAUS,GACdC,EACAC,EAAmB,CAInB,IAAMC,EAA0B,UAAA,CAAa,EAK7CC,GAAeD,EAAoBF,EAAc,eAAe,EAEhE,IAAMI,EAAgB,CACpB,MAAO,SAAUC,EAA8Bf,EAAU,CASvD,GAPIgB,GAAQD,CAAO,IAGjBA,EAAUA,EAAQ,CAAC,GAIjB,CAAAE,GAAYF,CAAO,EAIvB,OAAO,KAAKA,EAAQ,IAAI,EAAEA,EAAQ,SAAUf,CAAK,CACnD,EAEA,gBAAiB,UAAA,CACf,IAAMkB,EAA2BC,GAAgB,KAAMR,CAAS,EAChE,GAAI,CAACS,GAAQF,CAAwB,EAAG,CACtC,IAAMG,EAAgBC,GACpBJ,EACCK,GAAiBA,EAAa,GAAG,EAEpC,MAAM,MACJ,mCAAmC,KAAK,YAAY;GAC/CF,EAAc,KAAK;;CAAM,EAAE,QAAQ,MAAO;EAAM,GAAG,EAG9D,GAGF,OAAAT,EAAmB,UAAYE,EAC/BF,EAAmB,UAAU,YAAcA,EAE3CA,EAAmB,YAAcD,EAE1BC,CACT,CAEM,SAAUY,GACdd,EACAC,EACAc,EAAyB,CAIzB,IAAMb,EAA0B,UAAA,CAAa,EAK7CC,GAAeD,EAAoBF,EAAc,2BAA2B,EAE5E,IAAMgB,EAAoB,OAAO,OAAOD,EAAgB,SAAS,EACjE,OAAAE,GAAQhB,EAAYiB,GAAY,CAC9BF,EAAkBE,CAAQ,EAAI9B,EAChC,CAAC,EAEDc,EAAmB,UAAYc,EAC/Bd,EAAmB,UAAU,YAAcA,EAEpCA,CACT,CAEA,IAAYiB,IAAZ,SAAYA,EAAyB,CACnCA,EAAAA,EAAA,iBAAA,CAAA,EAAA,mBACAA,EAAAA,EAAA,eAAA,CAAA,EAAA,gBACF,GAHYA,KAAAA,GAAyB,CAAA,EAAA,EAW/B,SAAUV,GACdW,EACAnB,EAAmB,CAInB,OAFsBoB,GAA0BD,EAAiBnB,CAAS,CAG5E,CAEM,SAAUoB,GACdD,EACAnB,EAAmB,CAEnB,IAAMqB,EAAmBC,GAAOtB,EAAYuB,GACnCC,GAAYL,EAAwBI,CAAY,CAAC,IAAM,EAC/D,EAEKE,EAAoCd,GACxCU,EACCE,IACQ,CACL,IAAK,4BAA4BA,SAC/BJ,EAAgB,YAAY,oBAE9B,KAAMD,GAA0B,eAChC,WAAYK,GAEf,EAGH,OAAOG,GAAiCD,CAAM,CAChD,CD/HM,IAAOE,GAAP,KAAkB,CAoBtB,gBAAqCC,EAAqB,CAUxD,GATA,KAAK,UAAY,CAAA,EAGjB,KAAK,UAAaA,EAAe,UAEjC,KAAK,qBAAuBC,GAAID,EAAQ,sBAAsB,EACzDA,EAAO,qBACRE,EAAsB,qBAEtB,CAAC,KAAK,UACR,KAAK,yBAA2BC,EAChC,KAAK,sBAAwBA,EAC7B,KAAK,gBAAkBA,EACvB,KAAK,mBAAqBA,EAC1B,KAAK,YAAcA,UAEf,QAAQ,KAAK,KAAK,oBAAoB,EACpC,KAAK,iBACP,KAAK,yBAA2BC,GAChC,KAAK,wBAA0BA,GAC/B,KAAK,YAAcD,EACnB,KAAK,uBAAyB,KAAK,qCAEnC,KAAK,yBAA2BA,EAChC,KAAK,wBAA0BA,EAC/B,KAAK,YAAc,KAAK,gBACxB,KAAK,uBAAyB,KAAK,2CAE5B,cAAc,KAAK,KAAK,oBAAoB,EACjD,KAAK,iBACP,KAAK,yBAAgCE,GACrC,KAAK,wBAA+BA,GACpC,KAAK,YAAcF,EACnB,KAAK,uBACH,KAAK,2CAEP,KAAK,yBAA2BA,EAChC,KAAK,wBAA0BA,EAC/B,KAAK,YAAc,KAAK,sBACxB,KAAK,uBACH,KAAK,iDAEA,QAAQ,KAAK,KAAK,oBAAoB,EAC/C,KAAK,yBAA2BA,EAChC,KAAK,wBAA0BA,EAC/B,KAAK,YAAcA,EACnB,KAAK,uBAAyBA,MAE9B,OAAM,MACJ,kDAAkDH,EAAO,uBAAuB,CAIxF,CAEA,yCAEEM,EAAY,CAEZA,EAAQ,SAAW,CACjB,YAAa,IACb,UAAW,IAEf,CAEA,wCAEEA,EAAY,CAEZA,EAAQ,SAAW,CAKjB,YAAa,KAAK,GAAG,CAAC,EAAE,YACxB,UAAW,IAEf,CAEA,mCAAwDA,EAAY,CAClEA,EAAQ,SAAW,CACjB,YAAa,IACb,UAAW,IACX,YAAa,IACb,UAAW,IACX,QAAS,IACT,UAAW,IAEf,CAOA,kCAAuDA,EAAY,CACjE,IAAMC,EAAY,KAAK,GAAG,CAAC,EAC3BD,EAAQ,SAAW,CACjB,YAAaC,EAAU,YACvB,UAAWA,EAAU,UACrB,YAAaA,EAAU,YACvB,UAAW,IACX,QAAS,IACT,UAAW,IAEf,CAEA,yBAA8CC,EAAoB,CAChE,IAAMF,EAAmB,CACvB,KAAME,EACN,SAAU,OAAO,OAAO,IAAI,GAG9B,KAAK,uBAAuBF,CAAO,EACnC,KAAK,UAAU,KAAKA,CAAO,CAC7B,CAEA,uBAAqB,CACnB,KAAK,UAAU,IAAG,CACpB,CAEA,gBAAqCG,EAAoB,CAEvD,IAAMC,EAAY,KAAK,GAAG,CAAC,EACrBC,EAAMF,EAAY,SAIpBE,EAAI,aAAeD,EAAU,aAC/BC,EAAI,UAAYD,EAAU,UAC1BC,EAAI,QAAUD,EAAU,QACxBC,EAAI,UAAYD,EAAU,YAI1BC,EAAI,YAAc,IAClBA,EAAI,UAAY,IAChBA,EAAI,YAAc,IAEtB,CAEA,sBAA2CF,EAAoB,CAC7D,IAAMC,EAAY,KAAK,GAAG,CAAC,EAErBC,EAAMF,EAAY,SAIpBE,EAAI,aAAeD,EAAU,YAC/BC,EAAI,UAAYD,EAAU,UAI1BC,EAAI,YAAc,GAEtB,CAEA,gBAEEC,EACAC,EAAqB,CAErB,IAAMC,EAAU,KAAK,UAAU,KAAK,UAAU,OAAS,CAAC,EACxDC,GAAiBD,EAASD,EAAeD,CAAG,EAE5C,KAAK,yBAAyBE,EAAQ,SAAgBD,CAAa,CACrE,CAEA,mBAEEG,EACAC,EAAgB,CAEhB,IAAMC,EAAa,KAAK,UAAU,KAAK,UAAU,OAAS,CAAC,EAC3DC,GAAqBD,EAAYD,EAAUD,CAAa,EAExD,KAAK,wBAAwBE,EAAW,SAAWF,EAAc,QAAS,CAC5E,CAEA,8BAA4B,CAK1B,GAAII,GAAY,KAAK,yBAAyB,EAAG,CAC/C,IAAMC,EAA+BC,GACnC,KAAK,UACLC,GAAK,KAAK,oBAAoB,CAAC,EAEjC,YAAK,0BAA4BF,EAC1BA,EAGT,OAAY,KAAK,yBACnB,CAEA,0CAAwC,CAKtC,GAAID,GAAY,KAAK,qCAAqC,EAAG,CAC3D,IAAMI,EAAiBC,GACrB,KAAK,UACLF,GAAK,KAAK,oBAAoB,EAC9B,KAAK,6BAA4B,CAAE,EAErC,YAAK,sCAAwCC,EACtCA,EAGT,OAAY,KAAK,qCACnB,CAEA,8BAA4B,CAC1B,IAAME,EAAY,KAAK,WACvB,OAAOA,EAAUA,EAAU,OAAS,CAAC,CACvC,CAEA,kCAAgC,CAC9B,IAAMA,EAAY,KAAK,WACvB,OAAOA,EAAUA,EAAU,OAAS,CAAC,CACvC,CAEA,oCAAkC,CAChC,IAAMC,EAAkB,KAAK,sBAC7B,OAAOA,EAAgBA,EAAgB,OAAS,CAAC,CACnD,GGtQI,IAAOC,GAAP,KAAmB,CAKvB,kBAAgB,CACd,KAAK,UAAY,CAAA,EACjB,KAAK,gBAAkB,EACvB,KAAK,QAAU,EACjB,CAEA,IAAI,MAAMC,EAAkB,CAG1B,GAAI,KAAK,mBAAqB,GAC5B,MAAM,MACJ,kFAAkF,EAKtF,KAAK,MAAK,EACV,KAAK,UAAYA,EACjB,KAAK,gBAAkBA,EAAS,MAClC,CAEA,IAAI,OAAK,CACP,OAAO,KAAK,SACd,CAGA,YAAU,CACR,OAAI,KAAK,SAAW,KAAK,UAAU,OAAS,GAC1C,KAAK,aAAY,EACV,KAAK,GAAG,CAAC,GAETC,EAEX,CAIA,GAAwBC,EAAe,CACrC,IAAMC,EAAY,KAAK,QAAUD,EACjC,OAAIC,EAAY,GAAK,KAAK,iBAAmBA,EACpCF,GAEA,KAAK,UAAUE,CAAS,CAEnC,CAEA,cAAY,CACV,KAAK,SACP,CAEA,kBAAgB,CACd,OAAO,KAAK,OACd,CAEA,iBAAsCC,EAAgB,CACpD,KAAK,QAAUA,CACjB,CAEA,iBAAe,CACb,KAAK,QAAU,EACjB,CAEA,uBAAqB,CACnB,KAAK,QAAU,KAAK,UAAU,OAAS,CACzC,CAEA,kBAAgB,CACd,OAAO,KAAK,iBAAgB,CAC9B,GCrEF,OAAS,YAAAC,GAAU,UAAAC,OAAc,YAMjC,OAAe,oBAAAC,OAAwB,mBAYjC,IAAOC,GAAP,KAAoB,CACxB,OAA+BC,EAAa,CAC1C,OAAOA,EAAK,KAAK,IAAI,CACvB,CAEA,QAEEC,EACAC,EACAC,EAA2B,CAE3B,OAAO,KAAK,gBAAgBD,EAASD,EAAKE,CAAO,CACnD,CAEA,QAEEF,EACAG,EACAD,EAAiC,CAEjC,OAAO,KAAK,gBAAgBC,EAAYH,EAAKE,CAAO,CACtD,CAEA,OAEEF,EACAI,EAA0D,CAE1D,OAAO,KAAK,eAAeA,EAAmBJ,CAAG,CACnD,CAEA,GAEEA,EACAK,EAA6C,CAE7C,OAAO,KAAK,WAAWA,EAAYL,CAAG,CACxC,CAEA,KAEEA,EACAI,EAA0D,CAE1D,OAAO,KAAK,aAAaJ,EAAKI,CAAiB,CACjD,CAEA,WAEEJ,EACAI,EAAiE,CAEjE,OAAO,KAAK,mBAAmBJ,EAAKI,CAAiB,CACvD,CAEA,QAEEH,EACAC,EAA2B,CAE3B,OAAO,KAAK,gBAAgBD,EAAS,EAAGC,CAAO,CACjD,CAEA,SAEED,EACAC,EAA2B,CAE3B,OAAO,KAAK,gBAAgBD,EAAS,EAAGC,CAAO,CACjD,CAEA,SAEED,EACAC,EAA2B,CAE3B,OAAO,KAAK,gBAAgBD,EAAS,EAAGC,CAAO,CACjD,CAEA,SAEED,EACAC,EAA2B,CAE3B,OAAO,KAAK,gBAAgBD,EAAS,EAAGC,CAAO,CACjD,CAEA,SAEED,EACAC,EAA2B,CAE3B,OAAO,KAAK,gBAAgBD,EAAS,EAAGC,CAAO,CACjD,CAEA,SAEED,EACAC,EAA2B,CAE3B,OAAO,KAAK,gBAAgBD,EAAS,EAAGC,CAAO,CACjD,CAEA,SAEED,EACAC,EAA2B,CAE3B,OAAO,KAAK,gBAAgBD,EAAS,EAAGC,CAAO,CACjD,CAEA,SAEED,EACAC,EAA2B,CAE3B,OAAO,KAAK,gBAAgBD,EAAS,EAAGC,CAAO,CACjD,CAEA,SAEED,EACAC,EAA2B,CAE3B,OAAO,KAAK,gBAAgBD,EAAS,EAAGC,CAAO,CACjD,CAEA,SAEED,EACAC,EAA2B,CAE3B,OAAO,KAAK,gBAAgBD,EAAS,EAAGC,CAAO,CACjD,CAEA,QAEEC,EACAD,EAAiC,CAEjC,OAAO,KAAK,gBAAgBC,EAAY,EAAGD,CAAO,CACpD,CAEA,SAEEC,EACAD,EAAiC,CAEjC,OAAO,KAAK,gBAAgBC,EAAY,EAAGD,CAAO,CACpD,CAEA,SAEEC,EACAD,EAAiC,CAEjC,OAAO,KAAK,gBAAgBC,EAAY,EAAGD,CAAO,CACpD,CAEA,SAEEC,EACAD,EAAiC,CAEjC,OAAO,KAAK,gBAAgBC,EAAY,EAAGD,CAAO,CACpD,CAEA,SAEEC,EACAD,EAAiC,CAEjC,OAAO,KAAK,gBAAgBC,EAAY,EAAGD,CAAO,CACpD,CAEA,SAEEC,EACAD,EAAiC,CAEjC,OAAO,KAAK,gBAAgBC,EAAY,EAAGD,CAAO,CACpD,CAEA,SAEEC,EACAD,EAAiC,CAEjC,OAAO,KAAK,gBAAgBC,EAAY,EAAGD,CAAO,CACpD,CAEA,SAEEC,EACAD,EAAiC,CAEjC,OAAO,KAAK,gBAAgBC,EAAY,EAAGD,CAAO,CACpD,CAEA,SAEEC,EACAD,EAAiC,CAEjC,OAAO,KAAK,gBAAgBC,EAAY,EAAGD,CAAO,CACpD,CAEA,SAEEC,EACAD,EAAiC,CAEjC,OAAO,KAAK,gBAAgBC,EAAY,EAAGD,CAAO,CACpD,CAEA,OAEEE,EAA0D,CAE1D,OAAO,KAAK,eAAeA,EAAmB,CAAC,CACjD,CAEA,QAEEA,EAA0D,CAE1D,OAAO,KAAK,eAAeA,EAAmB,CAAC,CACjD,CAEA,QAEEA,EAA0D,CAE1D,OAAO,KAAK,eAAeA,EAAmB,CAAC,CACjD,CAEA,QAEEA,EAA0D,CAE1D,OAAO,KAAK,eAAeA,EAAmB,CAAC,CACjD,CAEA,QAEEA,EAA0D,CAE1D,OAAO,KAAK,eAAeA,EAAmB,CAAC,CACjD,CAEA,QAEEA,EAA0D,CAE1D,OAAO,KAAK,eAAeA,EAAmB,CAAC,CACjD,CAEA,QAEEA,EAA0D,CAE1D,OAAO,KAAK,eAAeA,EAAmB,CAAC,CACjD,CAEA,QAEEA,EAA0D,CAE1D,OAAO,KAAK,eAAeA,EAAmB,CAAC,CACjD,CAEA,QAEEA,EAA0D,CAE1D,OAAO,KAAK,eAAeA,EAAmB,CAAC,CACjD,CAEA,QAEEA,EAA0D,CAE1D,OAAO,KAAK,eAAeA,EAAmB,CAAC,CACjD,CAEA,GAEEC,EAAiD,CAEjD,OAAO,KAAK,WAAWA,EAAY,CAAC,CACtC,CAEA,IAEEA,EAAiD,CAEjD,OAAO,KAAK,WAAWA,EAAY,CAAC,CACtC,CAEA,IAEEA,EAAiD,CAEjD,OAAO,KAAK,WAAWA,EAAY,CAAC,CACtC,CAEA,IAEEA,EAAiD,CAEjD,OAAO,KAAK,WAAWA,EAAY,CAAC,CACtC,CAEA,IAEEA,EAAiD,CAEjD,OAAO,KAAK,WAAWA,EAAY,CAAC,CACtC,CAEA,IAEEA,EAAiD,CAEjD,OAAO,KAAK,WAAWA,EAAY,CAAC,CACtC,CAEA,IAEEA,EAAiD,CAEjD,OAAO,KAAK,WAAWA,EAAY,CAAC,CACtC,CAEA,IAEEA,EAAiD,CAEjD,OAAO,KAAK,WAAWA,EAAY,CAAC,CACtC,CAEA,IAEEA,EAAiD,CAEjD,OAAO,KAAK,WAAWA,EAAY,CAAC,CACtC,CAEA,IAEEA,EAAiD,CAEjD,OAAO,KAAK,WAAWA,EAAY,CAAC,CACtC,CAEA,KAEED,EAA0D,CAE1D,KAAK,aAAa,EAAGA,CAAiB,CACxC,CAEA,MAEEA,EAA0D,CAE1D,KAAK,aAAa,EAAGA,CAAiB,CACxC,CAEA,MAEEA,EAA0D,CAE1D,KAAK,aAAa,EAAGA,CAAiB,CACxC,CAEA,MAEEA,EAA0D,CAE1D,KAAK,aAAa,EAAGA,CAAiB,CACxC,CAEA,MAEEA,EAA0D,CAE1D,KAAK,aAAa,EAAGA,CAAiB,CACxC,CAEA,MAEEA,EAA0D,CAE1D,KAAK,aAAa,EAAGA,CAAiB,CACxC,CAEA,MAEEA,EAA0D,CAE1D,KAAK,aAAa,EAAGA,CAAiB,CACxC,CAEA,MAEEA,EAA0D,CAE1D,KAAK,aAAa,EAAGA,CAAiB,CACxC,CAEA,MAEEA,EAA0D,CAE1D,KAAK,aAAa,EAAGA,CAAiB,CACxC,CAEA,MAEEA,EAA0D,CAE1D,KAAK,aAAa,EAAGA,CAAiB,CACxC,CAEA,SAAmCF,EAA+B,CAChE,KAAK,qBAAqB,EAAGA,CAAO,CACtC,CAEA,UAAoCA,EAA+B,CACjE,KAAK,qBAAqB,EAAGA,CAAO,CACtC,CAEA,UAAoCA,EAA+B,CACjE,KAAK,qBAAqB,EAAGA,CAAO,CACtC,CAEA,UAAoCA,EAA+B,CACjE,KAAK,qBAAqB,EAAGA,CAAO,CACtC,CAEA,UAAoCA,EAA+B,CACjE,KAAK,qBAAqB,EAAGA,CAAO,CACtC,CAEA,UAAoCA,EAA+B,CACjE,KAAK,qBAAqB,EAAGA,CAAO,CACtC,CAEA,UAAoCA,EAA+B,CACjE,KAAK,qBAAqB,EAAGA,CAAO,CACtC,CAEA,UAAoCA,EAA+B,CACjE,KAAK,qBAAqB,EAAGA,CAAO,CACtC,CAEA,UAAoCA,EAA+B,CACjE,KAAK,qBAAqB,EAAGA,CAAO,CACtC,CAEA,UAAoCA,EAA+B,CACjE,KAAK,qBAAqB,EAAGA,CAAO,CACtC,CAEA,aAEEE,EAAiE,CAEjE,KAAK,mBAAmB,EAAGA,CAAiB,CAC9C,CAEA,cAEEA,EAAiE,CAEjE,OAAO,KAAK,mBAAmB,EAAGA,CAAiB,CACrD,CAEA,cAEEA,EAAiE,CAEjE,KAAK,mBAAmB,EAAGA,CAAiB,CAC9C,CAEA,cAEEA,EAAiE,CAEjE,KAAK,mBAAmB,EAAGA,CAAiB,CAC9C,CAEA,cAEEA,EAAiE,CAEjE,KAAK,mBAAmB,EAAGA,CAAiB,CAC9C,CAEA,cAEEA,EAAiE,CAEjE,KAAK,mBAAmB,EAAGA,CAAiB,CAC9C,CAEA,cAEEA,EAAiE,CAEjE,KAAK,mBAAmB,EAAGA,CAAiB,CAC9C,CAEA,cAEEA,EAAiE,CAEjE,KAAK,mBAAmB,EAAGA,CAAiB,CAC9C,CAEA,cAEEA,EAAiE,CAEjE,KAAK,mBAAmB,EAAGA,CAAiB,CAC9C,CAEA,cAEEA,EAAiE,CAEjE,KAAK,mBAAmB,EAAGA,CAAiB,CAC9C,CAEA,iBAEEF,EAAqC,CAErC,KAAK,2BAA2B,EAAGA,CAAO,CAC5C,CAEA,kBAEEA,EAAqC,CAErC,KAAK,2BAA2B,EAAGA,CAAO,CAC5C,CAEA,kBAEEA,EAAqC,CAErC,KAAK,2BAA2B,EAAGA,CAAO,CAC5C,CAEA,kBAEEA,EAAqC,CAErC,KAAK,2BAA2B,EAAGA,CAAO,CAC5C,CAEA,kBAEEA,EAAqC,CAErC,KAAK,2BAA2B,EAAGA,CAAO,CAC5C,CAEA,kBAEEA,EAAqC,CAErC,KAAK,2BAA2B,EAAGA,CAAO,CAC5C,CAEA,kBAEEA,EAAqC,CAErC,KAAK,2BAA2B,EAAGA,CAAO,CAC5C,CAEA,kBAEEA,EAAqC,CAErC,KAAK,2BAA2B,EAAGA,CAAO,CAC5C,CAEA,kBAEEA,EAAqC,CAErC,KAAK,2BAA2B,EAAGA,CAAO,CAC5C,CAEA,kBAEEA,EAAqC,CAErC,KAAK,2BAA2B,EAAGA,CAAO,CAC5C,CAEA,KAEEI,EACAC,EACAC,EAAyBC,GAAmB,CAE5C,GAAIC,GAAS,KAAK,kBAAmBJ,CAAI,EAAG,CAO1C,IAAMK,EAAQ,CACZ,QANAC,EAAqC,4BAA4B,CAC/D,aAAcN,EACd,YAAa,KAAK,UACnB,EAID,KAAMO,EAA0B,oBAChC,SAAUP,GAEZ,KAAK,iBAAiB,KAAKK,CAAK,EAGlC,KAAK,kBAAkB,KAAKL,CAAI,EAEhC,IAAMQ,EAAqB,KAAK,WAAWR,EAAMC,EAAgBC,CAAM,EACtE,YAAaF,CAAI,EAAIQ,EACfA,CACT,CAEA,cAEER,EACAP,EACAS,EAAyBC,GAAmB,CAE5C,IAAMM,EAAuCC,GAC3CV,EACA,KAAK,kBACL,KAAK,SAAS,EAEhB,KAAK,iBAAmB,KAAK,iBAAiB,OAAOS,CAAU,EAE/D,IAAMD,EAAqB,KAAK,WAAWR,EAAMP,EAAMS,CAAM,EAC5D,YAAaF,CAAI,EAAIQ,EACfA,CACT,CAEA,UAEEG,EACAC,EAAY,CAEZ,OAAO,UAAA,CAEL,KAAK,oBAAoB,KAAK,CAAC,EAC/B,IAAMC,EAAW,KAAK,eAAc,EACpC,GAAI,CACF,OAAAF,EAAY,MAAM,KAAMC,CAAI,EAErB,SACAE,EAAP,CACA,GAAIC,GAAuBD,CAAC,EAC1B,MAAO,GAEP,MAAMA,UAGR,KAAK,iBAAiBD,CAAQ,EAC9B,KAAK,oBAAoB,IAAG,EAEhC,CACF,CAGO,oBAAkB,CACvB,OAAO,KAAK,oBACd,CAEO,8BAA4B,CACjC,OAAOtB,GAAiByB,GAAO,KAAK,oBAAoB,CAAC,CAC3D,GC3rBF,OACE,SAAAC,GACA,SAAAC,GACA,WAAAC,GACA,OAAAC,GACA,WAAAC,GACA,WAAAC,GACA,YAAAC,GACA,UAAAC,GACA,QAAAC,GACA,UAAAC,OACK,YAyCD,IAAOC,GAAP,KAAuB,CAe3B,qBACEC,EACAC,EAAqB,CAiBrB,GAfA,KAAK,UAAY,KAAK,YAAY,KAElC,KAAK,oBAAsB,CAAA,EAC3B,KAAK,oBAAsB,CAAA,EAC3B,KAAK,iBAAmB,IACxB,KAAK,aAAeC,GACpB,KAAK,WAAa,EAElB,KAAK,kBAAoB,CAAA,EACzB,KAAK,UAAY,CAAA,EACjB,KAAK,oBAAsB,CAAA,EAC3B,KAAK,WAAa,CAAA,EAClB,KAAK,sBAAwB,CAAA,EAC7B,KAAK,qBAAuB,CAAA,EAExBC,GAAIF,EAAQ,mBAAmB,EACjC,MAAM,MACJ;;sBAE0B,EAI9B,GAAIG,GAAQJ,CAAe,EAAG,CAI5B,GAAIK,GAAQL,CAAwB,EAClC,MAAM,MACJ;;2CAE+C,EAInD,GAAI,OAAQA,EAA0B,CAAC,EAAE,aAAgB,SACvD,MAAM,MACJ;;sBAE0B,EAKhC,GAAII,GAAQJ,CAAe,EACzB,KAAK,UAAYM,GACfN,EACA,CAACO,EAAKC,KACJD,EAAIC,EAAQ,IAAI,EAAIA,EACbD,GAET,CAAA,CAAwC,UAG1CJ,GAAIH,EAAiB,OAAO,GAC5BS,GAAMC,GAAQC,GAAaX,EAAiB,KAAK,CAAC,EAAGY,EAAW,EAChE,CACA,IAAMC,EAAgBH,GAAQC,GAAaX,EAAiB,KAAK,CAAC,EAC5Dc,EAAeC,GAAKF,CAAa,EACvC,KAAK,UAAiBP,GACpBQ,EACA,CAACP,EAAKC,KACJD,EAAIC,EAAQ,IAAI,EAAIA,EACbD,GAET,CAAA,CAAwC,UAEjCS,GAAShB,CAAe,EACjC,KAAK,UAAYiB,GAAMjB,CAAsC,MAE7D,OAAM,IAAI,MACR,wIACuE,EAM3E,KAAK,UAAU,IAASkB,EAExB,IAAML,EAAgBV,GAAIH,EAAiB,OAAO,EAC9CU,GAAQC,GAAaX,EAAiB,KAAK,CAAC,EAC5CW,GAAOX,CAAe,EACpBmB,EAAwBV,GAAMI,EAAgBO,GAClDf,GAAQe,EAAiB,eAAe,CAAC,EAG3C,KAAK,aAAeD,EAChBjB,GACAmB,EAKJC,EAAkBX,GAAO,KAAK,SAAS,CAAC,CAC1C,CAEA,WAEEY,EACAC,EACAvB,EAAsB,CAEtB,GAAI,KAAK,iBACP,MAAM,MACJ,iBAAiBsB;6FAC+E,EAGpG,IAAME,EAAyBtB,GAAIF,EAAQ,eAAe,EACrDA,EAAO,cACRyB,GAAoB,cAClBC,EAAoBxB,GAAIF,EAAQ,mBAAmB,EACpDA,EAAO,kBACRyB,GAAoB,kBAIlBE,EACJ,KAAK,kBAAqB,EAAuB,EAEnD,KAAK,mBACL,KAAK,oBAAoBA,CAAS,EAAIL,EACtC,KAAK,oBAAoBA,CAAQ,EAAIK,EAErC,IAAIC,EAIJ,OAAI,KAAK,YAAc,GACrBA,EAAoB,YAEfC,EAAU,CAEb,GAAI,CACF,KAAK,0BAA0BF,EAAWL,EAAU,KAAK,UAAU,EACnEC,EAAK,MAAM,KAAMM,CAAI,EACrB,IAAMC,EAAM,KAAK,UAAU,KAAK,UAAU,OAAS,CAAC,EACpD,YAAK,YAAYA,CAAG,EACbA,QACAC,EAAP,CACA,OAAO,KAAK,gBAAgBA,EAAGP,EAAeE,CAAiB,UAE/D,KAAK,uBAAsB,EAE/B,EAEAE,EAAoB,YAEfC,EAAU,CAEb,GAAI,CACF,YAAK,0BAA0BF,EAAWL,EAAU,KAAK,UAAU,EAC5DC,EAAK,MAAM,KAAMM,CAAI,QACrBE,EAAP,CACA,OAAO,KAAK,gBAAgBA,EAAGP,EAAeE,CAAiB,UAE/D,KAAK,uBAAsB,EAE/B,EAGwD,OAAO,OAC/DE,EACA,CAAE,SAAAN,EAAU,sBAAuBC,CAAI,CAAE,CAI7C,CAEA,gBAEE,EACAS,EACAN,EAA2B,CAE3B,IAAMO,EAAqB,KAAK,WAAW,SAAW,EAKhDC,EACJF,GAAuB,CAAC,KAAK,eAAc,GAAM,KAAK,gBAExD,GAAIG,GAAuB,CAAC,EAAG,CAC7B,IAAMC,EAAkB,EACxB,GAAIF,EAAe,CACjB,IAAMG,EAAgB,KAAK,oBAAmB,EAC9C,GAAI,KAAK,yBAAyBA,CAAa,EAE7C,GADAD,EAAW,eAAiB,KAAK,SAASC,CAAa,EACnD,KAAK,UAAW,CAClB,IAAMC,EACJ,KAAK,UAAU,KAAK,UAAU,OAAS,CAAC,EAC1C,OAAAA,EAAiB,cAAgB,GAC1BA,MAEP,QAAOZ,EAAkB,CAAC,MAEvB,CACL,GAAI,KAAK,UAAW,CAClB,IAAMY,EACJ,KAAK,UAAU,KAAK,UAAU,OAAS,CAAC,EAC1CA,EAAiB,cAAgB,GACjCF,EAAW,iBAAmBE,EAGhC,MAAMF,OAEH,IAAIH,EAET,YAAK,sBAAqB,EAGnBP,EAAkB,CAAC,EAG1B,MAAMU,OAIR,OAAM,CAEV,CAGA,eAEEG,EACAC,EAAkB,CAElB,IAAMC,EAAM,KAAK,4BAA4B,IAAYD,CAAU,EACnE,OAAO,KAAK,oBAAoBD,EAAmBC,EAAYC,CAAG,CACpE,CAEA,oBAEEF,EACAC,EACAC,EAAW,CAEX,IAAIC,EAAgB,KAAK,mBAAmBD,CAAG,EAC3CE,EACJ,GAAI,OAAOJ,GAAsB,WAAY,CAC3CI,EAASJ,EAAkB,IAC3B,IAAMK,EAAYL,EAAkB,KAEpC,GAAIK,IAAc,OAAW,CAC3B,IAAMC,EAAuBH,EAC7BA,EAAgB,IACPE,EAAU,KAAK,IAAI,GAAKC,EAAqB,KAAK,IAAI,QAIjEF,EAASJ,EAGX,GAAIG,EAAc,KAAK,IAAI,IAAM,GAC/B,OAAOC,EAAO,KAAK,IAAI,CAG3B,CAEA,mBAEEG,EACAP,EAAiE,CAEjE,IAAMQ,EAAQ,KAAK,4BACjB,KACAD,CAAc,EAEhB,OAAO,KAAK,wBACVA,EACAP,EACAQ,CAAK,CAET,CAEA,wBAEED,EACAP,EACAE,EAAW,CAEX,IAAIC,EAAgB,KAAK,mBAAmBD,CAAG,EAC3CE,EACJ,GAAI,OAAOJ,GAAsB,WAAY,CAC3CI,EAASJ,EAAkB,IAC3B,IAAMK,EAAYL,EAAkB,KAEpC,GAAIK,IAAc,OAAW,CAC3B,IAAMC,EAAuBH,EAC7BA,EAAgB,IACPE,EAAU,KAAK,IAAI,GAAKC,EAAqB,KAAK,IAAI,QAIjEF,EAASJ,EAGX,GAAeG,EAAe,KAAK,IAAI,IAAM,GAAM,CACjD,IAAIM,EAAW,KAAK,mBAAmBL,CAAM,EAC7C,KACaD,EAAe,KAAK,IAAI,IAAM,IACzCM,IAAa,IAEbA,EAAW,KAAK,mBAAmBL,CAAM,MAG3C,OAAM,KAAK,wBACTG,EACAG,EAAU,qBACkBV,EAAmB,OAAO,EAS1D,KAAK,4BACH,KAAK,mBACL,CAACO,EAAgBP,CAAiB,EAC7BG,EACL,KACAI,EACAI,EAAiC,CAErC,CAEA,2BAEEJ,EACAK,EAAqC,CAErC,IAAMJ,EAAQ,KAAK,4BACjB,KACAD,CAAc,EAEhB,KAAK,gCAAgCA,EAAgBK,EAASJ,CAAK,CACrE,CAEA,gCAEED,EACAK,EACAV,EAAW,CAEX,IAAME,EAASQ,EAAQ,IACjBC,EAAYD,EAAQ,IAK1B,GAHoC,KAAK,mBAAmBV,CAAG,EAG/B,KAAK,IAAI,IAAM,GAAM,CAC9BE,EAAQ,KAAK,IAAI,EAItC,IAAMU,EAAyB,IACtB,KAAK,aAAa,KAAK,GAAG,CAAC,EAAGD,CAAS,EAIhD,KAAO,KAAK,aAAa,KAAK,GAAG,CAAC,EAAGA,CAAS,IAAM,IAGlD,KAAK,QAAQA,CAAS,EAEDT,EAAQ,KAAK,IAAI,EAIxC,KAAK,4BACH,KAAK,4BACL,CACEG,EACAM,EACAC,EACAV,EACAW,IAEFD,EACA,KACAP,EACAQ,EAAoC,MAGtC,OAAM,KAAK,wBACTR,EACAG,EAAU,oCACVE,EAAQ,OAAO,CAGrB,CAEA,aAEEL,EACAP,EAA0D,CAE1D,IAAMQ,EAAQ,KAAK,4BAA4B,IAAUD,CAAc,EACvE,OAAO,KAAK,kBAAkBA,EAAgBP,EAAmBQ,CAAK,CACxE,CAEA,kBAEED,EACAP,EACAE,EAAW,CAEX,IAAIc,EAAoB,KAAK,mBAAmBd,CAAG,EAC/CE,EACJ,GAAI,OAAOJ,GAAsB,WAAY,CAC3CI,EAASJ,EAAkB,IAC3B,IAAMK,EAAYL,EAAkB,KAEpC,GAAIK,IAAc,OAAW,CAC3B,IAAMC,EAAuBU,EAC7BA,EAAoB,IACXX,EAAU,KAAK,IAAI,GAAKC,EAAqB,KAAK,IAAI,QAIjEF,EAASJ,EAGX,IAAIS,EAAW,GACf,KAAOO,EAAkB,KAAK,IAAI,IAAM,IAAQP,IAAa,IAC3DA,EAAW,KAAK,mBAAmBL,CAAM,EAI3C,KAAK,4BACH,KAAK,aACL,CAACG,EAAgBP,CAAiB,EAC7BgB,EACL,IACAT,EACAU,GAMAR,CAAQ,CAEZ,CAEA,qBAEEF,EACAK,EAA+B,CAE/B,IAAMJ,EAAQ,KAAK,4BACjB,KACAD,CAAc,EAEhB,KAAK,0BAA0BA,EAAgBK,EAASJ,CAAK,CAC/D,CAEA,0BAEED,EACAK,EACAV,EAAW,CAEX,IAAME,EAASQ,EAAQ,IACjBC,EAAYD,EAAQ,IAI1B,GAH6B,KAAK,mBAAmBV,CAAG,EAG/B,KAAK,IAAI,IAAM,GAAM,CAC5CE,EAAO,KAAK,IAAI,EAEhB,IAAMU,EAAyB,IACtB,KAAK,aAAa,KAAK,GAAG,CAAC,EAAGD,CAAS,EAGhD,KAAO,KAAK,aAAa,KAAK,GAAG,CAAC,EAAGA,CAAS,IAAM,IAGlD,KAAK,QAAQA,CAAS,EAEtBT,EAAO,KAAK,IAAI,EAIlB,KAAK,4BACH,KAAK,4BACL,CACEG,EACAM,EACAC,EACAV,EACAc,IAEFJ,EACA,KACAP,EACAW,EAA8B,EAGpC,CAEA,4BAEEX,EACAM,EACAC,EACAV,EACAe,EAAyE,CAEzE,KAAOL,EAAsB,GAG3B,KAAK,QAAQD,CAAS,EACtBT,EAAO,KAAK,IAAI,EASlB,KAAK,4BACH,KAAK,4BACL,CACEG,EACAM,EACAC,EACAV,EACAe,GAEFL,EACA,KACAP,EACAY,CAAuB,CAE3B,CAEA,mBAAwCf,EAAgB,CACtD,IAAMgB,EAAkB,KAAK,iBAAgB,EAC7C,OAAAhB,EAAO,KAAK,IAAI,EACO,KAAK,iBAAgB,EAIpBgB,CAC1B,CAEA,WAEEC,EACApB,EAAkB,CAElB,IAAMO,EAAQ,KAAK,4BAA4B,IAAQP,CAAU,EAC3DqB,EAAO1D,GAAQyD,CAAU,EAAIA,EAAaA,EAAW,IAGrDE,EADS,KAAK,mBAAmBf,CAAK,EAChB,KAAK,KAAMc,CAAI,EAC3C,GAAIC,IAAiB,OAEnB,OAD+BD,EAAKC,CAAY,EACvB,IAAI,KAAK,IAAI,EAExC,KAAK,oBACHtB,EACCoB,EAAqC,OAAO,CAEjD,CAEA,wBAAsB,CAOpB,GANA,KAAK,WAAW,IAAG,EACnB,KAAK,sBAAsB,IAAG,EAG9B,KAAK,sBAAqB,EAEtB,KAAK,WAAW,SAAW,GAAK,KAAK,eAAc,IAAO,GAAO,CACnE,IAAMG,EAAoB,KAAK,GAAG,CAAC,EAC7BC,EAAS,KAAK,qBAAqB,8BAA8B,CACrE,eAAgBD,EAChB,SAAU,KAAK,oBAAmB,EACnC,EACD,KAAK,WACH,IAAIE,GAA2BD,EAAQD,CAAiB,CAAC,EAG/D,CAEA,gBAEEG,EACAC,EACAhB,EAAiC,CAEjC,IAAIiB,EACJ,GAAI,CACF,IAAMvC,EAAOsB,IAAY,OAAYA,EAAQ,KAAO,OACpD,YAAK,WAAagB,EAClBC,EAAaF,EAAW,MAAM,KAAMrC,CAAI,EACxC,KAAK,mBACHuC,EACAjB,IAAY,QAAaA,EAAQ,QAAU,OACvCA,EAAQ,MACRe,EAAW,QAAQ,EAElBE,QACArC,EAAP,CACA,MAAM,KAAK,qBAAqBA,EAAGoB,EAASe,EAAW,QAAQ,EAEnE,CAEA,qBAEE,EACAf,EACA7B,EAAgB,CAEhB,MAAIa,GAAuB,CAAC,GAAK,EAAE,mBAAqB,SACtD,KAAK,mBACH,EAAE,iBACFgB,IAAY,QAAaA,EAAQ,QAAU,OACvCA,EAAQ,MACR7B,CAAQ,EAGd,OAAO,EAAE,kBAEL,CACR,CAEA,gBAEEf,EACA4D,EACAhB,EAAsC,CAEtC,IAAIkB,EACJ,GAAI,CACF,IAAMC,EAAY,KAAK,GAAG,CAAC,EACvB,KAAK,aAAaA,EAAW/D,CAAO,IAAM,IAC5C,KAAK,aAAY,EACjB8D,EAAgBC,GAEhB,KAAK,qBAAqB/D,EAAS+D,EAAWnB,CAAO,QAEhDoB,EAAP,CACAF,EAAgB,KAAK,wBACnB9D,EACA4D,EACAI,CAAgB,EAIpB,YAAK,gBACHpB,IAAY,QAAaA,EAAQ,QAAU,OACvCA,EAAQ,MACR5C,EAAQ,KACZ8D,CAAa,EAERA,CACT,CAEA,qBAEE9D,EACA+D,EACAnB,EAAsC,CAEtC,IAAIqB,EACEC,EAAgB,KAAK,GAAG,CAAC,EAC/B,MAAItB,IAAY,QAAaA,EAAQ,QACnCqB,EAAMrB,EAAQ,QAEdqB,EAAM,KAAK,qBAAqB,0BAA0B,CACxD,SAAUjE,EACV,OAAQ+D,EACR,SAAUG,EACV,SAAU,KAAK,oBAAmB,EACnC,EAEG,KAAK,WACT,IAAIC,GAAyBF,EAAKF,EAAWG,CAAa,CAAC,CAE/D,CAEA,wBAEElE,EACA4D,EACAI,EAAuB,CAIvB,GACE,KAAK,iBAELA,EAAiB,OAAS,4BAC1B,CAAC,KAAK,eAAc,EACpB,CACA,IAAMI,EAAU,KAAK,4BAAiCpE,EAAS4D,CAAG,EAClE,GAAI,CACF,OAAO,KAAK,kBAAuB5D,EAASoE,CAAO,QAC5CC,EAAP,CACA,MAAIA,EAAoB,OAASC,GAGzBN,EAEAK,OAIV,OAAML,CAEV,CAEA,gBAAc,CAEZ,IAAMO,EAAc,KAAK,OACnBC,EAAiB/D,GAAM,KAAK,UAAU,EAC5C,MAAO,CACL,OAAQ8D,EACR,WAAY,KAAK,iBAAgB,EACjC,WAAYC,EACZ,UAAW,KAAK,UAEpB,CAEA,iBAAsCC,EAAsB,CAC1D,KAAK,OAASA,EAAS,OACvB,KAAK,iBAAiBA,EAAS,UAAU,EACzC,KAAK,WAAaA,EAAS,UAC7B,CAEA,0BAEErD,EACAsD,EACAC,EAAwB,CAExB,KAAK,sBAAsB,KAAKA,CAAgB,EAChD,KAAK,WAAW,KAAKvD,CAAS,EAE9B,KAAK,yBAAyBsD,CAAQ,CACxC,CAEA,gBAAc,CACZ,OAAO,KAAK,oBAAoB,SAAW,CAC7C,CAEA,qBAAmB,CACjB,IAAMtD,EAAY,KAAK,6BAA4B,EACnD,OAAO,KAAK,oBAAoBA,CAAS,CAC3C,CAEA,wBAA6CA,EAAiB,CAC5D,OAAO,KAAK,oBAAoBA,CAAS,CAC3C,CAEO,gBAAc,CACnB,OAAO,KAAK,aAAa,KAAK,GAAG,CAAC,EAAGV,CAAG,CAC1C,CAEO,OAAK,CACV,KAAK,gBAAe,EACpB,KAAK,WAAa,EAClB,KAAK,oBAAsB,CAAA,EAC3B,KAAK,OAAS,CAAA,EACd,KAAK,WAAa,CAAA,EAElB,KAAK,UAAY,CAAA,EACjB,KAAK,sBAAwB,CAAA,CAC/B,GCv1BF,OAAS,SAAAkE,GAAO,OAAAC,OAAW,YAYrB,IAAOC,GAAP,KAAmB,CAIvB,iBAAiBC,EAAqB,CACpC,KAAK,QAAU,CAAA,EACf,KAAK,qBAAuBC,GAAID,EAAQ,sBAAsB,EACzDA,EAAO,qBACRE,EAAsB,oBAC5B,CAEA,WAEEC,EAA4B,CAE5B,GAAIC,GAAuBD,CAAK,EAC9B,OAAAA,EAAM,QAAU,CACd,UAAW,KAAK,0BAAyB,EACzC,oBAAqBE,GAAM,KAAK,qBAAqB,GAEvD,KAAK,QAAQ,KAAKF,CAAK,EAChBA,EAEP,MAAM,MACJ,6DAA6D,CAGnE,CAEA,IAAI,QAAM,CACR,OAAOE,GAAM,KAAK,OAAO,CAC3B,CAEA,IAAI,OAAOC,EAAkC,CAC3C,KAAK,QAAUA,CACjB,CAGA,wBAEEC,EACAC,EACAC,EAAqC,CAErC,IAAMC,EAAW,KAAK,oBAAmB,EACnCC,EAAc,KAAK,mBAAkB,EAAGD,CAAQ,EAOhDE,EAN+BC,GACnCN,EACAI,EACAH,EACA,KAAK,YAAY,EAEkC,CAAC,EAChDM,EAAe,CAAA,EACrB,QAASC,EAAI,EAAGA,GAAK,KAAK,aAAcA,IACtCD,EAAa,KAAK,KAAK,GAAGC,CAAC,CAAC,EAE9B,IAAMC,EAAM,KAAK,qBAAqB,sBAAsB,CAC1D,uBAAwBJ,EACxB,OAAQE,EACR,SAAU,KAAK,GAAG,CAAC,EACnB,sBAAuBL,EACvB,SAAUC,EACX,EAED,MAAM,KAAK,WAAW,IAAIO,GAAmBD,EAAK,KAAK,GAAG,CAAC,EAAG,KAAK,GAAG,CAAC,CAAC,CAAC,CAC3E,CAGA,oBAEET,EACAW,EAA+B,CAE/B,IAAMR,EAAW,KAAK,oBAAmB,EACnCC,EAAc,KAAK,mBAAkB,EAAGD,CAAQ,EAEhDS,EAA+BC,GACnCb,EACAI,EACA,KAAK,YAAY,EAGbG,EAAe,CAAA,EACrB,QAASC,EAAI,EAAGA,GAAK,KAAK,aAAcA,IACtCD,EAAa,KAAK,KAAK,GAAGC,CAAC,CAAC,EAE9B,IAAMM,EAAgB,KAAK,GAAG,CAAC,EAEzBC,EAAS,KAAK,qBAAqB,wBAAwB,CAC/D,oBAAqBH,EACrB,OAAQL,EACR,SAAUO,EACV,sBAAuBH,EACvB,SAAU,KAAK,oBAAmB,EACnC,EAED,MAAM,KAAK,WACT,IAAIK,GAAqBD,EAAQ,KAAK,GAAG,CAAC,EAAGD,CAAa,CAAC,CAE/D,GChHF,OAAS,SAAAG,GAAO,eAAAC,OAAmB,YAG7B,IAAOC,GAAP,KAAoB,CACxB,mBAAiB,CAAI,CAEd,qBAELC,EACAC,EAAwB,CAExB,IAAMC,EAAgB,KAAK,qBAAqBF,CAAa,EAE7D,GAAIF,GAAYI,CAAa,EAC3B,MAAM,MAAM,UAAUF,qCAAiD,EAGzE,OAAOG,GACL,CAACD,CAAa,EACdD,EACA,KAAK,aACL,KAAK,YAAY,CAErB,CAIO,0BAELG,EAA8B,CAE9B,IAAMC,EAAcR,GAAMO,EAAY,SAAS,EAEzCE,EADkB,KAAK,mBAAkB,EACTD,CAAW,EAKjD,OAJ+B,IAAIE,GACjCD,EACAF,CAAW,EACX,aAAY,CAEhB,GCjCF,OACE,WAAAI,GACA,OAAAC,GACA,WAAAC,GACA,cAAAC,GACA,QAAQC,GACR,QAAAC,OACK,YAEP,OACE,eAAAC,GACA,eAAAC,GACA,eAAAC,GACA,UAAAC,GACA,cAAAC,GACA,uBAAAC,GACA,oCAAAC,GACA,2BAAAC,GACA,QAAAC,GACA,YAAAC,OACK,mBAeP,IAAMC,GAAwB,CAC5B,YAAa,8DAEf,OAAO,OAAOA,EAAqB,EAEnC,IAAMC,GAAmB,GACnBC,GAAiB,KAAK,IAAI,EAAG,CAAuB,EAAI,EAExDC,GAAMC,EAAY,CAAE,KAAM,wBAAyB,QAASC,EAAM,EAAE,CAAE,EAC5EC,EAAkB,CAACH,EAAG,CAAC,EACvB,IAAMI,GAAwBC,GAC5BL,GACA;qFAKA,GACA,GACA,GACA,GACA,GACA,EAAE,EAEJ,OAAO,OAAOI,EAAqB,EAEnC,IAAME,GAAmC,CACvC,KACE;qFAEF,SAAU,CAAA,GAMCC,GAAP,KAAmB,CAIvB,iBAAsCC,EAAqB,CACzD,KAAK,mBAAqB,CAAA,EAC1B,KAAK,gBAAkB,EACzB,CAEA,iBAAe,CACb,KAAK,gBAAkB,GAEvB,KAAK,WAAW,mBAAoB,IAAK,CAUvC,QAASC,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,IAAMC,EAAMD,EAAI,EAAIA,EAAI,GACxB,KAAK,UAAUC,GAAkB,EAAI,SAAUC,EAAMC,EAAI,CACvD,OAAO,KAAK,sBAAsBD,EAAMF,EAAGG,CAAI,CACjD,EACA,KAAK,UAAUF,GAAkB,EAAI,SAAUC,EAAMC,EAAI,CACvD,OAAO,KAAK,sBAAsBD,EAAMF,EAAGG,CAAI,CACjD,EACA,KAAK,SAASF,GAAiB,EAAI,SAAUC,EAAI,CAC/C,OAAO,KAAK,qBAAqBA,EAAMF,CAAC,CAC1C,EACA,KAAK,KAAKC,GAAa,EAAI,SAAUC,EAAI,CACvC,OAAO,KAAK,iBAAiBA,EAAMF,CAAC,CACtC,EACA,KAAK,OAAOC,GAAe,EAAI,SAAUC,EAAI,CAC3C,KAAK,mBAAmBF,EAAGE,CAAI,CACjC,EACA,KAAK,WAAWD,GAAmB,EAAI,SAAUC,EAAI,CACnD,KAAK,2BAA2BF,EAAGE,CAAI,CACzC,EACA,KAAK,eAAeD,GAAuB,EAAI,SAAUC,EAAI,CAC3D,KAAK,yBAAyBF,EAAGE,CAAI,CACvC,EACA,KAAK,mBAAmBD,GAA2B,EAAI,SAAUC,EAAI,CACnE,KAAK,iCAAiCF,EAAGE,CAAI,CAC/C,EAIF,KAAK,QAAa,SAAUD,EAAKC,EAAMC,EAAI,CACzC,OAAO,KAAK,sBAAsBD,EAAMD,EAAKE,CAAI,CACnD,EACA,KAAK,QAAa,SAAUF,EAAKC,EAAMC,EAAI,CACzC,OAAO,KAAK,sBAAsBD,EAAMD,EAAKE,CAAI,CACnD,EACA,KAAK,OAAY,SAAUF,EAAKC,EAAI,CAClC,OAAO,KAAK,qBAAqBA,EAAMD,CAAG,CAC5C,EACA,KAAK,GAAQ,SAAUA,EAAKC,EAAI,CAC9B,OAAO,KAAK,iBAAiBA,EAAMD,CAAG,CACxC,EACA,KAAK,KAAU,SAAUA,EAAKC,EAAI,CAChC,KAAK,mBAAmBD,EAAKC,CAAI,CACnC,EACA,KAAK,WAAgB,SAAUD,EAAKC,EAAI,CACtC,KAAK,yBAAyBD,EAAKC,CAAI,CACzC,EAEA,KAAK,OAAS,KAAK,cACnB,KAAK,UAAY,KAAK,iBACtB,KAAK,GAAK,KAAK,SACjB,CAAC,CACH,CAEA,kBAAgB,CACd,KAAK,gBAAkB,GAKvB,KAAK,WAAW,6BAA8B,IAAK,CACjD,IAAME,EAAY,KAElB,QAASJ,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,IAAMC,EAAMD,EAAI,EAAIA,EAAI,GACxB,OAAOI,EAAK,UAAUH,GAAK,EAC3B,OAAOG,EAAK,UAAUH,GAAK,EAC3B,OAAOG,EAAK,SAASH,GAAK,EAC1B,OAAOG,EAAK,KAAKH,GAAK,EACtB,OAAOG,EAAK,OAAOH,GAAK,EACxB,OAAOG,EAAK,WAAWH,GAAK,EAC5B,OAAOG,EAAK,eAAeH,GAAK,EAChC,OAAOG,EAAK,mBAAmBH,GAAK,EAGtC,OAAOG,EAAK,QACZ,OAAOA,EAAK,QACZ,OAAOA,EAAK,OACZ,OAAOA,EAAK,GACZ,OAAOA,EAAK,KACZ,OAAOA,EAAK,WAEZ,OAAOA,EAAK,OACZ,OAAOA,EAAK,UACZ,OAAOA,EAAK,EACd,CAAC,CACH,CAKA,cAAsCC,EAAa,CAEnD,CAGA,iBACEC,EACAC,EAAY,CAEZ,MAAO,IAAM,EACf,CAIA,UAAUC,EAAe,CAGvB,OAAOC,EACT,CAEA,mBAAmBC,EAAcC,EAAa,CAC5C,GAAI,CACF,IAAMC,EAAkB,IAAIC,GAAK,CAAE,WAAY,CAAA,EAAI,KAAMH,CAAI,CAAE,EAC/D,OAAAE,EAAgB,KAAOF,EACvB,KAAK,mBAAmB,KAAKE,CAAe,EAC5CD,EAAI,KAAK,IAAI,EACb,KAAK,mBAAmB,IAAG,EACpBC,QACAE,EAAP,CACA,GAAIA,EAAc,uBAAyB,GACzC,GAAI,CACFA,EAAc,QACZA,EAAc,QACd;;yEAEF,CAEA,MAAMA,EAGV,MAAMA,EAEV,CAGA,qBAEEC,EACAC,EAAkB,CAElB,OAAOC,GAAW,KAAK,KAAMC,GAAQH,EAAmBC,CAAU,CACpE,CAEA,yBAEEA,EACAD,EAAiE,CAEjEE,GAAW,KAAK,KAAME,GAAqBJ,EAAmBC,CAAU,CAC1E,CAEA,iCAEEA,EACAI,EAAqC,CAErCH,GAAW,KACT,KACAI,GACAD,EACAJ,EACA3B,EAAgB,CAEpB,CAEA,mBAEE2B,EACAD,EAA0D,CAE1DE,GAAW,KAAK,KAAMK,GAAYP,EAAmBC,CAAU,CACjE,CAEA,2BAEEA,EACAI,EAA+B,CAE/BH,GAAW,KACT,KACAM,GACAH,EACAJ,EACA3B,EAAgB,CAEpB,CAEA,iBAEEmC,EACAR,EAAkB,CAElB,OAAOS,GAAa,KAAK,KAAMD,EAAYR,CAAU,CACvD,CAEA,sBAEEU,EACAV,EACAI,EAAiC,CAGjC,GADAO,GAAuBX,CAAU,EAC7B,CAACU,GAAcE,GAAIF,EAAY,UAAU,IAAM,GAAO,CACxD,IAAMG,EAAa,IAAI,MACrB,WAAWC,GAAad,CAAU,wEACkB,KAAK,UACrDU,CAAU;2BAGH,KAAK,mBAAmB,CAAC,EAAG,OAClC,EAEP,MAAAG,EAAM,qBAAuB,GACvBA,EAGR,IAAME,EAAgBC,GAAK,KAAK,kBAAkB,EAC5CC,EAAWP,EAAW,SACtBQ,EAAkB,IAAIC,GAAY,CACtC,IAAKnB,EACL,gBAAiBiB,EACjB,MAAOb,GAAS,MAEhB,eAAgB,OACjB,EACD,OAAAW,EAAS,WAAW,KAAKG,CAAe,EAEjC,KAAK,UACRrC,GACKT,EACX,CAEA,sBAEEgD,EACApB,EACAI,EAA2B,CAG3B,GADAO,GAAuBX,CAAU,EAC7B,CAACqB,GAAoBD,CAAO,EAAG,CACjC,IAAMP,EAAa,IAAI,MACrB,WAAWC,GAAad,CAAU,oEACc,KAAK,UACjDoB,CAAO;2BAGA,KAAK,mBAAmB,CAAC,EAAG,OAClC,EAEP,MAAAP,EAAM,qBAAuB,GACvBA,EAER,IAAME,EAAgBC,GAAK,KAAK,kBAAkB,EAC5CE,EAAkB,IAAII,GAAS,CACnC,IAAKtB,EACL,aAAcoB,EACd,MAAOhB,GAAS,MACjB,EACD,OAAAW,EAAS,WAAW,KAAKG,CAAe,EAEjCvC,EACT,GAGF,SAASsB,GACPsB,EACAC,EACAxB,EACAyB,EAAqB,GAAK,CAE1Bd,GAAuBX,CAAU,EACjC,IAAMe,EAAgBC,GAAK,KAAK,kBAAkB,EAC5CU,EAAgBC,GAAWH,CAAW,EAAIA,EAAcA,EAAY,IAEpEI,EAAU,IAAIL,EAAgB,CAAE,WAAY,CAAA,EAAI,IAAKvB,CAAU,CAAE,EACvE,OAAIyB,IACFG,EAAQ,UAAYJ,EAAY,KAE9BZ,GAAIY,EAAa,eAAe,IAClCI,EAAQ,aAAeJ,EAAY,eAGrC,KAAK,mBAAmB,KAAKI,CAAO,EACpCF,EAAc,KAAK,IAAI,EACvBX,EAAS,WAAW,KAAKa,CAAO,EAChC,KAAK,mBAAmB,IAAG,EAEpBxD,EACT,CAEA,SAASqC,GAAae,EAAkBxB,EAAkB,CACxDW,GAAuBX,CAAU,EACjC,IAAMe,EAAgBC,GAAK,KAAK,kBAAkB,EAE5Ca,EAAaC,GAAQN,CAAW,IAAM,GACtCO,EACJF,IAAe,GAAQL,EAAcA,EAAY,IAE7CQ,EAAY,IAAIC,GAAY,CAChC,WAAY,CAAA,EACZ,IAAKjC,EACL,kBAAmB6B,GAAcL,EAAY,qBAAuB,GACrE,EACGZ,GAAIY,EAAa,eAAe,IAClCQ,EAAU,aAAeR,EAAY,eAGvC,IAAMU,EAAgBC,GAAKJ,EAAOK,GAAiBT,GAAWS,EAAQ,IAAI,CAAC,EAC3E,OAAAJ,EAAU,cAAgBE,EAE1BnB,EAAS,WAAW,KAAKiB,CAAS,EAElCK,GAAQN,EAAOK,GAAW,CACxB,IAAME,EAAc,IAAIC,GAAY,CAAE,WAAY,CAAA,CAAE,CAAE,EACtDP,EAAU,WAAW,KAAKM,CAAW,EACjC1B,GAAIwB,EAAS,oBAAoB,EACnCE,EAAY,kBAAoBF,EAAQ,mBAGjCxB,GAAIwB,EAAS,MAAM,IAC1BE,EAAY,kBAAoB,IAElC,KAAK,mBAAmB,KAAKA,CAAW,EACxCF,EAAQ,IAAI,KAAK,IAAI,EACrB,KAAK,mBAAmB,IAAG,CAC7B,CAAC,EACMhE,EACT,CAEA,SAAS0C,GAAa7B,EAAW,CAC/B,OAAOA,IAAQ,EAAI,GAAK,GAAGA,GAC7B,CAEA,SAAS0B,GAAuB1B,EAAW,CACzC,GAAIA,EAAM,GAAKA,EAAMX,GAAgB,CACnC,IAAMuC,EAAa,IAAI,MAErB,kCAAkC5B;wDAE9BX,GAAiB,GACjB,EAEN,MAAAuC,EAAM,qBAAuB,GACvBA,EAEV,CCtcA,OAAS,OAAA2B,OAAW,YACpB,OAAS,SAAAC,OAAa,oBAOhB,IAAOC,GAAP,KAAwB,CAK5B,sBAAsBC,EAAqB,CACzC,GAAIC,GAAID,EAAQ,eAAe,EAAG,CAChC,IAAME,EAAoBF,EAAO,cAC3BG,EAAgB,OAAOD,GAAsB,SACnD,KAAK,kBAAoBC,EACbD,EACR,IACJ,KAAK,cAAgBC,EACjBD,EAAoB,EACnBA,OAEL,KAAK,kBAAoB,EACzB,KAAK,cAAgBE,EAAsB,cAG7C,KAAK,gBAAkB,EACzB,CAEA,WAAmCC,EAAmBC,EAAkB,CAGtE,GAAI,KAAK,gBAAkB,GAAM,CAC/B,KAAK,kBACL,IAAMC,EAAS,IAAI,MAAM,KAAK,gBAAkB,CAAC,EAAE,KAAK,GAAI,EACxD,KAAK,gBAAkB,KAAK,mBAC9B,QAAQ,IAAI,GAAGA,SAAcF,IAAY,EAE3C,GAAM,CAAE,KAAAG,EAAM,MAAAC,CAAK,EAAKC,GAAMJ,CAAS,EAEjCK,EAAcH,EAAO,GAAK,QAAQ,KAAO,QAAQ,IACvD,OAAI,KAAK,gBAAkB,KAAK,mBAC9BG,EAAY,GAAGJ,SAAcF,YAAoBG,KAAQ,EAE3D,KAAK,kBACEC,MAEP,QAAOH,EAAS,CAEpB,GCpDI,SAAUM,GAAYC,EAAkBC,EAAgB,CAC5DA,EAAU,QAASC,GAAY,CAC7B,IAAMC,EAAYD,EAAS,UAC3B,OAAO,oBAAoBC,CAAS,EAAE,QAASC,GAAY,CACzD,GAAIA,IAAa,cACf,OAGF,IAAMC,EAAqB,OAAO,yBAChCF,EACAC,CAAQ,EAIRC,IACCA,EAAmB,KAAOA,EAAmB,KAE9C,OAAO,eACLL,EAAY,UACZI,EACAC,CAAkB,EAGpBL,EAAY,UAAUI,CAAQ,EAAIF,EAAS,UAAUE,CAAQ,CAEjE,CAAC,CACH,CAAC,CACH,ClCYO,IAAME,GAAcC,GACzBC,EACA,GACA,IACA,IACA,IACA,IACA,IACA,GAAG,EAEL,OAAO,OAAOF,EAAW,EAIlB,IAAMG,EAET,OAAO,OAAO,CAChB,gBAAiB,GACjB,aAAc,EACd,qBAAsB,GACtB,UAAW,GACX,qBAAsBC,GACtB,qBAAsB,OACtB,cAAe,GACf,gBAAiB,GAClB,EAEYC,GAAkD,OAAO,OAAO,CAC3E,kBAAmB,IAAG,GACtB,cAAe,GAChB,EAEWC,GAAZ,SAAYA,EAAyB,CACnCA,EAAAA,EAAA,kBAAA,CAAA,EAAA,oBACAA,EAAAA,EAAA,oBAAA,CAAA,EAAA,sBACAA,EAAAA,EAAA,sBAAA,CAAA,EAAA,wBACAA,EAAAA,EAAA,sBAAA,CAAA,EAAA,wBACAA,EAAAA,EAAA,uBAAA,CAAA,EAAA,yBACAA,EAAAA,EAAA,eAAA,CAAA,EAAA,iBACAA,EAAAA,EAAA,oBAAA,CAAA,EAAA,sBACAA,EAAAA,EAAA,eAAA,CAAA,EAAA,iBACAA,EAAAA,EAAA,gCAAA,CAAA,EAAA,kCACAA,EAAAA,EAAA,mBAAA,CAAA,EAAA,qBACAA,EAAAA,EAAA,uBAAA,EAAA,EAAA,yBACAA,EAAAA,EAAA,sBAAA,EAAA,EAAA,wBACAA,EAAAA,EAAA,cAAA,EAAA,EAAA,gBACAA,EAAAA,EAAA,4BAAA,EAAA,EAAA,6BACF,GAfYA,IAAAA,EAAyB,CAAA,EAAA,EA0D/B,IAAOC,GAAP,KAAa,CAYjB,OAAO,oBAAoBC,EAAsB,CAC/C,MAAM,MACJ,4HAC+D,CAEnE,CAEO,qBAAmB,CACxB,KAAK,WAAW,sBAAuB,IAAK,CAC1C,IAAIC,EAEJ,KAAK,iBAAmB,GACxB,IAAMC,EAAY,KAAK,UAEvB,KAAK,WAAW,cAAe,IAAK,CAIlCC,GAAiB,IAAI,CACvB,CAAC,EAED,KAAK,WAAW,oBAAqB,IAAK,CACxC,GAAI,CACF,KAAK,gBAAe,EAEpBC,GAAQ,KAAK,kBAAoBC,GAAgB,CAI/C,IAAMC,EAHe,KACnBD,CAAY,EAE4B,sBACtCE,EACJ,KAAK,WAAW,GAAGF,SAAqB,IAAK,CAC3CE,EAAmB,KAAK,mBACtBF,EACAC,CAAqB,CAEzB,CAAC,EACD,KAAK,qBAAqBD,CAAY,EAAIE,CAC5C,CAAC,UAED,KAAK,iBAAgB,EAEzB,CAAC,EAED,IAAIC,EAA2C,CAAA,EAmD/C,GAlDA,KAAK,WAAW,oBAAqB,IAAK,CACxCA,EAAiBC,GAAe,CAC9B,MAAOC,GAAO,KAAK,oBAAoB,EACxC,EACD,KAAK,iBAAmB,KAAK,iBAAiB,OAAOF,CAAc,CACrE,CAAC,EAED,KAAK,WAAW,sBAAuB,IAAK,CAG1C,GAAIG,GAAQH,CAAc,GAAK,KAAK,kBAAoB,GAAO,CAC7D,IAAMI,EAAmBC,GAAgB,CACvC,MAAOH,GAAO,KAAK,oBAAoB,EACvC,WAAYA,GAAO,KAAK,SAAS,EACjC,eAAgBI,EAChB,YAAaZ,EACd,EACKa,EAA4BC,GAAkB,CAClD,kBAAmB,KAAK,kBACxB,MAAON,GAAO,KAAK,oBAAoB,EACvC,WAAYA,GAAO,KAAK,SAAS,EACjC,YAAaR,EACd,EACD,KAAK,iBAAmB,KAAK,iBAAiB,OAC5CU,EACAG,CAAyB,EAG/B,CAAC,EAGGJ,GAAQ,KAAK,gBAAgB,IAE3B,KAAK,iBACP,KAAK,WAAW,yBAA0B,IAAK,CAC7C,IAAMM,EAAaC,GACjBR,GAAO,KAAK,oBAAoB,CAAC,EAEnC,KAAK,cAAgBO,CACvB,CAAC,EAGH,KAAK,WAAW,4BAA6B,IAAK,UAChDE,GAAAC,EAAA,KAAK,mBAAkB,cAAU,MAAAD,IAAA,QAAAA,EAAA,KAAAC,EAAG,CAClC,MAAOV,GAAO,KAAK,oBAAoB,EACxC,EACD,KAAK,6BAA6BA,GAAO,KAAK,oBAAoB,CAAC,CACrE,CAAC,GAID,CAACX,GAAO,kCACR,CAACY,GAAQ,KAAK,gBAAgB,EAE9B,MAAAV,EAAgBoB,GACd,KAAK,iBACJC,GAAaA,EAAS,OAAO,EAE1B,IAAI,MACR;GAAwCrB,EAAc,KACpD;;CAAqC,GACpC,CAGT,CAAC,CACH,CAMA,YAAYsB,EAAkCC,EAAqB,CAJnE,KAAA,iBAA6C,CAAA,EAC7C,KAAA,iBAAmB,GAIjB,IAAMC,EAAsB,KAW5B,GAVAA,EAAK,iBAAiBD,CAAM,EAC5BC,EAAK,iBAAgB,EACrBA,EAAK,eAAeD,CAAM,EAC1BC,EAAK,qBAAqBF,EAAiBC,CAAM,EACjDC,EAAK,gBAAgBD,CAAM,EAC3BC,EAAK,gBAAgBD,CAAM,EAC3BC,EAAK,kBAAiB,EACtBA,EAAK,iBAAiBD,CAAM,EAC5BC,EAAK,sBAAsBD,CAAM,EAE7BE,GAAIF,EAAQ,eAAe,EAC7B,MAAM,IAAI,MACR;;;sBAGwB,EAI5B,KAAK,gBAAkBE,GAAIF,EAAQ,iBAAiB,EAC/CA,EAAO,gBACRG,EAAsB,eAC5B,GAjJO5B,GAAA,iCAA4C,GAoJrD6B,GAAY7B,GAAQ,CAClB8B,GACAC,GACAC,GACAC,GACAC,GACAC,GACAC,GACAC,GACAC,GACAC,GACD,EAEK,IAAOC,GAAP,cAAyBxC,EAAM,CACnC,YACEwB,EACAC,EAAgCG,EAAqB,CAErD,IAAMa,EAAcC,GAAMjB,CAAM,EAChCgB,EAAY,UAAY,GACxB,MAAMjB,EAAiBiB,CAAW,CACpC,GmCpQF,OACE,eAAAE,GACA,eAAAC,GACA,eAAAC,GACA,UAAAC,GACA,cAAAC,GACA,uBAAAC,GACA,oCAAAC,GACA,2BAAAC,GACA,QAAAC,GACA,YAAAC,OACK,mBAIP,OACE,oBAAAC,GACA,uBAAAC,GACA,eAAAC,OACK,mBAEP,OAAS,kBAAAC,OAAsB,0BChE/B,SAASC,GAAUC,EAAc,CAE/B,IAAIC,EAAU,CACZ,GAAI,IACJ,KAAM,KACN,QAAS,IACT,OAAQ,IACR,OAAQ,IACR,UAAW,IACX,WAAY,IACZ,aAAc,KACd,YAAa,IACb,aAAc,GAChB,EAkBA,OAAO,OAAOA,EAASD,EAhBP,CACd,YAAa,IACb,aAAc,IACd,YAAa,IACb,aAAc,IACd,aAAc,IAChB,EAEgB,CACd,YAAa,IACb,aAAc,IACd,YAAa,IACb,aAAc,IACd,aAAc,GAChB,CAE2D,EAE3D,IAAME,EAAU,CAAC,EACjB,OAAO,QAAQD,CAAO,EAAE,QAAQ,CAAC,CAACE,GAAGC,EAAC,IAAM,CAAEF,EAAQC,EAAC,EAAIE,GAAYD,EAAC,CAAE,CAAC,EAE3E,IAAME,EAAuB,IAAI,OAAO,GAAGJ,EAAQ,2BAA2B,EAE9EA,EAAQ,QAAU,OAAO,OAAOA,CAAO,EAAE,KAAK,EAAE,EAAE,QAAQ,QAAS,EAAE,EACrED,EAAQ,gBAAkB,IAAI,OAAOK,EAAqB,OAAQ,GAAG,EAErE,IAAMC,EAAWC,EAAY,CAC3B,KAAM,WACN,QAAS,IAAI,OAAO,OAAON,EAAQ,YAAY,EAC/C,SAAU,EACZ,CAAC,EAEKO,EAAOD,EAAY,CACvB,KAAM,OACN,QAAS,IAAI,OAAO,KAAKN,EAAQ,cAAc,CACjD,CAAC,EAEKQ,EAAcF,EAAY,CAC9B,KAAM,cACN,QAASF,CACX,CAAC,EAEKK,EAAYH,EAAY,CAC5B,KAAM,YACN,QAAS,IAAI,OAAO,GAAGN,EAAQ,eAAe,EAC9C,UAAW,WACb,CAAC,EAGKU,EAAKJ,EAAY,CAAE,KAAM,KAAM,QAAS,IAAI,OAAON,EAAQ,YAAc,MAAM,CAAE,CAAC,EAClFW,EAAKL,EAAY,CAAE,KAAM,KAAM,QAAS,IAAI,OAAO,OAAON,EAAQ,cAAc,CAAE,CAAC,EACnFY,EAAKN,EAAY,CAAE,KAAM,KAAM,QAAS,UAAW,CAAC,EACpDO,EAAOP,EAAY,CAAE,KAAM,OAAQ,QAAS,YAAa,CAAC,EAC1DQ,EAAKR,EAAY,CAAE,KAAM,KAAM,QAAS,SAAU,CAAC,EACnDS,EAAKT,EAAY,CAAE,KAAM,KAAM,QAAS,oCAAqC,CAAC,EAC9EU,EAAKV,EAAY,CAAE,KAAM,KAAM,QAAS,IAAI,OAAO,GAAGN,EAAQ,iBAAiB,CAAE,CAAC,EAClFiB,EAAKX,EAAY,CAAE,KAAM,KAAM,QAAS,IAAI,OAAO,OAAON,EAAQ,cAAc,CAAE,CAAC,EACnFkB,EAAMZ,EAAY,CAAE,KAAM,MAAO,QAAS,IAAI,OAAO,IAAIN,EAAQ,UAAUA,EAAQ,sBAAsB,CAAE,CAAC,EAE5GmB,EAASb,EAAY,CAAE,KAAM,SAAU,QAAS,+CAAgD,CAAC,EACjGc,EAASd,EAAY,CAAE,KAAM,SAAU,QAAS,IAAI,OAAO,OAAON,EAAQ,gBAAgBA,EAAQ,kBAAkB,CAAE,CAAC,EACvHqB,EAAMf,EAAY,CAAE,KAAM,MAAO,QAAS,IAAI,OAAO,KAAKN,EAAQ,WAAW,CAAE,CAAC,EAatF,MAAO,CAAE,OARS,CAChB,MAAO,CACL,OALe,CAACmB,EAAQC,EAAQP,EAAMH,EAAIC,EAAIC,EAAIE,EAAII,EAAKH,EAAIC,EAAIC,EAAIT,EAAaa,EAAKZ,CAAS,EAMlG,UALa,CAACF,EAAMF,CAAQ,CAM9B,EACA,YAAa,QACf,EAE4B,UAAW,CAAE,QAAAN,EAAS,QAAAC,CAAQ,CAAE,CAC9D,CAEA,SAASG,GAAYmB,EAAG,CACtB,OAAOA,EAAE,QAAQ,yBAA0B,MAAM,CACnD,CC7FA,IAAMC,GAAN,cAA6BC,EAAU,CAErC,YAAYC,EAAW,CACrB,MAAMA,EAAW,CAAE,qBAAsB,MAAO,CAAC,EACjD,KAAK,UAAY,CAAC,SAAU,SAAU,SAAU,SAAU,QAAS,OAAQ,QAAQ,EACnF,KAAK,WAAW,CAClB,CAEA,MAAMC,EAAM,CACV,KAAK,MAAQA,EAAK,OAElB,IAAIC,EAAM,KAAK,OAAO,EACtB,GAAI,KAAK,OAAO,OAAS,EAAG,MAAM,MAC/B;AAAA,EAAgB,KAAK,OAAO,CAAC,EAAE,OAAO,EACzC,OAAOA,CACT,CAEA,YAAa,CAEX,IAAMC,EAAI,KAAMC,EAAS,KAAK,UAE9BD,EAAE,KAAK,SAAU,IAAM,CACrBA,EAAE,KAAK,IAAMA,EAAE,QAAQA,EAAE,IAAI,CAAC,CAChC,CAAC,EAEDA,EAAE,KAAK,QAAS,IAAM,CACpBA,EAAE,QAAQC,EAAO,WAAW,EAC5BD,EAAE,KAAK,IAAMA,EAAE,QAAQC,EAAO,EAAE,CAAC,CACnC,CAAC,EAEDD,EAAE,KAAK,SAAU,IAAM,CACrBA,EAAE,QAAQC,EAAO,MAAM,CACzB,CAAC,EAEDD,EAAE,KAAK,OAAQ,IAAM,CACnBA,EAAE,QAAQC,EAAO,SAAS,EAC1BD,EAAE,KAAK,IAAMA,EAAE,QAAQC,EAAO,IAAI,CAAC,EACnCD,EAAE,QAAQC,EAAO,QAAQ,CAC3B,CAAC,EAEDD,EAAE,KAAK,SAAU,IAAM,CACrBA,EAAE,QAAQC,EAAO,EAAE,EACnBD,EAAE,QAAQ,IAAMA,EAAE,QAAQA,EAAE,IAAI,CAAC,EACjCA,EAAE,QAAQC,EAAO,GAAG,EACpBD,EAAE,QAAQ,IAAM,CACdA,EAAE,QAAQC,EAAO,EAAE,EACnBD,EAAE,QAAQA,EAAE,IAAI,CAClB,CAAC,EACDA,EAAE,QAAQC,EAAO,EAAE,CACrB,CAAC,EAEDD,EAAE,KAAK,SAAU,IAAM,CACrBA,EAAE,QAAQC,EAAO,GAAG,EACpBD,EAAE,QAAQC,EAAO,EAAE,EACnBD,EAAE,QAAQA,EAAE,IAAI,CAClB,CAAC,EAEDA,EAAE,KAAK,SAAU,IAAM,CACrBA,EAAE,QAAQC,EAAO,GAAG,EACpBD,EAAE,KAAK,IAAMA,EAAE,QAAQC,EAAO,EAAE,CAAC,CACnC,CAAC,EAEDD,EAAE,KAAK,SAAU,IAAM,CACrBA,EAAE,QAAQA,EAAE,OAAO,CACrB,CAAC,EAEDA,EAAE,KAAK,SAAU,IAAM,CACrBA,EAAE,QAAQA,EAAE,OAAO,CACrB,CAAC,EAEDA,EAAE,KAAK,UAAW,IAAM,CACtBA,EAAE,SAAS,CACT,IAAKC,EAAO,GACZ,IAAK,IAAMD,EAAE,QAAQA,EAAE,KAAK,CAC9B,CAAC,CACH,CAAC,EAGDA,EAAE,KAAK,SAAU,IAAM,CACrBA,EAAE,QAAQC,EAAO,EAAE,EACnBD,EAAE,QAAQ,IAAMA,EAAE,QAAQA,EAAE,IAAI,CAAC,EACjCA,EAAE,QAAQA,EAAE,MAAM,EAKlBA,EAAE,QAAQ,IAAM,CACdA,EAAE,QAAQC,EAAO,IAAI,EACrBD,EAAE,QAAQA,EAAE,MAAM,CACpB,CAAC,EACDA,EAAE,QAAQC,EAAO,EAAE,EACnBD,EAAE,KAAK,IAAMA,EAAE,QAAQC,EAAO,EAAE,CAAC,CACnC,CAAC,EAEDD,EAAE,KAAK,QAAS,IAAM,CACpBA,EAAE,KAAK,IAAM,CACXA,EAAE,GAAG,CACH,CAAE,IAAK,IAAMA,EAAE,QAAQA,EAAE,IAAI,CAAE,EAC/B,CAAE,IAAK,IAAMA,EAAE,QAAQC,EAAO,MAAM,CAAE,CACxC,CAAC,CACH,CAAC,CACH,CAAC,EAEDD,EAAE,KAAK,OAAQ,IAAM,CACnBA,EAAE,aAAa,IAAMA,EAAE,QAAQA,EAAE,IAAI,CAAC,CACxC,CAAC,EAEDA,EAAE,KAAK,OAAQ,IAAM,CACnBA,EAAE,GAAG,KAAK,UAAU,IAAIE,IAAM,CAAE,IAAK,IAAMF,EAAE,QAAQA,EAAEE,CAAC,CAAC,CAAE,EAAE,CAAC,CAChE,CAAC,EAEDF,EAAE,KAAK,OAAQ,IAAM,CACnBA,EAAE,QAAQC,EAAO,GAAG,CACtB,CAAC,EAED,KAAK,oBAAoB,CAC3B,CACF,ECvHA,IAAME,GAAN,KAAkB,CAChB,YAAYC,EAAU,CACpB,KAAK,MAAQ,EAEb,KAAK,KAAO,GACZ,KAAK,UAAY,GACjB,KAAK,UAAYA,EACjB,KAAK,mBAAqB,GAC1B,KAAK,SAAW,KAAK,UAAU,WACjC,CAEA,UAAUC,EAAG,CACX,OAAQ,OAAOA,GAAM,WAClB,WAAYA,GAAM,SAAUA,GAAK,aAAcA,GAAK,aAAcA,EACvE,CAEA,MAAMC,EAASC,EAAO,CAIpB,GAHI,MAAM,QAAQD,CAAO,IACvBA,EAAUA,EAAQ,CAAC,GAEjB,OAAOA,EAAY,IACrB,OAEF,GAAI,CAAC,KAAK,UAAUA,CAAO,EACzB,MAAM,MAAM,gCAAkC,KAAK,UAAUA,CAAO,CAAC,EAGvE,GAAM,CAAE,KAAAE,EAAM,SAAAC,CAAS,EAAIH,EAO3B,GALA,KAAK,SAAW,KAAK,MAAM,UACzBG,EAAS,YACTA,EAAS,UAAY,CACvB,EAEI,OAAO,KAAKD,CAAI,GAAM,WACxB,MAAM,MAAM,kDACPA,aAAgB,OAAO,KAAKA,CAAI,MAAM,KAAK,UAAU,KAAKA,CAAI,CAAC,GAAG,EAGzE,OAAI,KAAK,WAAa,CAAC,qBAAqB,KAAKA,CAAI,IACnD,KAAK,MAAQA,EAAO,KAEf,KAAKA,CAAI,EAAEF,EAAQ,SAAUC,CAAK,CAC3C,CAEA,iBAAkB,CAElB,CACF,EAEMG,GAAN,cAA8BP,EAAY,CACxC,YAAYC,EAAUO,EAAU,CAAC,EAAG,CAClC,MAAMP,CAAQ,EACd,KAAK,QAAUO,EAEf,KAAK,MAAQ,EACb,KAAK,QAAU,CAAC,EAChB,KAAK,WAAa,GAClB,KAAK,QAAU,KAAK,UAAU,QAC9B,KAAK,QAAU,KAAK,UAAU,QAG9B,KAAK,QAAU,CAAC,EAChB,KAAK,SAAW,CAAC,EACjB,KAAK,aAAe,CAAC,EACrB,KAAK,eAAiB,IAAI,IAE1B,KAAK,gBAAgB,CACvB,CAEA,MAAMC,EAAO,CAAC,EAAG,CAIf,GAHA,KAAK,MAAQA,EAAK,MAClB,KAAK,MAAQA,EAAK,MAClB,KAAK,QAAUA,EAAK,QAChB,CAACA,EAAK,IAAK,MAAM,MAAM,QAAQ,EACnC,OAAO,MAAM,MAAMA,EAAK,GAAG,CAC7B,CAEA,OAAOC,EAAK,CACV,KAAK,MAAQ,EACb,IAAMC,EAAQD,EAAI,KAAOA,EAAI,KAAK,OAAS,EAG3C,GAFA,KAAK,MAAM,SAAU,IAAM,KAAK,SAAS,YAAY,KAAK,KAAK,EAC3D,QAAUC,EAAQ,gBAAgB,EAClC,CAACA,EAAO,MAAO,GACnB,GAAI,OAAO,KAAKD,CAAG,EAAE,SAAW,EAAG,MAAM,MAAM,sBAAsB,EACrE,OAAO,KAAK,MAAMA,EAAI,IAAI,CAC5B,CAEA,KAAKA,EAAK,CAER,IAAME,EAAQ,OAAO,KAAKF,CAAG,EAC7B,GAAIE,EAAM,SAAW,EAAG,MAAM,MAAM,iBAAmBA,EAAM,MAAM,EACnE,IAAMC,EAAQH,EAAI,KAAK,IAAKI,GAAM,KAAK,MAAMA,CAAC,CAAC,EAE/C,QAAS,EAAI,EAAG,EAAID,EAAM,OAAS,EAAG,IAElCA,EAAM,CAAC,EAAE,SAAW,GACpBA,EAAM,EAAI,CAAC,EAAE,SAAS,GAAG,GACzBA,EAAM,EAAI,CAAC,EAAE,WAAW,GAAG,IAE3BA,EAAM,EAAI,CAAC,EAAIA,EAAM,EAAI,CAAC,EAAE,UAAU,CAAC,GAG3C,OAAOA,EAAM,KAAK,EAAE,CACtB,CAEA,MAAMH,EAAK,CACT,KAAK,MAAM,OAAO,CACpB,CAEA,KAAKA,EAAK,CAGR,GAAIA,EAAI,KAAK,SAAW,EAAG,MAAM,MAAM,iBAAmBA,EAAI,IAAI,EAElE,IAAIK,EACEC,EAAMN,EAAI,KAAK,CAAC,EAAE,MACxB,GAAI,CACFK,EAAa,KAAK,UAAU,OAAOC,CAAG,CACxC,OAASC,EAAP,CACA,GAAI,CAAC,KAAK,mBACR,MAAM,MAAM,sBAAsBD;AAAA;AAAA,eAAyBC,GAAG,EAEhE,MAAI,CAAC,KAAK,UAAU,KAAK,QAAU,CAAC,KAAK,UAAU,QACjD,QAAQ,KAAK,kCAAkCD;AAAA,EAAUC,CAAC,EAErD,CAAE,SAAU,QAAS,CAC9B,CAEA,IAAMC,EAAc,CAAC,EACfC,EAAgB,CAAC,EACjBC,EAAWL,EAAW,SAAS,EAyBrC,GAxBAK,EAAS,QAASC,GAAQ,CACxB,GAAI,CAAE,OAAAC,EAAQ,SAAAC,EAAU,SAAAC,EAAU,OAAAC,CAAO,EAAI,KAAK,aAAaJ,CAAG,EAE9D,OAAOC,GAAW,aAEpBA,EAASA,EAAO,KAAK,EACrBC,EAAW,CAAC,KAAK,UAAU,YAAYD,CAAM,GAE3C,OAAOA,EAAW,KAAe,CAACC,EACpCJ,EAAc,KAAKE,CAAG,GAGlBG,EACF,KAAK,QAAQH,CAAG,EAAIC,EACXG,EACT,KAAK,QAAQJ,CAAG,EAAIC,EAEpB,KAAK,SAASD,CAAG,EAAIC,EAGvBJ,EAAYG,CAAG,EAAIC,EAEvB,CAAC,EAGC,OAAO,KAAKJ,CAAW,EAAE,OAASC,EAAc,SAChDC,EAAS,OACP,MAAM,MAAM,kBAAkB,EAGlC,GAAID,EAAc,OAAU,MAAO,CAAE,SAAU,QAAS,SAAUA,CAAc,EAEhF,IAAIG,EAASP,EAAW,KAAKG,CAAW,EACxC,MAAI,CAACI,GAAU,KAAK,WAAWJ,CAAW,IACxCI,EAASP,EAAW,KAAKG,CAAW,GAG/B,CAAE,SAAUI,EAAS,SAAW,QAAS,CAClD,CAEA,OAAOZ,EAAKD,EAAM,CAChB,IAAMY,EAAMX,EAAI,IAAI,CAAC,EAAE,MACnBgB,EACAC,EACEC,EAAQP,EAAI,QAAQ,KAAK,UAAU,YAAa,EAAE,EAGxD,GAFiBA,EAAI,WAAW,KAAK,QAAQ,MAAM,EAGjDK,EAAQ,KAAK,MAAMhB,EAAI,IAAI,EACvB,KAAK,UAAU,YAAYgB,CAAK,GAClC,KAAK,QAAQE,CAAK,EAAIF,EACtBA,EAAQ,KAAK,iBAAiBE,EAAOlB,EAAI,GAAIgB,CAAK,IAElD,KAAK,QAAQE,CAAK,EAAIF,EACtB,KAAK,eAAe,OAAOE,CAAK,EAChC,KAAK,OACH,QAAQ,IAAI,qBAAsBP,EAChC,KAAK,eAAe,OAChB,KAAK,UAAU,KAAK,cAAc,EAClC,EACN,GAEJM,EAAO,GAAGN,OAAS,KAAK,SAAS,YAAYK,CAAK,eAClCjB,GAAM,OAAS,WAAa,SACvC,CACL,IAAMoB,EAAI,KAGVH,EAAQ,IAAMG,EAAE,MAAMnB,EAAI,IAAI,EAC9BiB,EAAO,GAAGN,oBAAwBZ,GAAM,OAAS,WAAa,IAK9D,KAAK,SAASmB,CAAK,EAAIF,EAEzB,YAAK,MAAM,SAAUC,CAAI,EAElBD,CACT,CAEA,OAAOhB,EAAK,CACV,OAAIA,EAAI,GACN,KAAK,OAAOA,EAAK,CAAE,OAAQ,EAAK,CAAC,EAEjC,KAAK,OAAOA,EAAK,CAAE,OAAQ,EAAK,CAAC,EAE5B,EACT,CAEA,KAAKA,EAAK,CACR,IAAIY,EACEV,EAAQ,OAAO,KAAKF,CAAG,EAC7B,GAAIE,EAAM,SAAW,EAAG,MAAM,MAAM,iBAAmBA,CAAK,EAC5D,YAAK,UAAU,OAAO,UAAU,QAASkB,GAAS,CAChD,IAAMtB,EAAUE,EAAIoB,CAAI,EACxB,GAAItB,EAAS,CACX,GAAIA,EAAQ,SAAW,EACrB,MAAM,MAAMsB,EAAO,mBAAqBpB,EAAIoB,CAAI,EAAE,MAAM,EAG1DR,EAAS,KAAK,MAAMd,EAAQ,CAAC,CAAC,EAElC,CAAC,EAGG,OAAOc,GAAW,aACpBA,EAASA,EAAO,KAAK,GAEhBA,CACT,CAEA,KAAKZ,EAAK,CACR,GAAIA,EAAI,IAAI,SAAW,EAAG,MAAM,MAAM,kBAAkB,EACxD,GAAI,OAAO,KAAKA,CAAG,EAAE,SAAW,EAAG,MAAM,MAAM,kBAAkB,EACjE,IAAMqB,EAAQrB,EAAI,IAAI,CAAC,EAAE,MACzB,YAAK,MAAM,OAAQ,KAAK,SAAS,YAAY,IAAMqB,EAAQ,GAAG,CAAC,EACxDA,CACT,CAEA,OAAOrB,EAAK,CACV,OAAO,KAAK,QACd,CAEA,OAAOA,EAAKD,EAAM,CAChB,GAAIC,EAAI,IAAI,SAAW,EAAG,MAAM,MAAM,oBAAoB,EAE1D,IAAMsB,EAAW,KAAK,SAChBC,EAASvB,EAAI,IAAI,CAAC,EAAE,MACpBkB,EAAQK,EAAO,QAAQ,KAAK,UAAU,YAAa,EAAE,EAI3D,GAFA,KAAK,WAAa,KAAK,YAAYvB,EAAI,EAAE,EAErC,KAAK,eAAe,IAAIkB,CAAK,EAC/B,YAAK,MAAM,SAAU,GAAGK,gBAAqB,EACtCD,EAIT,GAAI,CAAE,OAAAV,EAAQ,SAAAE,EAAU,OAAAC,EAAQ,SAAAF,CAAS,EAAI,KAAK,aAAaK,CAAK,EAEpE,GAAI,CAACJ,GAAYS,EAAO,WAAW,KAAK,QAAQ,MAAM,GAChD,CAAC,KAAK,UAAU,SAAS,KAAKA,CAAM,EACtC,MAAM,MAAM,uCAAuCL,SAC7C,KAAK,QAAQ,SAASA,oBAAwBA,IAAQ,EAUhE,GANI,OAAON,GAAW,aAEpBA,EAASA,EAAO,KAAK,EACrBC,EAAW,CAAC,KAAK,UAAU,YAAYD,CAAM,GAG3C,KAAK,aAAeE,GAAYC,GAAS,CAC3C,KAAK,WAAa,GAClB,IAAMS,EAAM,kCAAoCV,EAC5C,kBAAoBS,EAAS,2BAC/B,KAAK,QAAQ,QAAUL,EAAQ,MAC7B,uBAAyBA,EAAQ,8BACnC,KAAK,QAAQ,QAAUA,EAAQ,kBACjC,MAAM,MAAMM,CAAG,EAGjB,GAAI,OAAOZ,EAAW,IAEpB,YAAK,MAAM,SAAUW,EAAS,QAAUD,EAAW,SACjD,KAAK,gBAAgB,EAAG,aAAcvB,GAAM,OAAS,WAAa,EAAE,EAC/DuB,EAGT,IAAIL,EAAOK,EAAW,QAAUV,EAAS,KAAOb,GAAM,OAAS,YAAc,IAG7E,OAAI,OAAOa,GAAW,UAAY,CAACC,GAC7BC,GACF,KAAK,eAAe,IAAII,CAAK,EAC7BN,EAAS,KAAK,iBAAiBM,EAAOlB,EAAI,GAAIY,CAAM,EACpD,KAAK,MAAM,UAAW,GAAGU,QAAeV,oBAAyBM,IAAQ,IAErElB,EAAI,KAAIY,EAAS,KAAK,kBAAkBA,EAAQZ,EAAI,EAAE,GAC1D,KAAK,MAAM,SAAUiB,CAAI,GAEpBL,IAGLE,IAEF,KAAK,QAAQI,CAAK,EAAIN,GAGpBZ,EAAI,KACNY,EAAS,KAAK,gBAAgBA,EAAQZ,EAAI,EAAE,EAC5CiB,GAAQ,QAAUL,EAAS,IAGvB,KAAK,aAAYK,GAAQ,gBAG/B,KAAK,MAAM,SAAUA,CAAI,EAGrB,KAAK,eAAe,IAAIC,CAAK,IAC/B,KAAK,OAAS,QAAQ,IAAI,uBAAwBJ,EAAW,IAAM,KAAOI,EACxE,KAAK,eAAe,OAAS,KAAK,UAAU,KAAK,cAAc,EAAI,EAAE,EACvE,KAAK,eAAe,OAAOA,CAAK,GAElC,KAAK,WAAa,GAEXN,EACT,CAEA,MAAMZ,EAAK,CACT,KAAK,MAAM,QAAS,KAAK,QAAQ,EAEjC,IAAMsB,EAAW,KAAK,SAChBJ,EAAQI,EAAS,QAAQ,KAAK,QAAQ,aAAc,EAAE,EACtDG,EAAS,KAAK,aAAaP,CAAK,EAEtC,GAAI,CAACO,EACH,MAAM,MAAM,oBAAsBH,EAAW,YAC3C,KAAK,UAAU,OAAO,KAAK,KAAK,YAAY,CAAC,CAAC,EAalD,OAVwBG,EAAO,SAAS,KAAMjC,GAAM,CAClD,GAAI,CAAE,OAAAoB,EAAQ,SAAAC,CAAS,EAAI,KAAK,aAAarB,CAAC,EAC9C,OAAI,OAAOoB,GAAW,aAEpBA,EAASA,EAAO,KAAK,EACrBC,EAAW,CAAC,KAAK,UAAU,YAAYD,CAAM,GAExC,OAAOA,EAAW,KAAe,CAACC,CAC3C,CAAC,EAE2BS,EAEb,KAAK,OAAOG,EAAO,eAAe,CAEnD,CAEA,KAAKzB,EAAK,CAER,OAAO,KAAK,MAAMA,EAAI,IAAI,EAAE,KAAK,CACnC,CAEA,OAAOA,EAAKD,EAAM,CAChB,IAAMoB,EAAI,KAAK,QACXO,EAASC,EACPL,EAAW,KAAK,SAClBL,EAAOK,EACLM,EAAY,KAAK,SAAS,YAAYN,EAAW,KAAO,KAAK,SAAStB,CAAG,CAAC,EAEhF,GAAI,CAAC,KAAK,YAAc,KAAK,YAAYA,EAAI,EAAE,EAC7C,MAAM,MAAM,+DAAiEsB,CAAQ,EAGvF,IAAIO,EAAW,SACf,GAAI9B,GAAM,YACR8B,EAAW,iBAEP7B,EAAI,OAEN0B,EAAU1B,EAAI,KAAK,CAAC,EAAE,SAAS,KAAK,CAAC,EAAE,MACvC2B,EAAa,KAAK,MAAM3B,EAAI,IAAI,EAChC6B,EAAWF,EAAW,SACtBV,GAAQ;AAAA,WAAcS,QAAcG,IAAa,QAC7CA,EAAS,YAAY,EACrB,SAASV,EAAE,eAAeS,QACvB,KAAK,gBAAgB,KAG1BD,GACEA,EAAW,WAAa,QAC1B,YAAK,aAAaC,CAAS,EAAI,CAC7B,gBAAiB5B,EACjB,SAAU2B,EAAW,QACvB,EACO,GAAGR,EAAE,eAAeS,IAKjC,GAAIC,IAAa,UAAY,EAAE,WAAY7B,GACzC,MAAO,GAGT,IAAM8B,EAAS9B,EAAI6B,CAAQ,IAAI,CAAC,GAAG,UAAU,UAAU,CAAC,EAClDE,EAAU,KAAK,aAAaD,CAAM,EACxC,GAAI,CAACC,EAAS,MAAM,MAAM,yBAA2BT,CAAQ,EAE7D,IAAIN,EAAQ,KACNgB,EAAW,CAAC,EACdC,EAAW,GACf,KAAOjB,IAAU,MAAM,CAIrB,GAHAA,EAAQ,KAAK,OAAOe,EAASC,CAAQ,EAAE,MAGnC,KAAK,UAAU,YAAYhB,CAAK,EAAG,CACjChB,EAAI,KAAIgB,EAAQ,KAAK,kBAAkBA,EAAOhB,EAAI,EAAE,GACxDiC,EAAW,GACX,MAOF,GAHIjC,EAAI,KAAIgB,EAAQ,KAAK,gBAAgBA,EAAOhB,EAAI,EAAE,GAGlD,KAAK,YAAcgB,IAAU,KAAK,QAAQY,CAAS,EAAG,CACxD,KAAK,MAAM,gBAAiBZ,EAAQ,aAAa,EACjDgB,EAAS,KAAKhB,CAAK,EACnBA,EAAQ,KACR,UAIJ,OAAKiB,IAAU,KAAK,QAAQL,CAAS,EAAIZ,GAElCA,CACT,CAIA,YAAYkB,EAAK,CACf,IAAMC,EAAa,KAAK,SAAS,gBAAgBD,CAAG,EACpD,OAAIC,EAAW,OACNA,EAAW,SAAS,IAAI,GAAKA,EAAW,SAAS,UAAU,EAE7D,EACT,CAEA,aAAajB,EAAO,CAClB,IAAIJ,EAAW,GACXC,EAAS,GACTH,EAEJ,GAAIM,EAAM,SAAW,EACnB,MAAO,CAAE,OAAQ,GAAI,SAAU,GAAM,SAAAJ,EAAU,OAAAC,CAAO,EAIxDH,EAAS,KAAK,SAASM,CAAK,EACxB,OAAON,EAAW,MAIpBA,EAAS,KAAK,QAAQM,CAAK,EACvB,OAAON,EAAW,MACpBE,EAAW,KAIX,OAAOF,EAAW,MAGpBA,EAAS,KAAK,QAAQM,CAAK,EACvB,OAAON,EAAW,IACpBG,EAAS,GAGTH,EAAS,KAAK,QAAQ,KAAK,QAAQ,QAAUM,CAAK,GAStD,IAAML,EAAW,CAAC,KAAK,UAAU,YAAYD,CAAM,EAEnD,MAAO,CAAE,OAAAA,EAAQ,SAAAE,EAAU,OAAAC,EAAQ,SAAAF,CAAS,CAC9C,CAEA,iBAAiBK,EAAOgB,EAAKtB,EAAQ,CACnC,IAAMO,EAAI,KAAK,QACTiB,EAAMjB,EAAE,OAASD,EACjBmB,EAAM,KAAK,kBAAkBzB,EAAQsB,CAAG,EAC9C,OAAAtB,EAASO,EAAE,aAAeiB,EAAM,IAAMC,GAAOlB,EAAE,aACxCP,CACT,CAEA,SAASZ,EAAK,CACZ,GAAI,CAACA,EAAI,IAAM,CAACA,EAAI,GAAG,OAAQ,MAAM,MAAM,gBAAgB,EAC3D,OAAOA,EAAI,GAAG,CAAC,EAAE,YAAc,IAAMA,EAAI,GAAG,CAAC,EAAE,SACjD,CAEA,aAAaA,EAAK,CAChB,IAAM+B,EAAU,CAAC,EACjB,GAAI/B,GAAOA,GAAK,UAAU,MAAO,CAC/B,IAAMsC,EAAStC,EAAI,SAAS,MAC5B,QAAS,EAAI,EAAG,EAAIsC,EAAO,OAAQ,IAAK,CACtC,IAAMC,EAAQD,EAAO,CAAC,EAChBE,EAAOD,EAAM,SAAS,KAC5B,GAAIC,GAAQA,EAAK,QAAU,EAAK,MAAM,MAAM,wBAA0BA,EAAK,MAAM,EAEjF,IAAMC,EAASF,EAAM,SAAS,OAC9B,GAAIE,EAAQ,CACV,GAAIA,EAAO,QAAU,EAAK,MAAM,MAAM,mBAAqBA,EAAO,MAAM,EACxE,IAAIC,EAAO,EACX,GAAI,CACFA,EAAO,SACL,KAAK,QAAQ,aAAa,OACtBD,EAAO,CAAC,EAAE,MAAM,KAAK,EAAE,MAAM,EAAG,EAAE,EAClCA,EAAO,CAAC,EAAE,MAAM,KAAK,EAAE,MAAM,CAAC,CACpC,CACF,MAAE,CACA,QAAQ,IAAI,OAASC,CAAI,CAC3B,CACA,MAAM,KAAK,CAAE,OAAQA,CAAK,EAAG,IAAMX,EAAQ,KAAKS,CAAI,CAAC,OAErDT,EAAQ,KAAKS,GAAQ,EAAE,GAI7B,OAAOT,CACT,CAEA,aAAaA,EAASH,EAAW,CAI/B,KAAOG,EAAQ,QAAqB,CAClC,GAAM,CAAE,MAAAY,EAAO,MAAA3B,CAAM,EAAI,KAAK,OAAOe,CAAO,EAC5C,GAAIf,IAAU,KAAK,QAAQY,CAAS,EAAG,OAAOZ,EAE9Ce,EAAQ,OAAOY,EAAO,CAAC,EAEzB,MAAM,MAAM,sBAAsB,CACpC,CAEA,OAAOZ,EAASa,EAAW,CAAC,EAAG,CAC7B,GAAI,CAACb,GAAW,CAACA,EAAQ,OACvB,MAAM,MAAM,4BAA4B,EAG1C,IAAMc,EAAQd,EAAQ,OAAQe,GAAM,CAACF,EAAS,SAASE,CAAC,CAAC,EACzD,GAAI,CAACD,EAAM,OACT,MAAM,MAAM,kCAAkC,EAGhD,IAAMF,EAAQ,KAAK,UAAU,KAAK,MAAME,EAAM,MAAM,EAEhD7B,EAAQ,GAAU+B,EAAWF,EAAMF,CAAK,EAE5C,OAAI,OAAOI,GAAa,SACtB,KAAK,MAAM,cAAe,IAAI,GAG9B,KAAK,KAAO,UAAY,KAAK,KAC7B/B,EAAQ,KAAK,MAAM+B,CAAQ,GAGzB,OAAO/B,GAAU,WAAUA,EAAQA,EAAM,KAAK,GAE3C,CAAE,MAAA2B,EAAO,MAAA3B,CAAM,CACxB,CAEA,gBAAgBA,EAAOgC,EAAK,CACtB,KAAK,SAAW,QAAQ,IAAI,kBAAmB,KAAK,UAAU,GAAG,SAAS,CAAC,EAC/E,QAASC,EAAI,EAAGA,EAAID,EAAI,OAAQC,IAC9BjC,EAAQ,KAAK,eAAeA,EAAOgC,EAAIC,CAAC,CAAC,EAE3C,OAAOjC,CACT,CAGA,kBAAkBA,EAAOgC,EAAK,CAC5B,OAAI,OAAOhC,GAAU,WACN,IAAI,OACf,IAAM,KAAK,QAAQ,YAAc,KAAO,KAAK,QAAQ,aAAe,GACtE,EACU,KAAKA,CAAK,IAElBA,EAAQ,KAAK,QAAQ,YAAcA,EAAQ,KAAK,QAAQ,cAEtDgC,GACFA,EAAI,QAASE,GAAQlC,GAASkC,EAAG,KAAM,EAErC,KAAK,SAAS,QAAQ,IAAI,qBAAsBlC,CAAK,GAEpDA,CACT,CAEA,WAAWmC,EAAK,CACd,IAAIC,EAAW,GACf,cAAO,QAAQD,CAAG,EAAE,QAAQ,CAAC,CAACE,EAAGC,CAAC,IAAM,CACtC,IAAMC,EAAM,WAAWD,CAAC,EACnB,MAAMC,CAAG,IACZH,EAAW,GACXD,EAAIE,CAAC,EAAIE,EAEb,CAAC,EACMH,CACT,CAEA,kBAAkBI,EAAO,CACvB,IAAIC,EAAc,GAClB,cAAO,QAAQD,CAAK,EAAE,QAAQ,CAAC,CAACE,EAAKC,CAAG,IAAM,CACvC,KAAK,UAAU,YAAYA,CAAG,IACjCF,EAAc,GAElB,CAAC,EACMA,CACT,CAEA,eAAeG,EAAQC,EAAW,CAChC,IAAMxC,EAAQwC,EAAU,MACpBjD,EACEN,EAAMsD,EAASvC,EACf6B,EAAK7B,EAAM,UAAU,CAAC,EAAE,QAAQ,QAAS,EAAE,EAGjD,OAAI,OAAO,KAAK,SAAS6B,CAAE,GAAM,WAC/BtC,EAAS,KAAK,SAASsC,CAAE,EAAEU,CAAM,EAG1B,OAAO,KAAK,QAAQV,CAAE,GAAM,WACnCtC,EAAS,KAAK,QAAQsC,CAAE,EAAEU,CAAM,EAGzB,OAAO,KAAK,QAAQV,CAAE,GAAM,WACnCtC,EAAS,KAAK,QAAQsC,CAAE,EAAEU,CAAM,EAIzB,OAAO,KAAK,SAAS,WAAWV,CAAE,GAAM,WAC/CtC,EAAS,KAAK,SAAS,WAAWsC,CAAE,EAAEU,CAAM,EAGrC,OAAOA,EAAOV,CAAE,GAAM,WAC7BtC,EAASgD,EAAOV,CAAE,EAAE,EAGhBU,EAAO,eAAeV,CAAE,EAC1BtC,EAASgD,EAAOV,CAAE,GAEd,CAAC,KAAK,UAAU,KAAK,QAAU,CAAC,KAAK,UAAU,QACjD,QAAQ,KAAK,gCAAkC5C,CAAG,EAKpDM,EAASN,EAAI,QAAQ,QAAS,cAAc,GAI5C,KAAK,OAAS,QAAQ,IAAI,GAAG,KAAK,QAAQ,gBAAgBA,SAAWM,IAAS,EAE3EA,CACT,CAEA,iBAAkB,CAChB,IAAMkD,EAAO,CAAC,EACRC,EAAQ,CAAC,EACf,cAAO,QAAQ,KAAK,UAAY,CAAC,CAAC,EAAE,QAClC,CAAC,CAACV,EAAGC,CAAC,IAAOQ,EAAK,IAAIT,IAAI,EAAIC,CAChC,EACA,OAAO,QAAQ,KAAK,SAAW,CAAC,CAAC,EAAE,QACjC,CAAC,CAACD,EAAGC,CAAC,IAAOS,EAAM,IAAIV,IAAI,EAAIC,CACjC,EACO,KAAK,UAAU,CAAE,GAAG,KAAK,QAAS,GAAGS,EAAO,GAAGD,CAAK,EAAG,CAACT,EAAGC,IAChE,OAAOA,GAAM,WAAa,eAAiBA,CAC7C,EAAE,QAAQ,KAAM,EAAE,CACpB,CAEA,UAAUtC,EAAOgC,EAAK,CACpB,OAAOhC,EAAQgC,EAAI,IAAKE,GAAOA,EAAG,MAAM,QAAQ,KAAM,EAAE,EAAI,IAAI,EAAE,KAAK,EAAE,CAC3E,CAEA,MAAMc,KAAMC,EAAM,CACZ,KAAK,QACH,KAAK,MAAQD,IAAM,WACrBA,EAAI,KAAK,KAAK,QAAQ,MAAO,EAAE,GAEjC,QAAQ,IAAI,EAAE,KAAK,MAAO,IAAIA,KAAM,GAAGC,CAAI,EAC3C,KAAK,KAAO,GAEhB,CAEA,SAAU,CACR,MAAO,IAAI,QAAQ,KAAK,MAAQ,IAAI,OAAS,CAAC,CAChD,CACF,EvClrBA,GAAM,CAAE,OAAAC,EAAO,EAAIC,GACbC,GAAU,UACVC,GAAc,OACdC,GAAe,iDAEfC,GAAN,cAAsBC,EAAM,CAC1B,YAAYC,EAAWC,EAAWC,EAAS,CACzC,GAAI,OAAOD,GAAc,SAAU,CACjC,IAAIE,EAAMF,EACVA,EAAYD,EAAU,UAAUC,CAAS,EAG3C,MAAMA,EAAWC,CAAO,CAC1B,CAEA,KAAKE,EAAK,CACR,QAASC,EAAI,EAAGC,EAAM,KAAK,SAAS,OAAQD,EAAIC,EAAKD,IACnD,GAAI,CAAC,KAAK,SAASA,CAAC,EAAED,CAAG,EAAG,MAAO,GAErC,MAAO,EACT,CAEA,UAAW,CACT,IAAMG,EAAQ,CAAC,KAAK,SAAS,EACvBC,EAAO,IAAI,IACjB,KAAOD,GAAO,OAAS,GAAG,CACxB,IAAME,EAAaF,EAAM,IAAI,EAC7B,OAAO,KAAKE,CAAU,EAAE,QAASC,GAAQ,CACvC,IAAMC,EAAQF,EAAWC,CAAG,EAEvBA,EAAI,WAAW,GAAG,GAAGF,EAAK,IAAIE,CAAG,EAClC,OAAOC,GAAU,UAAYA,IAAU,OAC5B,MAAM,QAAQA,CAAK,EAAIA,EAAQ,CAACA,CAAK,GAC7C,QAASC,GAAQL,EAAM,KAAKK,CAAG,CAAC,CAEzC,CAAC,EAEH,OAAO,MAAM,KAAKJ,CAAI,CACxB,CACF,EAEMK,EAAN,KAAe,CAOb,OAAO,SAASC,EAAQC,EAASC,EAAO,CAAC,EAAG,CAC1C,OAAO,IAAIH,EAAS,EAAE,SAASC,EAAQC,EAASC,CAAI,CACtD,CAEA,YAAYA,EAAO,CAAC,EAAG,CACrB,KAAK,QAAU,EACf,KAAK,aAAeA,EAAK,gBAAkB,EAC3C,GAAM,CAAE,UAAAC,EAAW,OAAAC,CAAO,EAAIC,GAAU,KAAK,YAAY,EACzD,KAAK,QAAUF,EAAU,QACzB,KAAK,QAAUA,EAAU,QAEzB,IAAMG,EAASH,EAAU,QAAQ,OAASA,EAAU,QAAQ,QACtDI,EAAOJ,EAAU,QAAQ,YACzBK,EAAQL,EAAU,QAAQ,aAEhC,KAAK,YAAc,IAAI,OAAO,KAAKG,qCAA2C,GAAG,EACjF,KAAK,YAAc,IAAI,OAAO,KAAKA,kCAAuC,EAC1E,KAAK,aAAe,IAAI,OAAO,IAAMC,EAAO,KAAOA,EAAOC,EAAQ,KAAOA,EAAQ,GAAG,EAEpF,KAAK,UAAY,IAAI,OAAO,IAAI,KAAK,QAAQ,QAAQ,QAAQ,IAAK,EAAE,IAAI,EACxE,KAAK,WAAa,IAAI,OAAO,KAAK,QAAQ,aAAe,UAAW,GAAG,EACvE,KAAK,aAAe,6CACpB,KAAK,YAAc,IAAI,OAAO,IAAIF,IAAS,EAE3C,KAAK,OAAS,GACd,KAAK,MAAQ,IAAIG,EAAML,CAAM,EAC7B,KAAK,OAAS,IAAIM,GAAeN,CAAM,EACvC,KAAK,KAAOF,EAAK,MAAQ,CACvB,QAAS,EACT,MAAQS,GAAM,KAAK,MAAM,KAAK,OAAO,EAAIA,CAAC,CAC5C,CACF,CAEA,IAAIT,EAAM,CACR,GAAI,CAACA,EAAK,MAAO,MAAM,MAAM,UAAU,EACvC,IAAMU,EAAY,KAAK,MAAM,SAASV,EAAK,KAAK,EAChD,GAAIU,EAAU,OAAO,OACnB,cAAQ,MAAM,UAAYV,EAAK,MAAQ;AAAA,EAAMU,EAAU,OAAO,CAAC,EAAE,OAAO,EAClE,MAAM,YAAcA,EAAU,OAAO,CAAC,EAAE,OAAO,EAEnDV,EAAK,OAAO,KAAK,YAAYU,EAAU,MAAM,EACjDV,EAAK,OAASU,EAAU,MAE1B,CAEA,MAAMV,EAAM,CACVA,EAAK,IAAM,KAAK,OAAO,MAAMA,CAAI,CACnC,CAEA,MAAMA,EAAM,CACV,OAAO,KAAK,QAAQ,MAAMA,CAAI,CAChC,CAEA,cAAcA,EAAO,CAAC,EAAG,CACvB,YAAK,IAAIA,CAAI,EACb,KAAK,MAAMA,CAAI,EACR,KAAK,MAAMA,CAAI,CACxB,CAEA,SAASF,EAAQC,EAASC,EAAO,CAAC,EAAG,CACnC,GAAI,OAAOF,GAAW,SACpB,MAAM,MAAM,6CAA+C,OAAOA,CAAM,EAE1E,OAAAE,EAAK,MAAQF,EACbE,EAAK,QAAU,IAAIW,GAAgB,KAAMZ,CAAO,EACzC,KAAK,UAAUC,CAAI,CAC5B,CAEA,UAAUA,EAAM,CACd,GAAM,CAAE,MAAAY,CAAM,EAAIZ,EAIda,EAAMC,EAAc,SAAS,KAAKF,CAAK,EAEvCG,EAAO,KAAK,SAASH,EAAOZ,CAAI,EACpC,GAAI,CAACe,EAAM,MAAO,GAOlB,GALIf,EAAK,OAAO,QAAQ,IAAI;AAAA,WAAcH,EAAS,YAAYe,CAAK,IAAI,EACpEZ,EAAK,OAASY,IAAUG,GAC1B,QAAQ,IAAI,YAAYlB,EAAS,YAAYkB,CAAI,IAAI,EAGnD,CAACf,EAAK,QAAS,MAAM,MAAM,YAAY,EAC3C,KAAK,QAAUA,EAAK,QACpB,OAAOA,EAAK,QAEZ,QAASX,EAAI,EAAG0B,IAASF,GAAQxB,GAAK,KACpCwB,EAAOE,EAEHf,EAAK,OAAO,QAAQ,IAAI,IAAI,OAAO,EAAE,EAAI,SAAWX,EAAI,IAAM,IAAI,OAAO,EAAE,CAAC,EAEhFW,EAAK,MAAQe,EACbA,EAAO,KAAK,cAAcf,CAAI,EAE1BA,EAAK,OACP,QAAQ,IAAI,UAAUX,UAAeQ,EAAS,YAAYkB,CAAI,UAClD,KAAK,QAAQ,gBAAgB,GAAG,EAI1C,EAAAf,EAAK,SAAW,CAAC,KAAK,YAAYe,CAAI,IAdF1B,IAcxC,CAIF,MAAI,CAAC,KAAK,QAAU,CAAC,KAAK,KAAK,QACzB,KAAK,YAAY,KAAK0B,EAAK,QAAQlC,GAAc,EAAE,CAAC,GACtD,QAAQ,KAAK,mCAAqCkC,EAAK,QAAQ,MAAO,KAAK,EAAI,IAAI,EAIhF,KAAK,UAAUA,EAAMf,CAAI,GAAKc,EAAc;AAAA,EAAO,GAC5D,CAEA,OAAOE,EAAUhB,EAAM,CACrB,OAAO,IAAIlB,GAAQ,KAAMkC,EAAUhB,CAAI,CACzC,CAEA,YAAYE,EAAQ,CAClB,IAAIe,EAAIf,EAAO,OAAO,CAACgB,EAAKC,IAAM,CAChC,GAAI,CAAE,KAAAC,CAAK,EAAID,EAAE,UACbE,EAAMD,EACV,OAAIC,IAAQ,SAAQA,EAAMxB,EAAS,YAAYsB,EAAE,MAAO,CAAC,GACrDE,IAAQ,QAAOA,EAAM,OAASF,EAAE,MAAQ,KACxCE,IAAQ,OAAMA,EAAM,MAAQF,EAAE,MAAQ,KACnCD,EAAMG,EAAM,IACrB,EAAG,EAAE,EACF,MAAM,EAAG,EAAE,EACd,QAAQ,IAAI;AAAA,YAAiBJ,EAAI,eAC/B,KAAK,QAAQ,gBAAgB,CAAC,CAClC,CAEA,UAAUL,EAAOZ,EAAM,CACrB,GAAI,OAAOY,GAAU,SAAU,MAAO,GAMtC,IAAIU,EAHU7C,GAAOmC,CAAK,EAGL,QAAQ,KAAK,aAAc,GAAG,EAAE,QAAQ,SAAU,EAAE,EAIzE,MADY,CAAC,GAAGU,EAAO,SAAS,KAAK,QAAQ,eAAe,CAAC,EACvD,QAASC,GAAM,CACnB,GAAI,CAACA,GAAK,CAACA,EAAE,CAAC,GAAK,CAACA,EAAE,CAAC,EAAG,MAAM,MAAM,aAAeA,CAAC,EACtD,IAAIC,EAAe,KAAK,QAAQ,aAAaD,EAAE,CAAC,CAAC,EAC7C,CAAE,gBAAAE,EAAiB,SAAAC,CAAS,EAAIF,EACpC,GAAI,CAACE,EAAS,OAAQ,MAAM,MAAM,aAAa,EAC/C,IAAIC,EAAS,KAAK,QAAQ,OAAOF,EAAiB,CAAE,YAAa,EAAK,CAAC,EAEvEH,EAASA,EAAO,QAAQC,EAAE,CAAC,EAAGI,CAAM,EAChC3B,EAAK,OAAO,QAAQ,IAAI,KAAOuB,EAAE,CAAC,EAAI,MAAQI,CAAM,CAC1D,CAAC,EAEG3B,EAAK,OAAO,QAAQ,IAAI;AAAA,UAAasB,IAAS,EAE7CtB,EAAK,kBAER,KAAK,QAAQ,QAAU,OACvB,KAAK,QAAQ,SAAW,QAGnBsB,CACT,CAEA,SAASxB,EAAQE,EAAM,CACrB,GAAI,OAAOF,GAAW,SAAU,MAAO,GAEvC,IAAM8B,EAAI,KAAK,QAEXhB,EAAQd,EACP,KAAK,eAERc,EAAQA,EAAM,QAAQ,mBAAoB,MAAM,GAGlDA,EAAQA,EAAM,QAAQ,uBAAwB,EAAE,EAChDA,EAAQA,EAAM,QAAQ,uBAAwB,EAAE,EAChDA,EAAQA,EAAM,QAAQ,KAAK,WAAY,EAAE,EACzCA,EAAQiB,GAAuBjB,CAAK,EAEpC,IAAIU,EAAS,GACTQ,EAAQlB,EAAM,MAAM,OAAO,EAC/B,QAASvB,EAAI,EAAGA,EAAIyC,EAAM,OAAQzC,IAEhC,GAAiC,KAAK,YAAY,KAAKyC,EAAMzC,CAAC,CAAC,EAAG,CAEhE,IAAI0C,EAAQD,EAAMzC,CAAC,EAAE,QAAQ,GAAG,EAChC,GAAI0C,EAAQ,EAAG,MAAM,MAAM,gCAAkCD,EAAMzC,CAAC,CAAC,EACrE,IAAI2C,EAAMF,EAAMzC,CAAC,EAAE,UAAU,EAAG0C,CAAK,EACnCE,EAAMH,EAAMzC,CAAC,EAAE,UAAU0C,EAAQ,CAAC,EAChCG,EAAQC,GAAUF,EAAKL,EAAE,WAAW,EACpCQ,EAASD,GAAUF,EAAKL,EAAE,YAAY,EAC1C,KAAOM,EAAQE,GAAQ,CACrB,IAAIC,EAAOP,EAAM,EAAEzC,CAAC,EACpB4C,GAAO;AAAA,EAAOI,EACdH,GAASC,GAAUE,EAAMT,EAAE,WAAW,EACtCQ,GAAUD,GAAUE,EAAMT,EAAE,YAAY,EAE1CN,GAAUM,EAAE,aAAeI,EAAM,IAAMC,GAAOL,EAAE,kBAEhDN,GAAUQ,EAAMzC,CAAC,EACbA,EAAIyC,EAAM,OAAS,IAAGR,GAAU;AAAA,GAIxC,OAAOA,CACT,CAKA,UAAUgB,EAAM,CACd,IAAMC,EAAyBD,GAAS,CAEtC,IAAIE,EAAMF,EACV,GACE,OAAOA,GAAS,UAChBA,EAAK,WAAW1D,EAAW,GAC3B0D,EAAK,SAAS1D,EAAW,EACzB,CACA,IAAI6D,EAAQH,EAAK,MAAM1D,EAAW,EAClC,GAAI6D,EAAM,SAAW,EAAG,MAAM,MAAM,2BAA2B,EAC/DD,EAAM,IAAI,OAAOC,EAAM,CAAC,EAAGA,EAAM,CAAC,CAAC,EAErC,OAAOD,CACT,EACIE,EAAU7C,EAAS,iBAAiByC,CAAI,EACzC,QAAQ,KAAK,YAAa,OAAO,EACjC,QAAQ,KAAM,GAAG,EAIhBhB,EAAS,KAAK,MAAMoB,CAAO,EAC7BC,EAAMJ,EACR,cAAO,KAAKjB,CAAM,EAAE,QAASb,GAAOa,EAAOb,CAAC,EAAIkC,EAAIrB,EAAOb,CAAC,CAAC,CAAE,EACxDa,CACT,CAEA,YAAYL,EAAG,CAEb,IAAIK,EAAS,GAGb,MAFiB,kBAAkB,KAAK,OAAOL,CAAC,IAEhCK,EAAS,KAAK,UAAU,KAAKL,EAAE,SAAS,CAAC,GAClDK,CACT,CAMA,OAAO,UAAUL,EAAG,CAClB,GAAI,CAACA,GAAK,CAACA,EAAE,OAAQ,MAAO,GAE5B,IAAI2B,EAAQ3B,EAAE,MAAM,KAAK,EAAE,CAAC,EAE5B,GAAI,CAACpB,EAAS,MAAM,OAClB,OAAKA,EAAS,aAAa,SACzB,QAAQ,KAAK,yCAAyC,EACtDA,EAAS,aAAa,OAAS,KAGzB,cAAc,KAAK+C,CAAK,EAAI,MAAQ,MAAQ3B,EAGtD,IAAI4B,EAAShD,EAAS,KAAK,OAAO+C,EAAO,CAAE,OAAQ,EAAK,CAAC,EAGzD,OACGC,GAAUA,EAAO,QAAUlE,GAAQ,KAAKkE,EAAO,CAAC,CAAC,EAAI,MAAQ,MAAQ5B,CAE1E,CAGA,OAAO,WAAWA,EAAG,CACnB,OAAOA,EAAIA,EAAE,CAAC,EAAE,YAAY,EAAIA,EAAE,UAAU,CAAC,EAAI,EACnD,CAGA,OAAO,UAAUA,EAAG,CAClB,OAAOA,EAAIA,EAAE,YAAY,EAAI,EAC/B,CAGA,OAAO,QAAQA,EAAG,CAChB,MAAO,WAAaA,GAAK,IAAM,SACjC,CAGA,OAAO,UAAUA,EAAG,CAClB,OAAKpB,EAAS,MAAM,UAObA,EAAS,KAAK,UAAUoB,CAAC,GANzBpB,EAAS,aAAa,UACzBA,EAAS,aAAa,QAAU,GAChC,QAAQ,KAAK,8CAA8C,GAEtDoB,EAAE,SAAS,GAAG,EAAIA,EAAIA,EAAI,IAGrC,CAGA,OAAO,SAASA,EAAG,CACjB,OAAOA,CACT,CAIA,OAAO,gBAAgB6B,EAAK,CAC1B,OAAOA,GAAOA,EAAI,OACdA,EAAI,IAAKC,GAAOA,EAAG,MAAM,QAAQ,eAAgB,EAAE,EAAG,CAAC,CAAC,EACxD,CAAC,CACP,CAEA,OAAO,YAAY9B,EAAG+B,EAAS,CAC7B,GAAI,OAAO/B,GAAM,SAAU,OAAOA,EAClC,IAAIE,EAAIF,EAAE,QAAQ,SAAU,KAAK,EACjC,OAAO+B,GAAW,CAAC7B,EAAE,OAAS,IAAMA,EAAI,IAAMA,CAChD,CAEA,OAAO,iBAAiBmB,EAAM,CAC5B,OAAOA,EAAK,QACV,2BACA,IAAI1D,OAAgBA,OAAgBA,KACtC,CACF,CAEA,OAAO,YAAYqC,EAAG,CACpB,IAAIgC,EACFC,EAAO,EACT,QAAS7D,EAAI,EAAGA,EAAI4B,EAAE,OAAQ5B,IAC5B4D,EAAMhC,EAAE,WAAW5B,CAAC,EACpB6D,GAAQA,GAAQ,GAAKA,EAAOD,EAC5BC,GAAQ,EAEV,IAAIC,EAAUD,EAAK,SAAS,EAC5B,OAAOA,EAAO,EAAIC,EAAQ,QAAQ,IAAK,GAAG,EAAIA,CAChD,CACF,EAzVMC,EAANvD,EACEwD,GADID,EACG,QAAQtE,IAEfuE,GAHID,EAGG,UAAU,sBAEjBC,GALID,EAKG,eAAe,CAAE,QAAS,GAAO,OAAQ,EAAM,GAwVxDA,EAAS,WAAa,CACpB,QAASA,EAAS,QAClB,UAAWA,EAAS,UACpB,WAAYA,EAAS,WACrB,UAAWA,EAAS,UACpB,UAAWA,EAAS,UAGpB,SAAUA,EAAS,SAGnB,IAAKA,EAAS,UACd,GAAIA,EAAS,SACb,IAAKA,EAAS,WACd,IAAKA,EAAS,WACd,GAAIA,EAAS,UACb,GAAIA,EAAS,QACb,EAAGA,EAAS,SACd,EAIA,SAASvB,GAAuBZ,EAAG,CACjC,OAAAA,EAAIqC,EAAWrC,EAAG,MAAO,QAAQ,EACjCA,EAAIqC,EAAWrC,EAAG,MAAO,QAAQ,EACjCA,EAAIqC,EAAWrC,EAAG,MAAO,QAAQ,EACjCA,EAAIqC,EAAWrC,EAAG,MAAO,QAAQ,EACjCA,EAAIqC,EAAWrC,EAAG,MAAO,QAAQ,EACjCA,EAAIqC,EAAWrC,EAAG,MAAO,QAAQ,EACjCA,EAAIqC,EAAWrC,EAAG,MAAO,UAAU,EACnCA,EAAIqC,EAAWrC,EAAG,MAAO,OAAO,EAChCA,EAAIqC,EAAWrC,EAAG,MAAO,QAAQ,EACjCA,EAAIqC,EAAWrC,EAAG,MAAO,UAAU,EAC5BA,CACT,CACA,SAASsC,GAAaC,EAAQ,CAC5B,OAAOA,EAAO,QAAQ,sBAAuB,MAAM,CACrD,CACA,SAASF,EAAWpC,EAAKuC,EAAOC,EAAa,CAC3C,OAAOxC,EAAI,QAAQ,IAAI,OAAOqC,GAAaE,CAAK,EAAG,GAAG,EAAG,IAAMC,CAAW,CAC5E,CACA,SAASvB,GAAUjB,EAAKyC,EAAG,CACzB,IAAIC,EAAQ,EACZ,QAASvE,EAAI,EAAGA,EAAI6B,EAAI,OAAQ7B,IAC1B6B,EAAI7B,CAAC,IAAMsE,GAAGC,IAEpB,OAAOA,CACT,CwC5cA,IAAMC,GAAN,KAAgB,CAEd,YAAYC,EAAQ,CAAC,EAAGC,EAAU,CAAC,EAAG,CACpC,GAAI,OAAOD,GAAU,SACnB,MAAM,MAAM,sCAAwC,OAAOA,CAAK,EAGlE,KAAK,UAAY,IAAIE,EACrB,KAAK,QAAUD,EACf,KAAK,SAASD,CAAK,CACrB,CAEA,OAAO,OAAOA,EAAOC,EAASE,EAAM,CAClC,OAAO,IAAIJ,GAAUC,EAAOC,CAAO,EAAE,OAAOE,CAAI,CAClD,CAEA,cAAe,CACb,OAAOD,EAAS,aAAa,GAAG,SAAS,CAC3C,CACA,iBAAkB,CAChB,OAAOA,EAAS,gBAAgB,GAAG,SAAS,CAC9C,CACA,eAAgB,CACd,OAAOA,EAAS,UAClB,CAEA,OAAOE,EAAI,CACT,OAAOA,EAAG,OAAO,IAAM,KAAK,OAAO,CACrC,CAEA,OAAOD,EAAO,CAAC,EAAG,CAChB,GAAI,YAAaA,EACf,MAAM,MAAM,+DAA+D,EAI7E,OAAAA,EAAK,QAAUA,EAAK,SAAW,IAAID,EAAS,QAAQ,KAAK,SAAS,EAClEC,EAAK,QAAQ,QAAU,KAAK,SAAW,CAAC,EACxCA,EAAK,MAAQ,KAAK,UAAUA,CAAI,EAGzB,KAAK,UAAU,UAAUA,CAAI,CACtC,CAEA,QAAQE,EAAMC,EAAK,CACjB,KAAK,cAAcD,EAAMC,CAAG,EAC5B,KAAK,MAAMD,CAAI,EAAIC,CACrB,CAEA,SAASN,EAAO,CACd,GAAI,OAAOA,EAAU,IAAa,MAAM,MAAM,iBAAiB,EAC/D,KAAK,MAAQ,CAAC,EACd,IAAIO,EAAW,OAAOP,GAAU,SAAWQ,GAAUR,CAAK,EAAIA,EAC1DS,EAAO,KACX,OAAO,QAAQF,CAAQ,EAAE,QAASG,GAAMD,EAAK,QAAQ,GAAGC,CAAC,CAAC,CAC5D,CAEA,WAAWL,EAAM,CACXA,KAAQ,KAAK,OACf,OAAO,KAAK,MAAMA,CAAI,CAE1B,CAEA,QAAS,CACP,OAAO,KAAK,UAAU,KAAK,MAAO,GAAG,SAAS,CAChD,CAEA,SAASF,EAAO,CAAC,EAAG,CAClB,IAAIQ,EAAWR,EAAK,UAAY,EAC5BS,EAAQT,EAAK,OAAS,EACtBU,EAAKV,GAAM,UACXW,EAAM,KAAK,OAAOH,EAAUC,CAAK,EACrC,OAAIC,IAAIC,EAAMA,EAAI,QAAQ,MAAOD,CAAE,GAC5BC,CACT,CAEA,OAAO,SAASC,EAAKZ,EAAM,CACzB,OAAO,IAAIJ,GAAU,KAAK,MAAMgB,CAAG,EAAGZ,CAAI,CAC5C,CAMA,UAAUA,EAAM,CACd,IAAIa,EAAS,GACXC,EAAQd,EAAK,OAAS,QACpB,CAAE,QAAAe,CAAQ,EAAI,KAAK,UAUvB,GARID,EAAM,WAAWC,EAAQ,OAAO,IAClCD,EAAQA,EAAM,UAAUC,EAAQ,QAAQ,MAAM,GAG5CD,EAAM,WAAWC,EAAQ,MAAM,IACjCD,EAAQA,EAAM,UAAUC,EAAQ,OAAO,MAAM,GAG3C,EAAED,KAAS,KAAK,OAASC,EAAQ,OAASD,KAAS,KAAK,OAC1D,MAAM,MAAM,UAAYA,EAAQ,wBAAwB,EAG1D,cAAO,QAAQ,KAAK,KAAK,EAAE,QAAQ,CAAC,CAACZ,EAAMc,CAAI,EAAGC,IAAM,CACtD,KAAOf,EAAK,WAAWa,EAAQ,OAAO,GACpCb,EAAOA,EAAK,UAAU,CAAC,EAEpBA,EAAK,WAAWa,EAAQ,MAAM,IACjCb,EAAOa,EAAQ,QAAUb,GAGtB,KAAK,UAAU,aAAa,KAAKc,CAAI,IAExCA,EAAOD,EAAQ,YAAcC,EAAOD,EAAQ,cAG9CF,GAAU,GAAGX,KAAQc;AAAA,CACvB,CAAC,EAEGhB,EAAK,OAAO,QAAQ,IAAI;AAAA,EAAea,EAAO,QAAQ,QAAS,KAAK,CAAC,EAEzEA,GAAU,GAAGE,EAAQ,UAAUD,IACxBD,CACT,CAEA,cAAcX,EAAMC,EAAK,CACvB,GAAI,OAAOD,GAAS,UAAYA,EAAK,SAAW,EAC9C,MAAM,MAAM,wBAAwB,EAGtC,GAAI,OAAOC,EAAQ,IACjB,MAAM,MAAM,uBAAyBD,CAAI,EAE3C,GAAI,CAAE,QAAAa,CAAQ,EAAI,KAAK,UAEvB,GAAIb,EAAK,WAAWa,EAAQ,OAAO,EACjC,MAAAb,EAAOA,EAAK,UAAUa,EAAQ,QAAQ,MAAM,EACtC,MACJ,yEAEEA,EAAQ,OACRb,EACA,0BACAA,EACA,IACJ,CAEJ,CACF,EAEA,SAASG,GAAUa,EAAM,CACvB,GAAI,OAAOA,GAAS,SAClB,GAAI,CACF,OAAO,KAAK,MAAMA,CAAI,CACxB,MAAE,CACA,MAAM,MACJ;AAAA,EAEEA,CACJ,CACF,CAEJ,CC9JAC,EAAS,QAAUC,GACnBD,EAAS,QAAUE,GAEnB,IAAOC,GAAQH","names":["he","Query","clone","forEach","has","isEmpty","map","values","toFastProperties","drop","forEach","Alternation","Alternative","NonTerminal","Option","Repetition","RepetitionMandatory","RepetitionMandatoryWithSeparator","RepetitionWithSeparator","Terminal","RestWalker","prod","prevRest","subProd","index","currRest","terminal","refProd","flatProd","fullOrRest","optionProd","atLeastOneProd","fullAtLeastOneRest","atLeastOneSepProd","fullAtLeastOneSepRest","restForRepetitionWithSeparator","manyProd","fullManyRest","manySepProd","fullManySepRest","orProd","alt","prodWrapper","repSepProd","flatten","map","uniq","isBranchingProd","isOptionalProd","isSequenceProd","NonTerminal","Terminal","first","prod","firstForTerminal","firstForSequence","firstForBranching","firstSet","seq","nextSubProdIdx","hasInnerProdsRemaining","currSubProd","isLastInnerProdOptional","allAlternativesFirsts","innerProd","terminal","assign","forEach","IN","Alternative","ResyncFollowsWalker","RestWalker","topProd","terminal","currRest","prevRest","refProd","followName","buildBetweenProdsFollowPrefix","fullRest","restProd","t_in_topProd_follows","first","computeAllProdsFollows","topProductions","reSyncFollows","forEach","currRefsFollow","assign","inner","occurenceInParent","IN","has","isString","isUndefined","BaseRegExpVisitor","compact","defaults","difference","filter","find","first","flatten","forEach","has","includes","indexOf","isArray","isEmpty","isFunction","isRegExp","isString","isUndefined","keys","map","reduce","reject","values","PRINT_ERROR","BaseRegExpVisitor","every","find","forEach","includes","isArray","values","PRINT_ERROR","PRINT_WARNING","RegExpParser","regExpAstCache","regExpParser","getRegExpAst","regExp","regExpStr","regExpAst","clearRegExpParserCache","complementErrorMessage","failedOptimizationPrefixMsg","getOptimizedStartCodesIndices","regExp","ensureOptimizations","ast","getRegExpAst","firstCharOptimizedIndices","e","PRINT_WARNING","msgSuffix","PRINT_ERROR","result","ignoreCase","terms","term","atom","addOptimizedIdxToResult","forEach","code","range","rangeCode","minOptimizationVal","minUnOptVal","maxUnOptVal","minOptIdx","charCodeToOptimizedIndex","maxOptIdx","currOptIdx","isOptionalQuantifier","isWholeOptional","values","optimizedCharIdx","handleIgnoreCase","char","upperChar","lowerChar","findCode","setNode","targetCharCodes","find","codeOrRange","includes","targetCode","quantifier","isArray","every","CharCodeFinder","BaseRegExpVisitor","node","canMatchCharCode","charCodes","pattern","charCodeFinder","PATTERN","DEFAULT_MODE","MODES","SUPPORT_STICKY","analyzeTokenTypes","tokenTypes","options","defaults","SUPPORT_STICKY","msg","action","tracer","initCharCodeToOptimizedIndexMap","onlyRelevantTypes","reject","currType","PATTERN","Lexer","hasCustom","allTransformedPatterns","map","currPattern","isRegExp","regExpSource","includes","addStickyFlag","addStartOfInput","isFunction","escapedRegExpString","wrappedRegExp","patternIdxToType","patternIdxToGroup","patternIdxToLongerAltIdxArr","patternIdxToPushMode","patternIdxToPopMode","clazz","groupName","isString","isUndefined","longerAltType","isArray","type","indexOf","has","patternIdxToCanLineTerminator","lineTerminatorCharCodes","getCharCodes","tokType","checkLineBreaksIssues","canMatchCharCode","patternIdxToIsCustom","patternIdxToShort","emptyGroups","patternIdxToConfig","isCustomPattern","isShortPattern","reduce","acc","x","idx","canBeOptimized","charCodeToPatternIdxToConfig","result","currTokType","charCode","optimizedIdx","charCodeToOptimizedIndex","addToMapOfArrays","lastOptimizedIdx","forEach","charOrInt","currOptimizedIdx","PRINT_ERROR","failedOptimizationPrefixMsg","optimizedCodes","getOptimizedStartCodesIndices","isEmpty","code","validatePatterns","validModesNames","errors","missingResult","findMissingPatterns","invalidResult","findInvalidPatterns","validTokenTypes","validateRegExpPattern","findInvalidGroupType","findModesThatDoNotExist","findUnreachablePatterns","withRegExpPatterns","filter","findEndOfInputAnchor","findStartOfInputAnchor","findUnsupportedFlags","findDuplicatePatterns","findEmptyMatchRegExps","tokenTypesWithMissingPattern","LexerDefinitionErrorType","valid","difference","tokenTypesWithInvalidPattern","pattern","end_of_input","EndAnchorFinder","BaseRegExpVisitor","node","invalidRegex","regexpAst","getRegExpAst","endAnchorVisitor","matchesEmptyString","start_of_input","StartAnchorFinder","startAnchorVisitor","invalidFlags","found","identicalPatterns","outerType","innerType","compact","duplicatePatterns","currIdenticalSet","setOfIdentical","tokenTypeNames","first","invalidTypes","group","validModes","invalidModes","canBeTested","noMetaChar","testIdx","str","tokenType","testTokenType","regExpArray","regExp","find","char","flags","performRuntimeChecks","lexerDefinition","trackLines","lineTerminatorCharacters","DEFAULT_MODE","MODES","currModeValue","currModeName","currIdx","longerAlt","currLongerAlt","performWarningRuntimeChecks","warnings","hasAnyLineBreak","allTokenTypes","flatten","values","concreteTokenTypes","terminatorCharCodes","currIssue","warningDescriptor","buildLineBreakIssueMessage","cloneEmptyGroups","clonedResult","groupKeys","keys","currKey","currGroupValue","LineTerminatorOptimizedTester","text","len","i","c","e","details","charsOrCodes","numOrString","key","value","minOptimizationVal","charCodeToOptimizedIdxMap","assign","clone","forEach","identity","isArray","isEmpty","isUndefined","keys","last","map","noop","reduce","reject","PRINT_WARNING","timer","toFastProperties","clone","compact","difference","flatten","forEach","has","includes","isArray","isEmpty","map","tokenStructuredMatcher","tokInstance","tokConstructor","instanceType","tokenStructuredMatcherNoCategories","token","tokType","tokenShortNameIdx","tokenIdxToClass","augmentTokenTypes","tokenTypes","tokenTypesAndParents","expandCategories","assignTokenDefaultProps","assignCategoriesMapProp","assignCategoriesTokensProp","result","categories","searching","currTokType","newCategories","hasShortKeyProperty","hasCategoriesProperty","hasExtendingTokensTypesProperty","hasExtendingTokensTypesMapProperty","val","key","singleAssignCategoriesToksMap","path","nextNode","pathNode","nextCategory","newPath","isTokenType","defaultLexerErrorProvider","token","fullText","startOffset","length","line","column","LexerDefinitionErrorType","DEFAULT_LEXER_CONFIG","defaultLexerErrorProvider","Lexer","lexerDefinition","config","phaseDesc","phaseImpl","indent","time","value","timer","traceMethod","assign","traceInitVal","actualDefinition","hasOnlySingleMode","LineTerminatorOptimizedTester","isArray","clone","DEFAULT_MODE","performRuntimeChecks","performWarningRuntimeChecks","forEach","currModeValue","currModeName","reject","currTokType","isUndefined","allModeNames","keys","currModDef","currModName","validatePatterns","isEmpty","augmentTokenTypes","currAnalyzeResult","analyzeTokenTypes","allErrMessagesString","map","error","warningDescriptor","PRINT_WARNING","SUPPORT_STICKY","identity","noop","unOptimizedModes","reduce","cannotBeOptimized","canBeOptimized","modeName","clearRegExpParserCache","toFastProperties","text","initialMode","i","j","k","matchAltImage","longerAlt","matchedImage","payload","altPayload","imageLength","group","tokType","newToken","errLength","droppedChar","msg","match","orgText","orgLength","offset","matchedTokensIndex","guessedNumberOfTokens","matchedTokens","errors","line","column","groups","cloneEmptyGroups","trackLines","lineTerminatorPattern","currModePatternsLength","patternIdxToConfig","currCharCodeToPatternIdxToConfig","modeStack","emptyArray","getPossiblePatterns","getPossiblePatternsSlow","getPossiblePatternsOptimized","charCode","optimizedCharIdx","charCodeToOptimizedIndex","possiblePatterns","pop_mode","popToken","newMode","last","modeCanBeOptimized","push_mode","currConfig","recoveryEnabled","nextCharCode","chosenPatternIdxToConfig","chosenPatternsLength","currPattern","singleCharCode","longerAltLength","longerAltConfig","longerAltPattern","numOfLTsInMatch","foundTerminator","lastLTEndOffset","errorStartOffset","errorLine","errorColumn","foundResyncPoint","pushMode","length","regExp","newLastIndex","lastLTIdx","lastCharIsLT","fixForEndingInLT","oldColumn","image","startOffset","tokenTypeIdx","tokenType","startLine","startColumn","tokenVector","index","tokenToAdd","token","pattern","regExpArray","tokenLabel","tokType","hasTokenLabel","hasTokenLabel","obj","isString","PARENT","CATEGORIES","LABEL","GROUP","PUSH_MODE","POP_MODE","LONGER_ALT","LINE_BREAKS","START_CHARS_HINT","createToken","config","createTokenInternal","pattern","tokenType","isUndefined","has","augmentTokenTypes","EOF","Lexer","createTokenInstance","tokType","image","startOffset","endOffset","startLine","endLine","startColumn","endColumn","tokenMatcher","token","tokenStructuredMatcher","first","map","reduce","getProductionDslName","NonTerminal","Rule","Terminal","defaultParserErrorProvider","expected","actual","previous","ruleName","hasTokenLabel","tokenLabel","firstRedundant","expectedPathsPerAlt","customUserDescription","errPrefix","errSuffix","allLookAheadPaths","result","currAltPaths","nextValidTokenSequences","currPath","currTokenType","calculatedDescription","itemMsg","idx","expectedIterationPaths","defaultGrammarResolverErrorProvider","topLevelRule","undefinedRule","defaultGrammarValidatorErrorProvider","duplicateProds","getExtraProductionArgument","prod","topLevelName","duplicateProd","index","dslName","extraArgument","hasExplicitIndex","msg","rule","options","pathMsg","currTok","occurrence","currtok","currMessage","pathNames","currRule","leftRecursivePath","defaults","forEach","forEach","values","GAstVisitor","resolveGrammar","topLevels","errMsgProvider","refResolver","GastRefResolverVisitor","nameToTopRule","prod","node","ref","msg","ParserDefinitionErrorType","clone","compact","difference","drop","dropRight","filter","first","flatMap","flatten","forEach","groupBy","includes","isEmpty","map","pickBy","reduce","reject","values","Alternation","AlternativeGAST","GAstVisitor","getProductionDslName","isOptionalProd","NonTerminal","Option","Repetition","RepetitionMandatory","RepetitionMandatoryWithSeparator","RepetitionWithSeparator","Terminal","every","flatten","forEach","has","isEmpty","map","reduce","clone","drop","dropRight","_first","forEach","isEmpty","last","Alternation","Alternative","NonTerminal","Option","Repetition","RepetitionMandatory","RepetitionMandatoryWithSeparator","RepetitionWithSeparator","Rule","Terminal","AbstractNextPossibleTokensWalker","RestWalker","topProd","path","clone","prod","prevRest","refProd","currRest","fullRest","isEmpty","NextAfterTokenWalker","terminal","restProd","first","AbstractNextTerminalAfterProductionWalker","topRule","occurrence","NextTerminalAfterManyWalker","manyProd","firstAfterMany","_first","NextTerminalAfterManySepWalker","manySepProd","firstAfterManySep","NextTerminalAfterAtLeastOneWalker","atLeastOneProd","firstAfterAtLeastOne","NextTerminalAfterAtLeastOneSepWalker","atleastOneSepProd","firstAfterfirstAfterAtLeastOneSep","possiblePathsFrom","targetDef","maxLength","currPath","result","remainingPathWith","nextDef","drop","getAlternativesForProd","definition","alternatives","newDef","forEach","currAlt","nextPossibleTokensAfter","initialDef","tokenVector","tokMatcher","maxLookAhead","EXIT_NON_TERMINAL","EXIT_NON_TERMINAL_ARR","EXIT_ALTERNATIVE","foundCompletePath","tokenVectorLength","minimalAlternativesIndex","possiblePaths","last","currDef","currIdx","currRuleStack","currOccurrenceStack","nextPath","dropRight","nextIdx","actualToken","newRuleStack","newOccurrenceStack","nextPathWithout","nextPathWith","secondIteration","separatorGast","nthRepetition","i","currAltPath","expandTopLevelRule","newCurrOccurrenceStack","Alternation","AlternativeGAST","GAstVisitor","Option","Repetition","RepetitionMandatory","RepetitionMandatoryWithSeparator","RepetitionWithSeparator","PROD_TYPE","getProdType","prod","buildLookaheadFuncForOr","occurrence","ruleGrammar","maxLookahead","hasPredicates","dynamicTokensEnabled","laFuncBuilder","lookAheadPaths","getLookaheadPathsForOr","tokenMatcher","areTokenCategoriesNotUsed","tokenStructuredMatcherNoCategories","tokenStructuredMatcher","buildLookaheadFuncForOptionalProd","k","prodType","lookaheadBuilder","getLookaheadPathsForOptionalProd","buildAlternativesLookAheadFunc","alts","numOfAlts","areAllOneTokenLookahead","every","currAlt","currPath","orAlts","predicates","map","t","currNumOfPaths","currPredicate","nextPath","j","currPathLength","i","nextToken","singleTokenAlts","flatten","choiceToAlt","reduce","result","idx","forEach","currTokType","has","currExtendingType","buildSingleAlternativeLookaheadFunction","alt","numOfPaths","singleTokensTypes","isEmpty","expectedTokenUniqueKey","RestDefinitionFinderWalker","RestWalker","topProd","targetOccurrence","targetProdType","node","expectedProdType","currRest","prevRest","optionProd","PROD_TYPE","atLeastOneProd","atLeastOneSepProd","manyProd","manySepProd","InsideDefinitionFinderVisitor","GAstVisitor","targetRef","expectedProdName","initializeArrayOfArrays","size","pathToHashKeys","path","keys","tokType","longerKeys","currShorterKey","categoriesKeySuffix","isUniquePrefixHash","altKnownPathsKeys","searchPathKeys","currAltIdx","otherAltKnownPathsKeys","searchIdx","searchKey","lookAheadSequenceFromAlternatives","altsDefs","partialAlts","possiblePathsFrom","finalResult","altsHashes","currAltPaths","dict","item","currKey","newData","pathLength","currDataset","altIdx","currAltPathsAndSuffixes","currPathIdx","currPathPrefix","suffixDef","prefixKeys","currAltResult","containsPath","newPartialPathsAndSuffixes","key","orProd","visitor","insideDefVisitor","insideDef","afterDef","insideFlat","AlternativeGAST","afterFlat","alternative","searchPath","compareOtherPath","otherPath","searchTok","otherTok","isStrictPrefixOfPath","prefix","other","otherTokType","singleAltPaths","singlePath","token","validateLookahead","options","lookaheadValidationErrorMessages","map","errorMessage","ParserDefinitionErrorType","validateGrammar","topLevels","tokenTypes","errMsgProvider","grammarName","duplicateErrors","flatMap","currTopLevel","validateDuplicateProductions","termsNamespaceConflictErrors","checkTerminalAndNoneTerminalsNameSpace","tooManyAltsErrors","curRule","validateTooManyAlts","duplicateRulesError","validateRuleDoesNotAlreadyExist","topLevelRule","collectorVisitor","OccurrenceValidationCollector","allRuleProductions","productionGroups","groupBy","identifyProductionForDuplicates","duplicates","pickBy","currGroup","values","currDuplicates","firstProd","first","msg","dslName","getProductionDslName","defError","param","getExtraProductionArgument","prod","Terminal","NonTerminal","GAstVisitor","subrule","option","manySep","atLeastOne","atLeastOneSep","many","or","terminal","rule","allRules","className","errors","reduce","result","errMsg","validateRuleIsOverridden","ruleName","definedRulesNames","includes","validateNoLeftRecursion","topRule","currRule","path","nextNonTerminals","getFirstNoneTerminal","isEmpty","validNextSteps","difference","errorsFromNextSteps","currRefRule","newPath","clone","definition","AlternativeGAST","Option","RepetitionMandatory","RepetitionMandatoryWithSeparator","RepetitionWithSeparator","Repetition","Alternation","flatten","currSubDef","isFirstOptional","isOptionalProd","hasMore","rest","drop","OrCollector","node","validateEmptyOrAlternative","orCollector","ors","currOr","exceptLast","dropRight","currAlternative","currAltIdx","possibleFirstInAlt","nextPossibleTokensAfter","tokenStructuredMatcher","validateAmbiguousAlternationAlternatives","globalMaxLookahead","reject","currOccurrence","actualMaxLookahead","alternatives","getLookaheadPathsForOr","altsAmbiguityErrors","checkAlternativesAmbiguities","altsPrefixAmbiguityErrors","checkPrefixAlternativesAmbiguities","RepetitionCollector","validateSomeNonEmptyLookaheadPath","topLevelRules","maxLookahead","forEach","currTopRule","currProd","prodType","getProdType","pathsInsideProduction","getLookaheadPathsForOptionalProd","alternation","foundAmbiguousPaths","identicalAmbiguities","currAlt","currPath","altsCurrPathAppearsIn","currOtherAlt","currOtherAltIdx","containsPath","currAmbDescriptor","ambgIndices","pathsAndIndices","idx","currPathsAndIdx","compact","currPathAndIdx","targetIdx","targetPath","prefixAmbiguitiesPathsAndIndices","filter","searchPathAndIdx","isStrictPrefixOfPath","currAmbPathAndIdx","occurrence","tokenNames","currToken","currRuleName","resolveGrammar","options","actualOptions","defaults","defaultGrammarResolverErrorProvider","topRulesTable","forEach","rule","validateGrammar","defaultGrammarValidatorErrorProvider","clone","dropRight","find","flatten","has","includes","isEmpty","map","includes","MISMATCHED_TOKEN_EXCEPTION","NO_VIABLE_ALT_EXCEPTION","EARLY_EXIT_EXCEPTION","NOT_ALL_INPUT_PARSED_EXCEPTION","RECOGNITION_EXCEPTION_NAMES","isRecognitionException","error","RecognitionException","message","token","MismatchedTokenException","previousToken","NoViableAltException","NotAllInputParsedException","EarlyExitException","EOF_FOLLOW_KEY","IN_RULE_RECOVERY_EXCEPTION","InRuleRecoveryException","message","Recoverable","config","has","DEFAULT_PARSER_CONFIG","attemptInRepetitionRecovery","tokType","tokToInsert","createTokenInstance","grammarRule","grammarRuleArgs","lookAheadFunc","expectedTokType","reSyncTokType","savedLexerState","resyncedTokens","passedResyncPoint","nextTokenWithoutResync","currToken","generateErrorMessage","previousToken","msg","error","MismatchedTokenException","dropRight","expectTokAfterLastMatch","nextTokIdx","notStuck","tokIdxInRule","grammarPath","follows","nextTok","expectedToken","isEmpty","mismatchedTok","find","possibleFollowsTokType","tokenTypeIdx","followKey","currentRuleReSyncSet","includes","allPossibleReSyncTokTypes","nextToken","k","foundMatch","resyncTokType","tokenMatcher","currRuleShortName","currRuleIdx","prevRuleShortName","explicitRuleStack","explicitOccurrenceStack","map","ruleName","idx","followStack","currKey","flatten","EOF","followName","IN","token","resyncTokens","prodFunc","args","lookaheadFunc","dslMethodIdx","prodOccurrence","nextToksWalker","pathRuleStack","pathOccurrenceStack","clone","currShortName","key","firstAfterRepInfo","currRuleName","ruleGrammar","isEndOfRule","forEach","has","getKeyForAutomaticLookahead","ruleIdx","dslMethodIdx","occurrence","BITS_START_FOR_ALT_IDX","GAstVisitor","getProductionDslName","flatMap","isEmpty","LLkLookaheadStrategy","options","_a","DEFAULT_PARSER_CONFIG","leftRecursionErrors","isEmpty","emptyAltErrors","ambiguousAltsErrors","emptyRepetitionErrors","rules","flatMap","currTopRule","validateNoLeftRecursion","defaultGrammarValidatorErrorProvider","validateEmptyOrAlternative","maxLookahead","validateAmbiguousAlternationAlternatives","validateSomeNonEmptyLookaheadPath","buildLookaheadFuncForOr","buildAlternativesLookAheadFunc","buildLookaheadFuncForOptionalProd","getProdType","buildSingleAlternativeLookaheadFunction","LooksAhead","config","has","DEFAULT_PARSER_CONFIG","LLkLookaheadStrategy","rules","forEach","currRule","alternation","repetition","option","repetitionMandatory","repetitionMandatoryWithSeparator","repetitionWithSeparator","collectMethods","currProd","prodIdx","getProductionDslName","laFunc","key","getKeyForAutomaticLookahead","rule","prodOccurrence","prodKey","prodType","prodMaxLookahead","dslMethodName","dslMethodIdx","occurrence","currRuleShortName","value","DslMethodsCollectorVisitor","GAstVisitor","manySep","atLeastOne","atLeastOneSep","many","or","collectorVisitor","dslMethods","setNodeLocationOnlyOffset","currNodeLocation","newLocationInfo","setNodeLocationFull","addTerminalToCst","node","token","tokenTypeName","addNoneTerminalToCst","ruleName","ruleResult","has","isUndefined","keys","noop","compact","filter","forEach","isArray","isEmpty","isFunction","isUndefined","keys","map","NAME","defineNameProp","obj","nameValue","defaultVisit","ctx","param","childrenNames","keys","childrenNamesLength","currChildName","currChildArray","currChildArrayLength","j","currChild","createBaseSemanticVisitorConstructor","grammarName","ruleNames","derivedConstructor","defineNameProp","semanticProto","cstNode","isArray","isUndefined","semanticDefinitionErrors","validateVisitor","isEmpty","errorMessages","map","currDefError","createBaseVisitorConstructorWithDefaults","baseConstructor","withDefaultsProto","forEach","ruleName","CstVisitorDefinitionError","visitorInstance","validateMissingCstMethods","missingRuleNames","filter","currRuleName","isFunction","errors","compact","TreeBuilder","config","has","DEFAULT_PARSER_CONFIG","noop","setNodeLocationFull","setNodeLocationOnlyOffset","cstNode","nextToken","fullRuleName","ruleCstNode","prevToken","loc","key","consumedToken","rootCst","addTerminalToCst","ruleCstResult","ruleName","preCstNode","addNoneTerminalToCst","isUndefined","newBaseCstVisitorConstructor","createBaseSemanticVisitorConstructor","keys","newConstructor","createBaseVisitorConstructorWithDefaults","ruleStack","occurrenceStack","LexerAdapter","newInput","END_OF_FILE","howMuch","soughtIdx","newState","includes","values","serializeGrammar","RecognizerApi","impl","idx","tokType","options","ruleToCall","actionORMethodDef","altsOrOpts","name","implementation","config","DEFAULT_RULE_CONFIG","includes","error","defaultGrammarValidatorErrorProvider","ParserDefinitionErrorType","ruleImplementation","ruleErrors","validateRuleIsOverridden","grammarRule","args","orgState","e","isRecognitionException","values","clone","every","flatten","has","isArray","isEmpty","isObject","reduce","uniq","values","RecognizerEngine","tokenVocabulary","config","tokenStructuredMatcherNoCategories","has","isArray","isEmpty","reduce","acc","tokType","every","flatten","values","isTokenType","allTokenTypes","uniqueTokens","uniq","isObject","clone","EOF","noTokenCategoriesUsed","tokenConstructor","tokenStructuredMatcher","augmentTokenTypes","ruleName","impl","resyncEnabled","DEFAULT_RULE_CONFIG","recoveryValueFunc","shortName","invokeRuleWithTry","args","cst","e","resyncEnabledConfig","isFirstInvokedRule","reSyncEnabled","isRecognitionException","recogError","reSyncTokType","partialCstResult","actionORMethodDef","occurrence","key","lookAheadFunc","action","predicate","orgLookaheadFunction","prodOccurrence","laKey","notStuck","PROD_TYPE","NextTerminalAfterAtLeastOneWalker","options","separator","separatorLookAheadFunc","NextTerminalAfterAtLeastOneSepWalker","lookaheadFunction","NextTerminalAfterManyWalker","NextTerminalAfterManySepWalker","nextTerminalAfterWalker","beforeIteration","altsOrOpts","alts","altIdxToTake","firstRedundantTok","errMsg","NotAllInputParsedException","ruleToCall","idx","ruleResult","consumedToken","nextToken","eFromConsumption","msg","previousToken","MismatchedTokenException","follows","eFromInRuleRecovery","IN_RULE_RECOVERY_EXCEPTION","savedErrors","savedRuleStack","newState","fullName","idxInCallingRule","clone","has","ErrorHandler","config","has","DEFAULT_PARSER_CONFIG","error","isRecognitionException","clone","newErrors","occurrence","prodType","userDefinedErrMsg","ruleName","ruleGrammar","insideProdPaths","getLookaheadPathsForOptionalProd","actualTokens","i","msg","EarlyExitException","errMsgTypes","lookAheadPathsPerAlternative","getLookaheadPathsForOr","previousToken","errMsg","NoViableAltException","first","isUndefined","ContentAssist","startRuleName","precedingInput","startRuleGast","nextPossibleTokensAfter","grammarPath","topRuleName","topProduction","NextAfterTokenWalker","forEach","has","isArray","isFunction","peek","some","Alternation","Alternative","NonTerminal","Option","Repetition","RepetitionMandatory","RepetitionMandatoryWithSeparator","RepetitionWithSeparator","Rule","Terminal","RECORDING_NULL_OBJECT","HANDLE_SEPARATOR","MAX_METHOD_IDX","RFT","createToken","Lexer","augmentTokenTypes","RECORDING_PHASE_TOKEN","createTokenInstance","RECORDING_PHASE_CSTNODE","GastRecorder","config","i","idx","arg1","arg2","that","impl","grammarRule","args","howMuch","END_OF_FILE","name","def","newTopLevelRule","Rule","originalError","actionORMethodDef","occurrence","recordProd","Option","RepetitionMandatory","options","RepetitionMandatoryWithSeparator","Repetition","RepetitionWithSeparator","altsOrOpts","recordOrProd","ruleToCall","assertMethodIdxIsValid","has","error","getIdxSuffix","prevProd","peek","ruleName","newNoneTerminal","NonTerminal","tokType","hasShortKeyProperty","Terminal","prodConstructor","mainProdArg","handleSep","grammarAction","isFunction","newProd","hasOptions","isArray","alts","newOrProd","Alternation","hasPredicates","some","currAlt","forEach","currAltFlat","Alternative","has","timer","PerformanceTracer","config","has","userTraceInitPerf","traceIsNumber","DEFAULT_PARSER_CONFIG","phaseDesc","phaseImpl","indent","time","value","timer","traceMethod","applyMixins","derivedCtor","baseCtors","baseCtor","baseProto","propName","basePropDescriptor","END_OF_FILE","createTokenInstance","EOF","DEFAULT_PARSER_CONFIG","defaultParserErrorProvider","DEFAULT_RULE_CONFIG","ParserDefinitionErrorType","Parser","parserInstance","defErrorsMsgs","className","toFastProperties","forEach","currRuleName","originalGrammarAction","recordedRuleGast","resolverErrors","resolveGrammar","values","isEmpty","validationErrors","validateGrammar","defaultGrammarValidatorErrorProvider","lookaheadValidationErrors","validateLookahead","allFollows","computeAllProdsFollows","_b","_a","map","defError","tokenVocabulary","config","that","has","DEFAULT_PARSER_CONFIG","applyMixins","Recoverable","LooksAhead","TreeBuilder","LexerAdapter","RecognizerEngine","RecognizerApi","ErrorHandler","ContentAssist","GastRecorder","PerformanceTracer","CstParser","configClone","clone","Alternation","Alternative","NonTerminal","Option","Repetition","RepetitionMandatory","RepetitionMandatoryWithSeparator","RepetitionWithSeparator","Rule","Terminal","serializeGrammar","serializeProduction","GAstVisitor","generateCstDts","getTokens","v2Compatible","Symbols","Escaped","k","v","escapeRegex","PENDING_GATE_PATTERN","ExitGate","createToken","Gate","PendingGate","EnterGate","OC","CC","OR","ELSE","EQ","TF","OS","CS","SYM","Entity","Weight","Raw","s","RiScriptParser","CstParser","allTokens","opts","cst","$","Tokens","t","BaseVisitor","riScript","o","cstNode","param","name","location","RiScriptVisitor","context","opts","ctx","count","types","exprs","c","mingoQuery","raw","e","resolvedOps","unresolvedOps","operands","sym","result","resolved","isStatic","isUser","value","info","ident","$","type","image","original","symbol","msg","lookup","rawGate","gateResult","choiceKey","decision","orExpr","options","excluded","restored","tfs","transforms","lhs","rhs","wexprs","wexpr","expr","weight","mult","index","excludes","valid","x","selected","txs","i","tx","obj","madeCast","k","v","num","table","allResolved","key","val","target","transform","dyns","stats","s","args","decode","he","VowelRE","RegexEscape","HtmlEntities","RiQuery","Query","scripting","condition","options","raw","obj","i","len","stack","keys","currentObj","key","value","ele","_RiScript","script","context","opts","Constants","tokens","getTokens","anysym","open","close","Lexer","RiScriptParser","k","lexResult","RiScriptVisitor","input","last","endingBreak","expr","rawQuery","s","str","t","name","tag","result","g","deferredGate","deferredContext","operands","reject","$","slashEscapesToEntities","lines","eqIdx","lhs","rhs","opens","charCount","closes","line","text","unescapeRegexProperty","res","parts","escaped","urp","first","phones","txs","tx","quotify","chr","hash","strHash","RiScript","__publicField","replaceAll","escapeRegExp","string","match","replacement","c","count","RiGrammar","rules","context","RiScript","opts","rg","name","def","incoming","parseJSON","self","e","replacer","space","lb","res","str","script","start","Symbols","rule","i","json","RiScript","RiGrammar","RiScriptVisitor","src_default"]}